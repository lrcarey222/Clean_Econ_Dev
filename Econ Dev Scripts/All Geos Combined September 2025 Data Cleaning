# ACRE Pipeline — Q2 2025 (prep through geo_long + ALL raw loads + GEO coverage checks with names)
# Updated: 2025-09-17 | Full, start-to-finish script (nothing omitted) | Extra debugging throughout
# Coverage checks report MISSING geographies *with names* wherever possible

suppressPackageStartupMessages({
  library(tidyverse); library(sf); library(dplyr); library(tidyr); library(stringr); library(purrr); library(tibble)
  library(rlang); library(readr); library(readxl); library(jsonlite); library(httr); library(tigris); library(censusapi); library(tidycensus)
}); options(stringsAsFactors=FALSE, scipen=999, timeout=max(300,getOption("timeout",60))); options(tigris_use_cache=TRUE); sf::sf_use_s2(TRUE)

# Utilities / Safety patches
`%||%` <- function(a,b) if(!is.null(a)) a else b
fix_bad_names <- function(df){ if(is.null(df)) return(df); nm <- names(df); if(is.null(nm)) return(df); bad <- is.na(nm)|nm==""; if(any(bad)){ nm[bad] <- paste0("X", seq_along(nm))[bad]; names(df) <- nm }; df }
trim_names <- function(df){ if(is.null(df)||is.null(names(df))) return(df); names(df) <- gsub("\\s+$","", gsub("^\\s+","", names(df))); df }
if (exists("fix_df", envir=globalenv()) && bindingIsLocked("fix_df", globalenv())) unlockBinding("fix_df", globalenv())
fix_df <- function(df){
  if (is.null(df)) return(df); if (inherits(df, c("sf","sfc"))) return(df)
  if (inherits(df,"tbl_df")) df <- as.data.frame(df, stringsAsFactors=FALSE)
  nm <- names(df); if(!is.null(nm)){ nm <- gsub("\\s+$","", gsub("^\\s+","", nm)); bad <- is.na(nm)|nm==""; if(any(bad)) nm[bad] <- paste0("X", which(bad)); names(df) <- nm }
  tibble::as_tibble(df, .name_repair="unique")
}; try(lockBinding("fix_df", globalenv()), silent=TRUE)

# Debug helpers
dbg <- function(x,name, head_n=6){
  cat("\n==== ",name," ====\n",sep=""); if(is.null(x)){cat("<<not loaded>>\n"); return(invisible(NULL))}
  cat("Rows:", tryCatch(nrow(x), error=function(e) NA_integer_), "  Cols:", tryCatch(ncol(x), error=function(e) NA_integer_), "\n")
  suppressWarnings(try(dplyr::glimpse(x), silent=TRUE))
  pr <- tryCatch(readr::problems(x), error=function(e) NULL); if(!is.null(pr) && nrow(pr)>0){cat("\n---- parsing problems (top 10) ----\n"); print(utils::head(pr,10))}
  nas <- tryCatch(sapply(x, function(v) sum(is.na(v))), error=function(e) NULL); if(!is.null(nas)){ nas <- nas[nas>0]; if(length(nas)){cat("\n---- NA counts (top 20) ----\n"); print(utils::head(sort(nas,decreasing=TRUE),20))} }
  invisible(x)
}
nz_chr <- function(x) ifelse(is.na(x)|!nzchar(x), NA_character_, x)
# New (NA-safe)
nf <- function(x) { x <- suppressWarnings(as.character(x)); ifelse(is.na(x), NA_character_, stringr::str_pad(x, 5, pad="0")) }
ns <- function(x) { x <- suppressWarnings(as.character(x)); ifelse(is.na(x), NA_character_, stringr::str_pad(x, 2, pad="0")) }
inspect_csv_issues <- function(path, expected_cols, skip=0, n_show=10){
  cat("\n== Inspect:", basename(path), "==\n"); suppressWarnings(print(tryCatch(readr::guess_encoding(path, n_max=5000), error=function(e) tibble(note="failed to guess encoding"))))
  cf <- tryCatch(utils::count.fields(path, sep=",", quote="\""), error=function(e) integer(0)); if(length(cf)==0){ cat("Could not count fields; file unreadable?\n"); return(invisible(NULL)) }
  bad <- which(cf != expected_cols); cat("\nTotal lines:", length(cf), "\nExpected cols:", expected_cols, "\nBad lines:", length(bad), "\n")
  if(length(bad)){ show_idx <- utils::tail(bad, n_show); rl <- tryCatch(readr::read_lines(path), error=function(e) character(0)); cat("\n-- Last", length(show_idx), "problem lines --\n"); for(i in show_idx){ line <- if(i<=length(rl)) rl[i] else "<out of range>"; cat(sprintf("[%d:%d] %s\n", i, cf[i], line)) } }
}
read_csv_trim_block <- function(path, expected_cols=3, col_types=cols(.default=col_character())){
  cf <- utils::count.fields(path, sep=",", quote="\""); keep <- which(cf==expected_cols); if(!length(keep)) stop("No rows with expected column count in: ", path)
  rng <- range(keep); readr::read_csv(I(readr::read_lines(path)[rng[1]:rng[2]]), col_types=col_types, show_col_types=FALSE) %>% fix_df()
}
assert_unique_by <- function(df, keys, name=deparse(substitute(df))) {
  d <- df %>% count(across(all_of(keys)), name="n") %>% filter(n>1)
  if (nrow(d)) stop(sprintf("[%s] has %d duplicate keys by (%s). Example:\n%s", name, nrow(d), paste(keys, collapse=", "), paste(utils::capture.output(print(head(d, 10))), collapse="\n")))
  invisible(df)
}
make_unique_by <- function(df, keys, summarise_fn=dplyr::first){ df %>% group_by(across(all_of(keys))) %>% summarise(across(everything(), summarise_fn), .groups="drop") }

# Paths
find_acre_data_dir <- function(){
  env_dir <- nz_chr(Sys.getenv("RMI_DATA_DIR")); if(!is.na(env_dir)&&dir.exists(env_dir)) return(normalizePath(env_dir, winslash="/", mustWork=FALSE))
  cand <- unique(na.omit(c(nz_chr(Sys.getenv("OneDriveCommercial")), nz_chr(Sys.getenv("OneDrive")), nz_chr(Sys.getenv("ONEDRIVE")),
                           path.expand("~/Library/CloudStorage/OneDrive-RMI"), file.path(path.expand("~"), "OneDrive - RMI"), file.path(path.expand("~"), "OneDrive"), path.expand("~"))))
  anchors <- c(file.path("US Program - Documents","6_Projects","Clean Regional Economic Development","ACRE","Data"), "Data")
  for(r in cand) for(a in anchors){ p <- file.path(r,a); if(dir.exists(p) && (dir.exists(file.path(p,"Raw Data"))||dir.exists(file.path(p,"US Maps etc")))) return(normalizePath(p, winslash="/", mustWork=FALSE)) }
  NA_character_
}
DATA_DIR <- find_acre_data_dir(); if(is.na(DATA_DIR)){ warning("Set RMI_DATA_DIR to .../ACRE/Data; using getwd().", immediate.=TRUE); DATA_DIR <- normalizePath(getwd(), winslash="/", mustWork=FALSE) }
paths <- list(data_root=DATA_DIR, raw_data=file.path(DATA_DIR,"Raw Data"), us_maps=file.path(DATA_DIR,"US Maps etc"), states_data=file.path(DATA_DIR,"States Data"),
              downloads_dir=file.path(path.expand("~"),"Downloads"), chatgpt_map_app=file.path(DATA_DIR,"ChatGPT","map_app"),
              cgp_raw=file.path(DATA_DIR,"Clean-growth-project","raw"), ct_fips_data=file.path(DATA_DIR,"Raw Data","CT_FIPS_CHANGES"))
invisible(lapply(paths, function(p) if(!dir.exists(p)) dir.create(p, recursive=TRUE, showWarnings=FALSE)))

# API keys
readRenviron("~/.Renviron"); if (!nzchar(Sys.getenv("CENSUS_KEY"))) stop("CENSUS_KEY not set. Add `CENSUS_KEY=yourtoken` to ~/.Renviron and restart R.")

PATH_COUNTY_GDP <- file.path(paths$raw_data,"county_gdp_2022.csv"); PATH_MSA_GDP <- file.path(paths$raw_data,"msa_gdp_2022.csv")
PATH_STATES_SIMPLE <- file.path(paths$us_maps,"Regions","rmi_regions.csv"); PATH_CBSA_COUNTY <- file.path(paths$us_maps,"Regions","csa_cbsa_county.csv")
PATH_CD119_COUNTY <- file.path(paths$raw_data,"cd_119_counties.csv"); PATH_FCC_PEA_XLSX <- file.path(paths$raw_data,"FCC_PEA_website.xlsx")

# Core local GDP inputs (trim footers/headers)
county_gdp_csv <- read_csv_trim_block(PATH_COUNTY_GDP,3,cols(GeoFips=col_character(),GeoName=col_character(),"2022"=col_character())) %>% filter(nchar(GeoFips)==5) %>% fix_df(); dbg(county_gdp_csv,"county_gdp_csv (raw)")
msa_gdp <- read_csv_trim_block(PATH_MSA_GDP,3,cols(GeoFips=col_character(),GeoName=col_character(),"2022"=col_double())) %>% filter(nchar(GeoFips)==5|GeoFips=="00998") %>% fix_df(); dbg(msa_gdp,"msa_gdp (raw)")
states_simple <- readr::read_csv(PATH_STATES_SIMPLE, show_col_types=FALSE) %>% fix_df(); if ("...1" %in% names(states_simple)) states_simple <- select(states_simple, -"...1")
states_simple <- states_simple %>% mutate(fips_int=suppressWarnings(as.integer(fips)), statefp_chr=ns(fips_int), abbr=as.character(abbr), full=as.character(full)) %>% fix_df(); dbg(states_simple,"states_simple (clean)")

# Rebuild county_cbsa cleanly
county_cbsa <- readr::read_csv(PATH_CBSA_COUNTY, skip=2, show_col_types=FALSE) %>% fix_df() %>%
  filter(!is.na(`FIPS State Code`), !is.na(`FIPS County Code`)) %>%
  mutate(`FIPS State Code`=stringr::str_pad(as.character(`FIPS State Code`),2,pad="0"),
         `FIPS County Code`=stringr::str_pad(as.character(`FIPS County Code`),3,pad="0"), fips=paste0(`FIPS State Code`,`FIPS County Code`)) %>%
  select(fips, `CBSA Title`, `CBSA Code`) %>% distinct() %>% fix_df(); dbg(county_cbsa,"county_cbsa (raw)")
dup_cbsa <- county_cbsa %>% count(fips) %>% filter(n>1); if (nrow(dup_cbsa)) warning("county_cbsa has duplicate fips rows; check source before joining.")

cd_119_county <- readr::read_csv(PATH_CD119_COUNTY, show_col_types=FALSE) %>% fix_df(); dbg(cd_119_county,"cd_119_county (raw)")

tmp_x <- tempfile(fileext=".xlsx"); invisible(httr::RETRY("GET","https://www.americancommunities.org/wp-content/uploads/2023/08/2023-Typology-1.xlsx", write_disk(tmp_x, overwrite=TRUE), times=3))
us_communities <- readxl::read_excel(tmp_x, 1) %>% fix_df(); dbg(us_communities,"us_communities (raw)")

pea_county_raw <- readxl::read_excel(PATH_FCC_PEA_XLSX, 3) %>% fix_df(); pea_raw <- readxl::read_excel(PATH_FCC_PEA_XLSX, 2) %>% fix_df()
dbg(pea_county_raw,"pea_county (raw)"); dbg(pea_raw,"pea (raw)")

# Prep to GEO master
county_2020 <- us_communities %>% as.data.frame() %>% rename(GeoName="County name", fips="Fips", Community="2023 Typology") %>%
  mutate(GEOID=nf(substr(GEO_ID,10,14)), fips=nf(fips)) %>% select(GeoName, GEOID, fips, Community) %>% fix_df(); dbg(county_2020,"county_2020")

cd_119 <- cd_119_county %>% mutate(GEOID=nf(GEOID), STATEFP_chr=ns(STATEFP)) %>%
  left_join(select(states_simple, statefp_chr, abbr, full), by=c("STATEFP_chr"="statefp_chr")) %>%
  mutate(cd_119=paste0(abbr,"-",sprintf("%02d", as.numeric(CD119FP)))) %>%
  select(cd_119, GEOID_2, GEOID, percent_district) %>% fix_df(); dbg(cd_119,"cd_119")

pea <- pea_county_raw %>% mutate(fips=nf(FIPS)) %>% left_join(pea_raw, by="FCC_PEA_Number") %>% select(fips, FCC_PEA_Name, FCC_PEA_Number) %>% fix_df(); dbg(pea,"pea (with fips)")

census_divisions <- tibble(State.Name=state.name, state_abbr=state.abb, Region=as.character(state.region), Division=as.character(state.division)) %>%
  add_row(State.Name="District of Columbia", state_abbr="DC", Region="South", Division="South Atlantic") %>% fix_df(); dbg(census_divisions,"census_divisions")

# County GDP 2022 from BEA CAGDP2 (All industry total) with CSV fallback
tmp_zip <- tempfile(fileext=".zip"); tmp_dir <- tempdir()
download.file("https://apps.bea.gov/regional/zip/CAGDP2.zip", tmp_zip, mode="wb", quiet=TRUE); unzip(tmp_zip, exdir=tmp_dir)
cagdp2_path <- list.files(tmp_dir, pattern="^CAGDP2__ALL_AREAS_\\d{4}_\\d{4}\\.csv$", full.names=TRUE)[1]
CAGDP2_wide <- suppressWarnings(readr::read_csv(cagdp2_path, col_types=cols(.default=col_character()), show_col_types=FALSE)) %>% filter(nchar(GeoFIPS)==5) %>% fix_df()
yrs <- grep("^\\d{4}$", names(CAGDP2_wide), value=TRUE); na_tokens <- c("(D)","(L)","(S)","(NA)","(N/A)","(X)")
CAGDP2_long <- CAGDP2_wide %>% pivot_longer(all_of(yrs), names_to="Year", values_to="Value_raw") %>% mutate(Year=as.integer(Year), Value=readr::parse_number(Value_raw, na=na_tokens)) %>% select(-Value_raw) %>% fix_df()
CAGDP2_LONG_2022_ALLINDUSTRY_GDP <- CAGDP2_long %>% filter(Description=="All industry total", Year==2022) %>% filter(substr(GeoFIPS,3,5)!="000"); glimpse(CAGDP2_LONG_2022_ALLINDUSTRY_GDP)

# BEA county/city crosswalk for CAGDP2 special geos (population weighted with ACS 2022)
bea_va_xwalk <- tibble::tribble(
  ~GeoFIPS, ~target_fips, ~label,
  "51901","51003","Albemarle + Charlottesville","51901","51540","Albemarle + Charlottesville",
  "51903","51005","Alleghany + Covington","51903","51580","Alleghany + Covington",
  "51907","51015","Augusta + Staunton + Waynesboro","51907","51790","Augusta + Staunton + Waynesboro","51907","51820","Augusta + Staunton + Waynesboro",
  "51911","51031","Campbell + Lynchburg","51911","51680","Campbell + Lynchburg",
  "51913","51035","Carroll + Galax","51913","51640","Carroll + Galax",
  "51918","51053","Dinwiddie + Colonial Heights + Petersburg","51918","51570","Dinwiddie + Colonial Heights + Petersburg","51918","51730","Dinwiddie + Colonial Heights + Petersburg",
  "51919","51059","Fairfax + Fairfax City + Falls Church","51919","51600","Fairfax + Fairfax City + Falls Church","51919","51610","Fairfax + Fairfax City + Falls Church",
  "51921","51069","Frederick + Winchester","51921","51840","Frederick + Winchester",
  "51923","51081","Greensville + Emporia","51923","51595","Greensville + Emporia",
  "51929","51089","Henry + Martinsville","51929","51690","Henry + Martinsville",
  "51931","51095","James City + Williamsburg","51931","51830","James City + Williamsburg",
  "51933","51121","Montgomery + Radford","51933","51750","Montgomery + Radford",
  "51939","51143","Pittsylvania + Danville","51939","51590","Pittsylvania + Danville",
  "51941","51149","Prince George + Hopewell","51941","51670","Prince George + Hopewell",
  "51942","51153","Prince William + Manassas + Manassas Park","51942","51683","Prince William + Manassas + Manassas Park","51942","51685","Prince William + Manassas + Manassas Park",
  "51944","51161","Roanoke + Salem","51944","51775","Roanoke + Salem",
  "51945","51163","Rockbridge + Buena Vista + Lexington","51945","51530","Rockbridge + Buena Vista + Lexington","51945","51678","Rockbridge + Buena Vista + Lexington",
  "51947","51165","Rockingham + Harrisonburg","51947","51660","Rockingham + Harrisonburg",
  "51949","51175","Southampton + Franklin","51949","51620","Southampton + Franklin",
  "51951","51177","Spotsylvania + Fredericksburg","51951","51630","Spotsylvania + Fredericksburg",
  "51953","51191","Washington + Bristol","51953","51520","Washington + Bristol",
  "51955","51195","Wise + Norton","51955","51720","Wise + Norton",
  "51958","51199","York + Poquoson","51958","51735","York + Poquoson"
) %>% select(GeoFIPS, target_fips)
bea_hi_xwalk <- tibble::tribble(~GeoFIPS, ~target_fips, "15901","15009","15901","15005")
bea_ak_xwalk <- tibble::tribble(~GeoFIPS, ~target_fips, "02261","02063","02261","02066","02232","02105","02232","02230","02280","02275","02280","02195","02201","02198","02201","02130")
bea_cagdp2_xwalk <- bind_rows(bea_va_xwalk, bea_hi_xwalk, bea_ak_xwalk) %>% mutate(GeoFIPS=nf(GeoFIPS), target_fips=nf(target_fips)) %>% fix_df()

# Pull ACS 2022 5-year population at county level for weights
acs_pop_2022 <- censusapi::getCensus(name="acs/acs5", vintage=2022, vars=c("B01003_001E"), region="county:*", regionin="state:*", key=Sys.getenv("CENSUS_KEY")) %>%
  transmute(fips=nf(paste0(state, county)), pop_2022=suppressWarnings(as.numeric(B01003_001E))) %>% fix_df()

# Build population weights for BEA combined geos
xw_pop <- bea_cagdp2_xwalk %>% left_join(acs_pop_2022, by=c("target_fips"="fips")) %>% group_by(GeoFIPS) %>%
  mutate(group_pop=sum(pop_2022, na.rm=TRUE), weight_pop=dplyr::if_else(is.finite(group_pop)&group_pop>0, pop_2022/group_pop, NA_real_)) %>% ungroup()
xw_weights <- xw_pop %>% group_by(GeoFIPS) %>% mutate(n_members=dplyr::n(), eq_wt=1/n_members, weight=dplyr::coalesce(weight_pop, eq_wt)) %>% ungroup() %>% select(GeoFIPS, target_fips, weight)

# Expand & allocate CAGDP2 GDP (All industry, 2022) to actual counties
county_gdp_expanded <- CAGDP2_LONG_2022_ALLINDUSTRY_GDP %>% select(GeoFIPS, Value) %>% left_join(xw_weights, by="GeoFIPS") %>%
  mutate(target_fips=dplyr::coalesce(target_fips, nf(GeoFIPS)), weight=dplyr::coalesce(weight, 1.0)) %>%
  group_by(target_fips) %>% summarise(gdp_2022=sum(Value*weight, na.rm=TRUE), .groups="drop") %>% rename(fips=target_fips) %>% fix_df()

# Prefer BEA-expanded GDP; use CSV as final backstop
county_gdp_clean <- county_gdp_expanded %>% full_join(county_gdp_csv %>% transmute(fips=nf(GeoFips), gdp_2022_csv=readr::parse_number(`2022`)), by="fips") %>%
  mutate(gdp_2022=coalesce(gdp_2022, gdp_2022_csv)) %>% select(fips, gdp_2022) %>% fix_df()
county_gdp_clean <- county_gdp_clean %>% right_join(county_2020 %>% select(fips), by="fips") %>% arrange(fips) %>% fix_df()
assert_unique_by(county_gdp_clean, "fips"); glimpse(county_gdp_clean)

# MSA GDP clean
msa_gdp_clean <- msa_gdp %>% transmute(cbsa_code=as.character(GeoFips), msa_gdp_2022=`2022`) %>% fix_df(); dbg(msa_gdp_clean,"msa_gdp_clean")

CAGDP2_LONG_STATE <- CAGDP2_long %>% filter(Description=="All industry total") %>% filter(substr(GeoFIPS,3,5)=="000" & GeoFIPS!="00000"); glimpse(CAGDP2_LONG_STATE)

# TIGRIS baselayers
tigris_counties_2024_raw <- tigris::counties(cb=FALSE, year=2024, class="sf"); dbg(tigris_counties_2024_raw,"tigris_counties_2024_raw")
tigris_congressional_districts_2024_raw <- tigris::congressional_districts(cb=FALSE, year=2024, class="sf"); dbg(tigris_congressional_districts_2024_raw,"tigris_congressional_districts_2024_raw")
tigris_cbsa_2024_raw <- tigris::core_based_statistical_areas(cb=FALSE, year=2024, class="sf"); dbg(tigris_cbsa_2024_raw,"tigris_cbsa_2024_raw")
tigris_counties_2020_raw <- tigris::counties(cb=FALSE, year=2020, class="sf"); dbg(tigris_counties_2020_raw,"tigris_counties_2020_raw")
tigris_cbsa_2020_raw <- tigris::core_based_statistical_areas(cb=FALSE, year=2020, class="sf"); dbg(tigris_cbsa_2020_raw,"tigris_cbsa_2020_raw")
tigris_counties_2018_raw <- tigris::counties(cb=FALSE, year=2018, class="sf"); dbg(tigris_counties_2018_raw,"tigris_counties_2018_raw")
tigris_cbsa_2018_raw <- tigris::core_based_statistical_areas(cb=FALSE, year=2018, class="sf"); dbg(tigris_cbsa_2018_raw,"tigris_cbsa_2018_raw")
tigris_states_2024_raw <- tigris::states(year=2024, cb=FALSE, class="sf"); dbg(tigris_states_2024_raw,"tigris_states_2024_raw")
tigris_regions_2020_raw <- tigris::regions(year=2020, class="sf"); dbg(tigris_regions_2020_raw,"tigris_regions_2020_raw")
tigris_divisions_2020_raw <- tigris::divisions(year=2020, class="sf"); dbg(tigris_divisions_2020_raw,"tigris_divisions_2020_raw")

# Build county crosswalk with Census regions/divisions, state info, CBSA membership/names (2020), and population (2022 ACS w/ 2020 fallback)
build_county_crosswalk <- function(counties_sf, states_year=2024, cbsa_year=2020, acs_year=2022){
  states_x <- states(year=states_year, cb=FALSE, class="sf") |> st_drop_geometry() |> filter(!(STATEFP %in% c("60","66","69","72","78"))) |>
    transmute(STATE_FIPS=STATEFP, STATE_NAME=NAME, STATE_ABBREVIATION=STUSPS, CENSUS_REGION_GEOID=REGION, CENSUS_DIVISION_GEOID=DIVISION) |>
    left_join(regions(year=2020, class="sf") |> st_drop_geometry() |> transmute(CENSUS_REGION_GEOID=GEOID, CENSUS_REGION_NAME=NAMELSAD), by="CENSUS_REGION_GEOID") |>
    left_join(divisions(year=2020, class="sf") |> st_drop_geometry() |> transmute(CENSUS_DIVISION_GEOID=GEOID, CENSUS_DIVISION_NAME=NAMELSAD), by="CENSUS_DIVISION_GEOID")
  cbsa_x <- core_based_statistical_areas(cb=FALSE, year=cbsa_year, class="sf") |> st_drop_geometry() |> transmute(CBSA_GEOID=GEOID, CBSA_NAME=NAMELSAD)
  pop_x <- get_acs("county","B01003_001", year=acs_year, survey="acs5", geometry=FALSE) |> transmute(COUNTY_GEOID=GEOID, POP_2022=estimate) |>
    full_join(get_decennial("county","P1_001N", year=2020, geometry=FALSE) |> transmute(COUNTY_GEOID=GEOID, POP_2020=value), by="COUNTY_GEOID") |>
    mutate(POP_FINAL=coalesce(POP_2022, POP_2020)) |> select(COUNTY_GEOID, `2022_COUNTY_POPULATION`=POP_FINAL)
  counties_sf |> st_drop_geometry() |> filter(!(STATEFP %in% c("60","66","69","72","78"))) |>
    transmute(STATE_FIPS=STATEFP, COUNTY_GEOID=GEOID, COUNTY_NAME=NAMELSAD, CBSA_GEOID=CBSAFP, IN_CBSA=!is.na(CBSAFP)) |>
    left_join(cbsa_x, by="CBSA_GEOID") |> left_join(states_x, by="STATE_FIPS") |> left_join(pop_x, by="COUNTY_GEOID") |>
    select(CENSUS_REGION_GEOID, CENSUS_REGION_NAME, CENSUS_DIVISION_GEOID, CENSUS_DIVISION_NAME,
           STATE_FIPS, STATE_NAME, STATE_ABBREVIATION, COUNTY_GEOID, COUNTY_NAME, IN_CBSA, CBSA_GEOID, CBSA_NAME, `2022_COUNTY_POPULATION`) |> distinct()
}

# Usage
COUNTY_CROSSWALK_SUPPLEMENT <- tigris_counties_2020_raw %>% build_county_crosswalk(); glimpse(COUNTY_CROSSWALK_SUPPLEMENT)

# Add county GDP information
COUNTY_CROSSWALK_SUPPLEMENT_GDP <- COUNTY_CROSSWALK_SUPPLEMENT %>% left_join(county_gdp_clean, by=c("COUNTY_GEOID"="fips")) %>%
  rename(COUNTY_GDP_2022=gdp_2022) %>% fix_df(); glimpse(COUNTY_CROSSWALK_SUPPLEMENT_GDP)

# Add PEA info using fips/COUNTY_GEOID
COUNTY_CROSSWALK_SUPPLEMENT_GDP_PEA <- COUNTY_CROSSWALK_SUPPLEMENT_GDP %>%
  left_join(pea %>% rename(COUNTY_GEOID=fips, PEA_NAME=FCC_PEA_Name, PEA_NUMBER=FCC_PEA_Number), by="COUNTY_GEOID") %>%
  fix_df(); glimpse(COUNTY_CROSSWALK_SUPPLEMENT_GDP_PEA)

# Load geocorr data for county 2020/congressional district 119
geocorr_county_2020_cd_119 <- readr::read_csv(file.path(paths$raw_data,"geocorr_county_2020_cd_119.csv"), skip=1, show_col_types=FALSE) %>% glimpse()
geocorr_county_2020_cd_119 <- geocorr_county_2020_cd_119 %>%
  mutate(State_code=stringr::str_pad(as.character(`State code`),2,pad="0"),
         CD119_code=stringr::str_pad(as.character(`Congressional district code (119th Congress)`),2,pad="0"),
         CD119_GEOID=paste0(State_code, CD119_code),
         COUNTY_GEOID=stringr::str_pad(as.character(`County code`),5,pad="0"))
glimpse(geocorr_county_2020_cd_119)

# Coverage check between crosswalk and geocorr
missing_counties <- COUNTY_CROSSWALK_SUPPLEMENT_GDP_PEA %>% filter(!(COUNTY_GEOID %in% geocorr_county_2020_cd_119$COUNTY_GEOID)) %>% select(COUNTY_GEOID, COUNTY_NAME)
if(nrow(missing_counties)>0){ cat("The following COUNTY_GEOID values are missing in geocorr_county_2020_cd_119:\n"); print(missing_counties) } else { cat("All COUNTY_GEOID values in COUNTY_CROSSWALK_SUPPLEMENT_GDP_PEA are present in geocorr_county_2020_cd_119.\n") }

geocorr_ct_county_cd_119 <- readr::read_csv(file.path(paths$raw_data,"geocorr_ct_county_cd_119.csv"), skip=1); glimpse(geocorr_ct_county_cd_119)

compute_cd119_population_weighted_gdp <- function(county_gdp_df, xwalk_df, ct_xwalk_df, gdp_col="COUNTY_GDP_2022", pop_col="2022_COUNTY_POPULATION"){
  suppressPackageStartupMessages({require(dplyr, quietly=TRUE); require(stringr, quietly=TRUE); require(tidyr, quietly=TRUE); require(rlang, quietly=TRUE)})
  gdp_q <- rlang::ensym(gdp_col); pop_q <- rlang::ensym(pop_col)
  req_cols_county <- c("COUNTY_GEOID","STATE_FIPS","STATE_ABBREVIATION","STATE_NAME", as_string(gdp_q), as_string(pop_q))
  missing_county <- setdiff(req_cols_county, names(county_gdp_df)); if(length(missing_county)) stop("county_gdp_df is missing required columns: ", paste(missing_county, collapse=", "))
  xwalk_df_std <- xwalk_df %>% mutate(State_code=str_pad(as.character(`State code`),2,pad="0"),
                                      CD119_code=str_pad(as.character(`Congressional district code (119th Congress)`),2,pad="0"),
                                      CD119_GEOID=paste0(State_code, CD119_code),
                                      COUNTY_GEOID=str_pad(as.character(`County code`),5,pad="0")) %>%
    rename(alloc_factor=`cd119-to-county allocation factor`) %>% select(COUNTY_GEOID, CD119_GEOID, alloc_factor)
  ct_fips <- "09"; ct_counties_expected <- county_gdp_df %>% filter(STATE_FIPS==ct_fips) %>% distinct(COUNTY_GEOID) %>% pull()
  present_in_nat <- xwalk_df_std %>% distinct(COUNTY_GEOID) %>% pull()
  ct_missing <- setdiff(ct_counties_expected, present_in_nat); if(length(ct_missing)>0 && length(ct_counties_expected)>0) message("Handling ", length(ct_missing), " CT county GEOIDs via ct_xwalk_df: ", paste(ct_missing, collapse=", "))
  county_nonct <- county_gdp_df %>% filter(STATE_FIPS!=ct_fips)
  alloc_nonct <- county_nonct %>% inner_join(xwalk_df_std, by="COUNTY_GEOID") %>% mutate(allocated_gdp=(!!gdp_q)*alloc_factor, allocated_pop=(!!pop_q)*alloc_factor) %>%
    select(COUNTY_GEOID, STATE_FIPS, STATE_ABBREVIATION, STATE_NAME, CD119_GEOID, allocated_gdp, allocated_pop)
  ct_xwalk_std <- ct_xwalk_df %>% mutate(COUNTY_GEOID=str_pad(as.character(`County code`),5,pad="0"),
                                         CD119_code=str_pad(as.character(`Congressional district code (119th Congress)`),2,pad="0"),
                                         State_code=ct_fips, CD119_GEOID=paste0(State_code, CD119_code)) %>%
    rename(alloc_factor=`cd119-to-CTcounty allocation factor`) %>% select(COUNTY_GEOID, CD119_GEOID, alloc_factor)
  county_ct <- county_gdp_df %>% filter(STATE_FIPS==ct_fips)
  alloc_ct <- county_ct %>% inner_join(ct_xwalk_std, by="COUNTY_GEOID") %>% mutate(allocated_gdp=(!!gdp_q)*alloc_factor, allocated_pop=(!!pop_q)*alloc_factor) %>%
    select(COUNTY_GEOID, STATE_FIPS, STATE_ABBREVIATION, STATE_NAME, CD119_GEOID, allocated_gdp, allocated_pop)
  alloc_all <- bind_rows(alloc_nonct, alloc_ct)
  cd_meta <- alloc_all %>% mutate(STATE_CODE=substr(CD119_GEOID,1,2), DISTRICT_CODE=substr(CD119_GEOID,3,4)) %>%
    mutate(DISTRICT_LABEL=if_else(DISTRICT_CODE=="00","AL",DISTRICT_CODE)) %>%
    group_by(CD119_GEOID, STATE_CODE, DISTRICT_CODE, DISTRICT_LABEL) %>%
    summarise(total_gdp_2022=sum(allocated_gdp, na.rm=TRUE), total_pop_alloc=sum(allocated_pop, na.rm=TRUE),
              STATE_ABBREVIATION=dplyr::first(STATE_ABBREVIATION), STATE_NAME=dplyr::first(STATE_NAME), .groups="drop") %>%
    mutate(CD119_LABEL=paste0(STATE_ABBREVIATION,"-",DISTRICT_LABEL), gdp_per_capita=if_else(total_pop_alloc>0, total_gdp_2022/total_pop_alloc, NA_real_)) %>%
    select(CD119_GEOID, STATE_CODE, STATE_ABBREVIATION, STATE_NAME, DISTRICT_CODE, CD119_LABEL, total_gdp_2022, total_pop_alloc, gdp_per_capita) %>%
    arrange(STATE_ABBREVIATION, DISTRICT_CODE)
  attr(cd_meta,"notes") <- paste0("Population-weighted GDP allocated from counties to 119th districts using Geocorr factors. ",
                                  "CT handled via special crosswalk. GDP column: ", as_string(gdp_q), "; Pop column: ", as_string(pop_q), ".")
  cd_meta
}
gdp_cd119 <- compute_cd119_population_weighted_gdp(COUNTY_CROSSWALK_SUPPLEMENT_GDP_PEA, geocorr_county_2020_cd_119, geocorr_ct_county_cd_119); dplyr::glimpse(gdp_cd119)

# Rollups by geography
# ---------- Rollups by geography (with County + PEA, no Region/Division) ----------
cc <- COUNTY_CROSSWALK_SUPPLEMENT_GDP_PEA

# County GDP rows
county_gdp_rows <- cc %>%
  transmute(
    geo_type                = "county",
    geo_code                = COUNTY_GEOID,
    geo_name                = COUNTY_NAME,
    geo_gdp_2022_estimated  = COUNTY_GDP_2022
  )

# PEA GDP rows
pea_gdp_rows <- cc %>%
  filter(!is.na(PEA_NUMBER)) %>%
  group_by(PEA_NUMBER, PEA_NAME) %>%
  summarise(val = sum(COUNTY_GDP_2022, na.rm = TRUE), .groups = "drop") %>%
  transmute(
    geo_type                = "pea",
    geo_code                = as.character(PEA_NUMBER),
    geo_name                = PEA_NAME,
    geo_gdp_2022_estimated  = val
  )

# State GDP rows
state_gdp <- cc %>%
  group_by(STATE_FIPS, STATE_NAME) %>%
  summarise(val = sum(COUNTY_GDP_2022, na.rm = TRUE), .groups = "drop") %>%
  transmute(
    geo_type                = "state",
    geo_code                = STATE_FIPS,
    geo_name                = STATE_NAME,
    geo_gdp_2022_estimated  = val
  )

# CBSA GDP rows
cbsa_gdp <- cc %>%
  filter(!is.na(CBSA_GEOID), IN_CBSA) %>%
  group_by(CBSA_GEOID, CBSA_NAME) %>%
  summarise(val = sum(COUNTY_GDP_2022, na.rm = TRUE), .groups = "drop") %>%
  transmute(
    geo_type                = "cbsa",
    geo_code                = CBSA_GEOID,
    geo_name                = CBSA_NAME,
    geo_gdp_2022_estimated  = val
  )

# Congressional District GDP (population-weighted)
cd119_gdp <- gdp_cd119 %>%
  transmute(
    geo_type                = "cd119",
    geo_code                = CD119_GEOID,
    geo_name                = CD119_LABEL,
    geo_gdp_2022_estimated  = total_gdp_2022
  )

# Combine all (no region/division)
GEO_LONG_GDP <- bind_rows(
  state_gdp,
  county_gdp_rows,
  cbsa_gdp,
  pea_gdp_rows,
  cd119_gdp
) %>%
  mutate(
    geo_type_standardized = dplyr::recode(
      geo_type,
      "state"   = "State",
      "county"  = "County",
      "cbsa"    = "Metro Area",
      "pea"     = "Economic Area",
      "cd119"   = "Congressional District",
      .default  = NA_character_
    )
  ) %>%
  arrange(geo_type, geo_code) %>%
  fix_df()

# Sanity: unique per (geo_type, geo_code)
assert_unique_by(GEO_LONG_GDP, c("geo_type","geo_code"))

#Glimpse data
cat("\nGEO_LONG_GDP (all geos with GDP):\n"); dplyr::glimpse(GEO_LONG_GDP)

# GEO master + long
geo <- county_2020 %>% mutate(state.fips=as.integer(substr(fips,1,2))) %>% select(state.fips, GeoName, fips, Community) %>%
  left_join(select(states_simple, fips_int, abbr, full), by=c("state.fips"="fips_int")) %>% rename(State.Name=full, state_abbr=abbr) %>%
  left_join(census_divisions, by=c("State.Name","state_abbr")) %>% select(Region, Division, State.Name, state_abbr, state.fips, GeoName, fips, Community) %>%
  left_join(county_cbsa, by="fips") %>% left_join(pea %>% rename(PEA=FCC_PEA_Name), by="fips") %>% left_join(cd_119, by=c("fips"="GEOID")) %>%
  left_join(county_gdp_clean, by="fips") %>% rename(gdp=gdp_2022) %>% left_join(msa_gdp_clean, by=c("CBSA Code"="cbsa_code")) %>% fix_df(); dbg(geo,"geo (master)")

# Print missing GDP counties
missing_gdp_geo <- geo %>% filter(is.na(gdp)) %>% select(GeoName, fips) %>% arrange(GeoName) %>% distinct(GeoName, fips)
cat("\nCounties with missing GDP:\n"); print(missing_gdp_geo, n=Inf)

# Alaska CD fill rule
geo <- geo %>% mutate(cd_119=ifelse(is.na(cd_119) & substr(fips,1,2)=="02", "AK-00", cd_119)) %>% fix_df()

geo_states <- geo %>% select(geo_name=State.Name, geo_code=state.fips) %>% distinct() %>% mutate(geo="State", geo_code=as.character(geo_code)) %>% fix_df(); dbg(geo_states,"geo_states")
geo_counties <- geo %>% select(geo_name=GeoName, geo_code=fips) %>% distinct() %>% mutate(geo="County") %>% fix_df(); dbg(geo_counties,"geo_counties")
geo_cd <- geo %>% select(geo_name=cd_119, geo_code=GEOID_2) %>% distinct() %>% mutate(geo="Congressional District", geo_code=as.character(geo_code)) %>% fix_df(); dbg(geo_cd,"geo_cd")
geo_pea <- geo %>% select(geo_name=PEA, geo_code=FCC_PEA_Number) %>% distinct() %>% mutate(geo="Economic Area", geo_code=as.character(geo_code)) %>% fix_df(); dbg(geo_pea,"geo_pea")

geo_metro <- geo %>% filter(!is.na(`CBSA Code`), !is.na(`CBSA Title`)) %>% distinct(geo_name=`CBSA Title`, geo_code=`CBSA Code`) %>%
  mutate(geo="Metro Area") %>% fix_df(); dbg(geo_metro,"geo_metro")

geo_long <- bind_rows(
  geo %>% transmute(geo_type="State",  geo_name=State.Name, geo_code=as.character(state.fips)),
  geo %>% transmute(geo_type="County", geo_name=GeoName,    geo_code=fips),
  geo %>% transmute(geo_type="Congressional District", geo_name=cd_119, geo_code=as.character(GEOID_2)),
  geo %>% transmute(geo_type="Economic Area", geo_name=PEA, geo_code=as.character(FCC_PEA_Number)),
  geo %>% filter(!is.na(`CBSA Code`), !is.na(`CBSA Title`)) %>% transmute(geo_type="Metro Area", geo_name=`CBSA Title`, geo_code=`CBSA Code`)
) %>% filter(!is.na(geo_name), !is.na(geo_code)) %>% distinct(geo_type, geo_name, geo_code) %>% fix_df(); dbg(geo_long,"geo_long (master)")

# RAW LOADS (download/read/glimpse only; no transforms)
bea_ea_raw <- readxl::read_excel(file.path(paths$raw_data,"BEA Economic Areas and Counties.xls"), sheet=2) %>% fix_df(); dbg(bea_ea_raw,"bea_ea_raw")
congress_119_path <- file.path(paths$raw_data,"congress_119.geojson")
congress_119_raw <- if(file.exists(congress_119_path)) sf::st_read(congress_119_path, quiet=TRUE) else st_as_sf(tibble()); congress_119_raw <- fix_df(congress_119_raw); dbg(congress_119_raw,"congress_119_raw")
ct_fips_changes_raw <- suppressWarnings(read.csv(file.path(paths$ct_fips_data,"geocorr_county_to_county_CT.csv"), skip = 1, check.names=FALSE)) %>% fix_df(); dbg(ct_fips_changes_raw,"ct_fips_changes_raw")
options(tibble.width=Inf, tibble.print_max=Inf); print(ct_fips_changes_raw); options(tibble.width=75, tibble.print_max=10)
census_divisions_raw <- tryCatch(read.csv("https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv"), error=function(e) tibble()) %>% fix_df(); dbg(census_divisions_raw,"census_divisions_raw")

# Clean Investment Monitor (raw CSV drops)
cim_dir <- file.path(paths$raw_data,"clean_investment_monitor_q2_2025")
facilities <- suppressWarnings(read.csv(file.path(cim_dir,"manufacturing_energy_and_industry_facility_metadata.csv"), skip=5, check.names=FALSE)) %>% fix_df(); dbg(facilities,"facilities_raw") 
print(unique(facilities$Current_Facility_Status))
print(unique(facilities$Investment_Status))

# ============================================
# Facilities pipeline — robust, tidy, coverage-first
# Drop-in replacement for everything after facilities_raw dbg()
# ============================================

cat("\n================ FACILITIES PIPELINE (START) ================\n")

# -------------------------------------------------------------------
# Helpers (tiny, fast, reusable) + extra debug wrappers
# -------------------------------------------------------------------
safe_date <- function(x){
  # Handle "mm/dd/yy", "mm/dd/yyyy", ISO; return Date or NA
  suppressWarnings(as.Date(x, tryFormats = c("%m/%d/%y","%m/%d/%Y","%Y-%m-%d")))
}

norm_status <- function(x){
  # Normalize both worded and single-letter status codes
  # Input examples seen:
  #   Current_Facility_Status: "Under Construction","Operating","Retired","Canceled prior to operation","Announced"
  #   Investment_Status: "U","O","R","C","A"
  x0 <- trimws(as.character(x))
  xU <- toupper(x0)
  dplyr::case_when(
    # any canceled/cancelled phrase or code -> "C"
    xU %in% c("C","CANCELED","CANCELLED") | grepl("CANCEL", xU, fixed = TRUE) ~ "C",
    # retired -> "R"
    xU %in% c("R","RETIRED") ~ "R",
    # operating
    xU %in% c("O","OPERATING") ~ "Operating",
    # announced
    xU %in% c("A","ANNOUNCED") ~ "Announced",
    # under construction
    xU %in% c("U","U/C","UNDER CONSTRUCTION") ~ "Under Construction",
    TRUE ~ x0
  )
}

nz_num <- function(x) dplyr::coalesce(suppressWarnings(as.numeric(x)), 0)

dbg_count_na <- function(df, cols, label){
  miss <- sapply(cols, function(cn) if(cn %in% names(df)) sum(is.na(df[[cn]])) else NA_integer_)
  cat("\n-- NA counts:", label, "--\n")
  print(stats::setNames(as.integer(miss), cols))
  invisible(NULL)
}

# -------------------------------------------------------------------
# 1) Spatial geocoding (one pass) with fallbacks & debug
# -------------------------------------------------------------------
cat("\n--- Stage 1: Spatial geocoding ---\n")

# sanity: what unique statuses exist before normalization?
cat("\nUnique Current_Facility_Status (raw):\n"); print(unique(facilities$Current_Facility_Status))
cat("\nUnique Investment_Status (raw):\n");       print(unique(facilities$Investment_Status))

# Build sf points
facilities_sf <- facilities %>%
  dplyr::filter(is.finite(Latitude), is.finite(Longitude)) %>%
  sf::st_as_sf(coords = c("Longitude","Latitude"), crs = 4326, remove = FALSE)

cat("facilities_sf rows:", nrow(facilities_sf), "\n")

# Prep TIGRIS layers
counties_4326 <- tigris_counties_2020_raw %>%
  sf::st_transform(4326) %>%
  dplyr::select(GEOID, STATEFP, NAMELSAD, CBSAFP)

cd_4326 <- tigris_congressional_districts_2024_raw %>%
  sf::st_transform(4326) %>%
  dplyr::select(CD_GEOID = GEOID, CD_NAME = NAMELSAD)

# Join county + CD
fac_geo <- facilities_sf %>%
  sf::st_join(counties_4326, join = sf::st_within) %>%      # county + CBSA code
  sf::st_join(cd_4326,      join = sf::st_within) %>%       # congressional district
  sf::st_drop_geometry() %>%
  dplyr::mutate(
    fips             = GEOID,
    # fallback to provided county_2020_geoid if missing from spatial join
    fips             = dplyr::coalesce(fips, if("county_2020_geoid" %in% names(.)) stringr::str_pad(as.character(county_2020_geoid), 5, pad="0") else NA_character_),
    ann_date         = safe_date(Announcement_Date),
    year_str         = format(ann_date, "%Y"),
    status_now       = norm_status(Current_Facility_Status),
    Investment_Status= norm_status(Investment_Status) # keep name but normalize
  ) %>%
  # bring in friendly names (State, PEA, CBSA title, Region/Division, GDP at county level)
  dplyr::left_join(
    geo %>% 
      dplyr::select(fips, Region, Division, State.Name, state_abbr, GeoName,
                    `CBSA Title`, `CBSA Code`, PEA, FCC_PEA_Number, gdp) %>%
      dplyr::distinct(fips, .keep_all = TRUE) %>%
      dplyr::rename(CBSA.Title = `CBSA Title`, CBSA.Code = `CBSA Code`)
    , by = "fips"
  ) %>%
  # prefer CBSA code from TIGRIS when missing; also fill CBSA title from TIGRIS if we have a CBSA code but no title
  dplyr::mutate(
    CBSA.Code  = dplyr::coalesce(CBSA.Code, CBSAFP)
  ) %>%
  dplyr::left_join(
    tigris_cbsa_2024_raw %>% sf::st_drop_geometry() %>% dplyr::select(CBSA.Code = GEOID, CBSA.Name.2024 = NAMELSAD),
    by = "CBSA.Code"
  ) %>%
  dplyr::mutate(
    CBSA.Title = dplyr::coalesce(CBSA.Title, CBSA.Name.2024)
  ) %>%
  dplyr::mutate(
    # build cd_119 from CD_GEOID; fallback to source's CD119_2024_Name if needed
    cd_119 = {
      cd_raw <- ifelse(is.na(CD_GEOID), "", CD_GEOID)
      statefp_from_cd <- substr(cd_raw, 1, 2)
      cd_num          <- substr(cd_raw, 3, 4)
      ab <- states_simple$abbr[match(statefp_from_cd, states_simple$statefp_chr)]
      cd_built <- ifelse(!is.na(ab) & nzchar(cd_num), paste0(ab, "-", ifelse(cd_num=="00","AL",cd_num)), NA_character_)
      if("CD119_2024_Name" %in% names(.)) dplyr::coalesce(cd_built, .$CD119_2024_Name) else cd_built
    }
  ) %>%
  dplyr::distinct()

# Debug: spatial success
geo_success <- fac_geo %>%
  dplyr::summarise(
    total = dplyr::n(),
    has_county = sum(!is.na(fips)),
    has_cd     = sum(!is.na(cd_119)),
    has_cbsa   = sum(!is.na(CBSA.Code)),
    has_cbsa_title = sum(!is.na(CBSA.Title))
  )
cat("\nSpatial geocoding results:\n"); print(geo_success)
dbg_count_na(fac_geo, c("fips","cd_119","CBSA.Code","CBSA.Title","State.Name","GeoName","PEA"), "fac_geo key columns")

# -------------------------------------------------------------------
# 2) Canonical geo-long scaffold for facilities rows
# -------------------------------------------------------------------
cat("\n--- Stage 2: Build fac_long (tidy, one geo per row) ---\n")

fac_long <- fac_geo %>%
  dplyr::transmute(
    Region, Division, State.Name, GeoName, PEA, CBSA.Title, cd_119,
    Company, Decarb_Sector, Segment, Technology, Subcategory,
    Estimated_Total_Facility_CAPEX = nz_num(Estimated_Total_Facility_CAPEX),
    status_now, Investment_Status, ann_date, year_str, Latitude, Longitude
  ) %>%
  dplyr::mutate(
    industry = dplyr::if_else(Segment == "Manufacturing",
                              paste0(Technology, " Manufacturing"),
                              Technology)
  ) %>%
  tidyr::pivot_longer(
    cols = c(State.Name, cd_119, PEA, CBSA.Title, GeoName),
    names_to = "geo", values_to = "geo_name"
  ) %>%
  dplyr::filter(!is.na(geo_name), nzchar(geo_name)) %>%
  dplyr::mutate(
    geo = dplyr::recode(geo,
                        "State.Name" = "State",
                        "GeoName"    = "County",
                        "CBSA.Title" = "Metro Area",
                        "PEA"        = "Economic Area",
                        "cd_119"     = "Congressional District"
    )
  )

cat("fac_long rows:", nrow(fac_long), "\n")
cat("fac_long unique geos:", paste(unique(fac_long$geo), collapse=", "), "\n")
dbg_count_na(fac_long, c("geo","geo_name","ann_date","Investment_Status","status_now","Estimated_Total_Facility_CAPEX"), "fac_long essentials")

# -------------------------------------------------------------------
# 3) Metric builders (each returns geo, geo_name, …)
# -------------------------------------------------------------------
cat("\n--- Stage 3: Metric builders ---\n")

# Total investment since IRA (by status)
build_total <- function(df){
  out <- df %>%
    dplyr::filter(!is.na(ann_date), ann_date > as.Date("2022-08-15"), Investment_Status != "") %>%
    dplyr::group_by(geo, geo_name, status_now) %>%
    dplyr::summarise(val = sum(Estimated_Total_Facility_CAPEX, na.rm = TRUE), .groups = "drop") %>%
    dplyr::mutate(status_now = dplyr::recode(status_now,
                                             "Operating" = "Operating Investment since IRA",
                                             "Announced" = "Announced Investment since IRA",
                                             "Under Construction" = "Investment under Construction since IRA",
                                             .default = NA_character_
    )) %>%
    dplyr::filter(!is.na(status_now)) %>%
    tidyr::pivot_wider(names_from = status_now, values_from = val, values_fill = 0)
  
  # Ensure columns exist even if absent in data
  for (nm in c("Operating Investment since IRA",
               "Announced Investment since IRA",
               "Investment under Construction since IRA")) {
    if (!nm %in% names(out)) out[[nm]] <- 0
  }
  
  out %>%
    dplyr::mutate(
      total_investment = rowSums(dplyr::across(c(
        `Operating Investment since IRA`,
        `Announced Investment since IRA`,
        `Investment under Construction since IRA`
      )), na.rm = TRUE)
    )
}

# Cleantech manufacturing slice
build_man_total <- function(df){
  out <- df %>%
    dplyr::filter(!is.na(ann_date), ann_date > as.Date("2022-08-15"),
                  Decarb_Sector == "Clean Tech Manufacturing",
                  !Investment_Status %in% c("C","R")) %>%
    dplyr::group_by(geo, geo_name, status_now) %>%
    dplyr::summarise(val = sum(Estimated_Total_Facility_CAPEX, na.rm = TRUE), .groups = "drop") %>%
    dplyr::mutate(status_now = dplyr::recode(status_now,
                                             "Operating" = "Operating Cleantech Manufacturing Investment since IRA",
                                             "Announced" = "Announced Cleantech Manufacturing Investment since IRA",
                                             "Under Construction" = "Cleantech Manufacturing Investment under Construction since IRA",
                                             .default = NA_character_
    )) %>%
    dplyr::filter(!is.na(status_now)) %>%
    tidyr::pivot_wider(names_from = status_now, values_from = val, values_fill = 0)
  
  # Ensure columns exist even if absent in data
  for (nm in c("Operating Cleantech Manufacturing Investment since IRA",
               "Announced Cleantech Manufacturing Investment since IRA",
               "Cleantech Manufacturing Investment under Construction since IRA")) {
    if (!nm %in% names(out)) out[[nm]] <- 0
  }
  
  out %>%
    dplyr::mutate(
      Total_Manufacturing_Investment = rowSums(dplyr::across(c(
        `Operating Cleantech Manufacturing Investment since IRA`,
        `Announced Cleantech Manufacturing Investment since IRA`,
        `Cleantech Manufacturing Investment under Construction since IRA`
      )), na.rm = TRUE)
    )
}

# Technology buckets (inv_*) — 2024/2025 only, non-cancelled
build_tech_buckets <- function(df){
  keep <- c("Solar","Storage","Batteries Manufacturing","Hydrogen",
            "Wind Manufacturing","Zero Emission Vehicles Manufacturing",
            "Solar Manufacturing","Critical Minerals Manufacturing")
  df %>%
    dplyr::filter(!status_now %in% c("C"), year_str %in% c("2024","2025")) %>%
    dplyr::group_by(geo, geo_name, industry) %>%
    dplyr::summarise(Estimated_Total_Facility_CAPEX = sum(Estimated_Total_Facility_CAPEX, na.rm = TRUE), .groups = "drop") %>%
    dplyr::mutate(industry = factor(industry)) %>%
    dplyr::filter(as.character(industry) %in% keep) %>%
    tidyr::pivot_wider(
      names_from = industry,
      values_from = Estimated_Total_Facility_CAPEX,
      values_fill = 0,
      names_prefix = "inv_"
    )
}

# Top 5 technology/subcategory lines since 2024 (string)
build_top5 <- function(df){
  df %>%
    dplyr::filter(!is.na(ann_date), year_str %in% c("2024","2025"), !status_now %in% c("C")) %>%
    dplyr::group_by(geo, geo_name, Segment, Technology, Subcategory) %>%
    dplyr::summarise(val = sum(Estimated_Total_Facility_CAPEX, na.rm = TRUE), .groups = "drop") %>%
    dplyr::mutate(label = dplyr::if_else(Segment=="Manufacturing",
                                         paste0(Subcategory," Manufacturing"),
                                         Subcategory)) %>%
    dplyr::group_by(geo, geo_name) %>%
    dplyr::slice_max(order_by = val, n = 5, with_ties = FALSE) %>%
    dplyr::arrange(geo, geo_name, dplyr::desc(val)) %>%
    dplyr::mutate(rn = dplyr::row_number()) %>%
    dplyr::summarise(
      inv_description = paste0(rn, ". ", label, " ($", round(val, 1), "m)", collapse = ", "),
      .groups = "drop"
    )
}

# Single largest facility since IRA (string)
build_top_facility <- function(df){
  df %>%
    dplyr::filter(!is.na(ann_date), ann_date > as.Date("2022-08-15"),
                  !Investment_Status %in% c("C","R")) %>%
    dplyr::group_by(geo, geo_name) %>%
    dplyr::slice_max(order_by = Estimated_Total_Facility_CAPEX, n = 1, with_ties = FALSE) %>%
    dplyr::ungroup() %>%
    dplyr::mutate(topinv_desc = paste0(
      "In ", format(ann_date, "%Y"), ", ", Company,
      ifelse(status_now == "Operating", " made an investment of ", " announced an investment of "),
      round(Estimated_Total_Facility_CAPEX, 1), " million dollars in a ",
      ifelse(Segment=="Manufacturing", paste0(Technology, " Manufacturing"), Technology), " project."
    )) %>%
    dplyr::select(geo, geo_name, topinv_desc)
}

# Top 3 companies since IRA (string)
build_top_companies <- function(df){
  df %>%
    dplyr::filter(!is.na(ann_date), ann_date > as.Date("2022-08-15"),
                  !Investment_Status %in% c("C","R")) %>%
    dplyr::mutate(Company = gsub("\\([0-9]+\\)", "", Company),
                  Company = gsub(", LLC", "", Company)) %>%
    dplyr::group_by(geo, geo_name, Company) %>%
    dplyr::summarise(val = sum(Estimated_Total_Facility_CAPEX, na.rm = TRUE), .groups = "drop_last") %>%
    dplyr::slice_max(order_by = val, n = 3, with_ties = FALSE) %>%
    dplyr::arrange(dplyr::desc(val), .by_group = TRUE) %>%
    dplyr::summarise(
      top_industries = paste0(Company, " ($", round(val,1), "m)", collapse = ", "),
      .groups = "drop"
    )
}

# -------------------------------------------------------------------
# 4) Build each metric + debug sizes
# -------------------------------------------------------------------
cat("\n--- Stage 4: Compute metrics ---\n")
fac_total   <- build_total(fac_long);    cat("fac_total rows:",   nrow(fac_total),   "cols:", ncol(fac_total),   "\n")
fac_man     <- build_man_total(fac_long);cat("fac_man rows:",     nrow(fac_man),     "cols:", ncol(fac_man),     "\n")
fac_tech    <- build_tech_buckets(fac_long); cat("fac_tech rows:",    nrow(fac_tech),    "cols:", ncol(fac_tech),    "\n")
fac_top5    <- build_top5(fac_long);     cat("fac_top5 rows:",    nrow(fac_top5),    "cols:", ncol(fac_top5),    "\n")
fac_top     <- build_top_facility(fac_long);  cat("fac_top rows:",     nrow(fac_top),     "cols:", ncol(fac_top),     "\n")
fac_company <- build_top_companies(fac_long); cat("fac_company rows:", nrow(fac_company), "cols:", ncol(fac_company), "\n")

# --- Stage 5 (REPLACEMENT): GDP keyed by geo codes, not names ---
lookup_geo <- geo_long %>%
  dplyr::rename(geo = geo_type) %>%
  dplyr::mutate(
    geo_code = dplyr::case_when(
      geo == "State" ~ stringr::str_pad(as.character(geo_code), width = 2, pad = "0"),
      TRUE           ~ as.character(geo_code)
    )
  )

gdp_by_code <- GEO_LONG_GDP %>%
  dplyr::transmute(
    geo = dplyr::recode(geo_type,
                        "state" = "State",
                        "county" = "County",
                        "cbsa" = "Metro Area",
                        "pea" = "Economic Area",
                        "cd119" = "Congressional District",
                        .default = NA_character_),
    geo_code = as.character(geo_code),
    gdp = as.numeric(geo_gdp_2022_estimated)  # BEA CAGDP2 = thousands of dollars
  ) %>%
  dplyr::filter(!is.na(geo))

assert_unique_by(gdp_by_code, c("geo","geo_code"))

# --- Stage 6 (REPLACEMENT): Build scaffold (with codes) and attach metrics + GDP ---
scaffold <- lookup_geo %>%
  dplyr::select(geo, geo_name, geo_code) %>%
  dplyr::distinct()

facilities_all <- scaffold %>%
  dplyr::left_join(fac_total,   by = c("geo","geo_name")) %>%
  dplyr::left_join(fac_man,     by = c("geo","geo_name")) %>%
  dplyr::left_join(fac_tech,    by = c("geo","geo_name")) %>%
  dplyr::left_join(fac_top5,    by = c("geo","geo_name")) %>%
  dplyr::left_join(fac_top,     by = c("geo","geo_name")) %>%
  dplyr::left_join(fac_company, by = c("geo","geo_name")) %>%
  dplyr::left_join(gdp_by_code, by = c("geo","geo_code"))


cat("After joins: facilities_all rows:", nrow(facilities_all), "cols:", ncol(facilities_all), "\n")

# Only coalesce numeric metric columns to zero (keep character text, and keep gdp numeric intact)
facilities_all <- {
  out <- facilities_all
  metric_cols <- c(
    "Operating Investment since IRA",
    "Announced Investment since IRA",
    "Investment under Construction since IRA",
    "total_investment",
    "Operating Cleantech Manufacturing Investment since IRA",
    "Announced Cleantech Manufacturing Investment since IRA",
    "Cleantech Manufacturing Investment under Construction since IRA",
    "Total_Manufacturing_Investment"
  )
  metric_cols <- intersect(metric_cols, names(out))
  
  # detect numeric inv_* columns ONLY
  inv_num_cols <- names(out)[startsWith(names(out), "inv_") & vapply(out, is.numeric, logical(1))]
  cat("Numeric inv_* columns to coalesce:", length(inv_num_cols), "\n")
  
  out %>%
    dplyr::mutate(dplyr::across(dplyr::all_of(metric_cols), ~ dplyr::coalesce(.x, 0))) %>%
    dplyr::mutate(dplyr::across(dplyr::all_of(inv_num_cols), ~ dplyr::coalesce(.x, 0)))
}

# Ratio (unit-corrected) & ranks
# BEA GDP (CAGDP2) is in thousands of dollars; convert to millions for a like-with-like ratio.
facilities_all <- facilities_all %>%
  dplyr::mutate(
    gdp_2022_millions = dplyr::if_else(is.finite(gdp), gdp / 1000, NA_real_),
    inv_gdp = dplyr::if_else(is.finite(gdp_2022_millions) & !is.na(gdp_2022_millions) & gdp_2022_millions > 0,
                             (dplyr::coalesce(total_investment, 0) / gdp_2022_millions) * 100,
                             NA_real_)
  ) %>%
  dplyr::group_by(geo) %>%
  dplyr::mutate(
    Operating_Investment_Rank           = rank(-`Operating Investment since IRA`,               ties.method = "min", na.last = "keep"),
    Total_Investment_Rank               = rank(-total_investment,                               ties.method = "min", na.last = "keep"),
    Total_Manufacturing_Investment_Rank = rank(-Total_Manufacturing_Investment,                 ties.method = "min", na.last = "keep"),
    CAPEX_GDP_Rank                      = rank(-inv_gdp,                                        ties.method = "min", na.last = "keep")
  ) %>%
  dplyr::ungroup()


# Debug: verify types for text columns not coerced
cat("\nType check (inv_description/top_industries should be <chr>):\n")
if("inv_description" %in% names(facilities_all)) cat("  inv_description:", class(facilities_all$inv_description), "\n")
if("top_industries" %in% names(facilities_all))  cat("  top_industries :", class(facilities_all$top_industries),  "\n")

cat("\nfacilities_all built: rows=", nrow(facilities_all), "  cols=", ncol(facilities_all), "\n")
dbg_count_na(facilities_all, c("gdp","total_investment","inv_gdp"), "facilities_all metrics")

# Coverage summary
geo_summary <- facilities_all %>%
  dplyr::group_by(geo) %>%
  dplyr::summarise(count = dplyr::n(), 
                   with_investment = sum(dplyr::coalesce(total_investment,0) > 0, na.rm = TRUE),
                   pct_with_investment = round(100 * with_investment / count, 1),
                   .groups = "drop")
cat("\nCoverage by geo (count / % with any investment):\n"); print(geo_summary)

# Final verification against geo_long counts
final_check <- scaffold %>%
  dplyr::left_join(facilities_all %>% dplyr::select(geo, geo_name) %>% dplyr::distinct(), by = c("geo","geo_name")) %>%
  dplyr::group_by(geo) %>%
  dplyr::summarise(expected = dplyr::n(), found = sum(!is.na(geo_name)), missing = expected - found, .groups = "drop")
cat("\nFinal verification vs geo_long:\n"); print(final_check)

# -------------------------------------------------------------------
# 7) Final per-facility rows for maps (facilities_clean_geo)
# -------------------------------------------------------------------
cat("\n--- Stage 7: facilities_clean_geo (point map rows) ---\n")

facilities_clean_geo <- fac_geo %>%
  dplyr::filter(!is.na(Announcement_Date)) %>%
  dplyr::mutate(announce_date = safe_date(Announcement_Date)) %>%
  dplyr::filter(announce_date > as.Date("2022-08-01")) %>%
  dplyr::select(-dplyr::any_of(c("state_abbr","CBSA.Name.2024"))) %>%
  dplyr::transmute(
    Region, Division,
    State           = State.Name,
    `Economic Area` = PEA,
    `Metro Area`    = CBSA.Title,
    `Congressional District` = cd_119,
    County          = GeoName,
    Company, Decarb_Sector, Technology,
    Estimated_Total_Facility_CAPEX = nz_num(Estimated_Total_Facility_CAPEX),
    Latitude, Longitude
  ) %>%
  dplyr::distinct() %>%
  dplyr::filter(!is.na(Latitude), !is.na(Longitude))

cat("facilities_clean_geo built: rows=", nrow(facilities_clean_geo), "  cols=", ncol(facilities_clean_geo), "\n")
dbg_count_na(facilities_clean_geo, c("State","Economic Area","Metro Area","Congressional District","County","Estimated_Total_Facility_CAPEX"), "facilities_clean_geo NA key fields")

cat("\n================ FACILITIES PIPELINE (END) ================\n")

dbg_count_na(facilities_all, c("gdp","inv_gdp"), "facilities_all final")

#Print out the geo, corresponding geo_name, and corresponding geo_code values of all rows in facilities_all for which gdp is NA/blank
missing_gdp_facilities_all <- facilities_all %>%
  dplyr::filter(is.na(gdp) | gdp == "") %>%
  dplyr::select(geo, geo_name, geo_code, gdp)
cat("\nFacilities_all rows with missing/blank gdp:\n"); print(missing_gdp_facilities_all)



# EIA 860M (latest)
get_latest_eia860m <- function(lookback_months=3, timeout_sec=30){
  base <- as.Date(format(Sys.Date(), "%Y-%m-01")); mon <- seq(base, length.out=lookback_months, by="-1 month")
  urls <- sprintf("https://www.eia.gov/electricity/data/eia860m/xls/%s_generator%s.xlsx", tolower(format(mon,"%B")), format(mon,"%Y"))
  for(u in urls){ r <- try(RETRY("HEAD", u, times=2, quiet=TRUE, terminate_on=c(200,403,404), timeout(timeout_sec)), silent=TRUE)
  if(inherits(r,"response") && status_code(r)==200){ tf <- tempfile(fileext=".xlsx"); RETRY("GET", u, times=2, quiet=TRUE, write_disk(tf, overwrite=TRUE), timeout(timeout_sec)); return(tf) } }
  NA_character_
}
eia860m_path <- get_latest_eia860m(3); eia860m_raw <- if(!is.na(eia860m_path)) tryCatch(readxl::read_excel(eia860m_path, sheet=1, skip=2), error=function(e) tibble()) else tibble(); eia860m_raw <- fix_df(eia860m_raw)
eia_860m_geocoded <- eia860m_raw %>%
  filter(!is.na(Latitude), !is.na(Longitude)) %>%
  st_as_sf(coords=c("Longitude","Latitude"), crs=4326, remove=FALSE) %>%
  st_join(tigris_counties_2020_raw %>% st_transform(4326) %>%
            transmute(COUNTY_GEOID_2020=GEOID, COUNTY_NAME_2020=NAME, COUNTY_NAMELSAD_2020=NAMELSAD),
          join=st_intersects) %>%
  st_join(tigris_congressional_districts_2024_raw %>% st_transform(4326) %>%
            transmute(CD119_GEOID=GEOID), join=st_intersects) %>%
  st_join(tigris_cbsa_2020_raw %>% st_transform(4326) %>%
            transmute(CBSA_2020_CODE=GEOID, CBSA_2020_TITLE=NAME), join=st_intersects) %>%
  st_join(tigris_states_2024_raw %>% st_transform(4326) %>%
            transmute(STATE_ABBR=STUSPS, STATE_NAME=NAME, STATE_FIPS=STATEFP), join=st_intersects) %>%
  st_join(tigris_counties_2024_raw %>% st_transform(4326) %>%
            transmute(COUNTY_GEOID_2024=GEOID, COUNTY_NAME_2024=NAME, COUNTY_NAMELSAD_2024=NAMELSAD),
          join=st_intersects)

glimpse(eia_860m_geocoded)

# ================================================
# EIA 860M > multi-geo capacity panel (audited)
# ================================================

# ---- 0) Setup ----
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(purrr)
  library(sf)
  library(stringr)
  library(readr)
})
options(dplyr.summarise.inform = FALSE)

cat("=== START PIPELINE ===\n")

# Small helpers for auditing
audit_n <- function(df, name) {
  message(sprintf("[AUDIT] %-35s rows=%s, cols=%s", name, nrow(df), ncol(df)))
}
is_blank <- function(x) trimws(x) == "" | is.na(x)
pct <- function(n, d) ifelse(d > 0, round(100 * n / d, 2), NA_real_)

pad2  <- function(x) stringr::str_pad(as.character(x), 2,  pad = "0")
pad4  <- function(x) stringr::str_pad(as.character(x), 4,  pad = "0")
pad5  <- function(x) stringr::str_pad(as.character(x), 5,  pad = "0")
as_chr <- function(x) as.character(x)

# ---- 0.1) Lightweight input audits ----
cat("\n=== INPUT SNAPSHOTS ===\n")
suppressWarnings({
  if (exists("eia_860m_geocoded")) audit_n(eia_860m_geocoded, "eia_860m_geocoded (sf)")
  if (exists("geo_long"))           audit_n(geo_long,           "geo_long")
  if (exists("geo"))                audit_n(geo,                "geo")
})

# ---- 1) County + State + CBSA frame (attributes only) ----
cat("\n=== BUILD county/state/CBSA reference ===\n")

territory_statefps <- c("60", "66", "69", "72", "78")  # AS, GU, MP, PR, VI

tigris_county_state_cbsa_2020 <- tigris_counties_2020_raw %>%
  filter(!STATEFP %in% territory_statefps) %>%
  st_drop_geometry() %>%
  transmute(
    COUNTY_GEOID_2020 = as_chr(GEOID),
    COUNTY_NAME_2020  = NAMELSAD,
    STATEFP           = as_chr(STATEFP),
    CBSAFP            = as_chr(CBSAFP)
  ) %>%
  left_join(
    tigris_states_2024_raw %>%
      st_drop_geometry() %>%
      transmute(
        STATEFP    = as_chr(STATEFP),
        STATE_ABBR = STUSPS,
        STATE_NAME = NAME
      ),
    by = "STATEFP"
  ) %>%
  left_join(
    tigris_cbsa_2020_raw %>%
      #filter(LSAD == "M1") %>%  # metro areas
      st_drop_geometry() %>%
      transmute(
        CBSAFP             = as_chr(GEOID),
        METRO_AREA_NAME_2020 = NAME
      ),
    by = "CBSAFP"
  ) %>%
  # attach FCC PEA attrs by county FIPS
  left_join(
    pea %>% transmute(
      COUNTY_GEOID_2020 = as_chr(fips),
      FCC_PEA_Name,
      FCC_PEA_Number = as.numeric(FCC_PEA_Number)
    ),
    by = "COUNTY_GEOID_2020"
  )

audit_n(tigris_county_state_cbsa_2020, "tigris_county_state_cbsa_2020")

# Quick key audits
n_cty <- n_distinct(tigris_county_state_cbsa_2020$COUNTY_GEOID_2020)
n_st  <- n_distinct(tigris_county_state_cbsa_2020$STATEFP)
n_cbsa_with_name <- sum(!is.na(tigris_county_state_cbsa_2020$METRO_AREA_NAME_2020))
message(sprintf("[AUDIT] County keys: %s unique; States observed: %s; Counties with CBSA: %s (%.2f%%)",
                n_cty, n_st, n_cbsa_with_name, pct(n_cbsa_with_name, n_cty)))

n_pea <- sum(!is.na(tigris_county_state_cbsa_2020$FCC_PEA_Number))
message(sprintf("[AUDIT] Counties with FCC PEA mapping: %s of %s (%.2f%%)",
                n_pea, n_cty, pct(n_pea, n_cty)))

# ---- 2) Congressional Districts (119th) reference ----
cat("\n=== BUILD congressional district (CD119) reference ===\n")

tigris_CD_119 <- tigris_congressional_districts_2024_raw %>%
  st_drop_geometry() %>%
  transmute(
    STATEFP     = as_chr(STATEFP),
    CD119_GEOID = as_chr(GEOID)
  ) %>%
  left_join(
    tigris_states_2024_raw %>%
      st_drop_geometry() %>%
      transmute(
        STATEFP    = as_chr(STATEFP),
        STATE_ABBR = STUSPS,
        STATE_NAME = NAME
      ),
    by = "STATEFP"
  ) %>%
  filter(!STATEFP %in% territory_statefps)

audit_n(tigris_CD_119, "tigris_CD_119")

message(sprintf("[AUDIT] Distinct CD119s: %s; distinct states in CD table: %s",
                n_distinct(tigris_CD_119$CD119_GEOID),
                n_distinct(tigris_CD_119$STATEFP)))

# ---- 3) Clean EIA units & expand to active-by-year ----
cat("\n=== CLEAN EIA units & expand active-by-year ===\n")

eia_units <- eia_860m_geocoded %>%
  st_drop_geometry() %>%
  filter(!is.na(`Operating Year`),
         !is.na(`Nameplate Capacity (MW)`)) %>%
  mutate(
    Technology = tidyr::replace_na(Technology, "Unknown"),
    start_year = as.integer(`Operating Year`),
    nameplate_mw = suppressWarnings(as.numeric(`Nameplate Capacity (MW)`))
  ) %>%
  transmute(
    COUNTY_GEOID_2020 = as_chr(COUNTY_GEOID_2020),
    CD119_GEOID       = as_chr(CD119_GEOID),
    Technology,
    start_year,
    nameplate_mw
  )

audit_n(eia_units, "eia_units (post-clean)")

# Diagnose missing geocodes on EIA rows
miss_cty <- sum(is.na(eia_units$COUNTY_GEOID_2020))
miss_cd  <- sum(is.na(eia_units$CD119_GEOID))
both_miss <- sum(is.na(eia_units$COUNTY_GEOID_2020) & is.na(eia_units$CD119_GEOID))
message(sprintf("[AUDIT] EIA rows missing COUNTY_GEOID_2020: %s (%.2f%%)",
                miss_cty, pct(miss_cty, nrow(eia_units))))
message(sprintf("[AUDIT] EIA rows missing CD119_GEOID: %s (%.2f%%)",
                miss_cd, pct(miss_cd, nrow(eia_units))))
message(sprintf("[AUDIT] EIA rows missing BOTH cty & CD: %s (%.2f%%)",
                both_miss, pct(both_miss, nrow(eia_units))))

# Define year range
min_year <- min(eia_units$start_year, na.rm = TRUE)
max_year <- as.integer(format(Sys.Date(), "%Y"))  # through current calendar year
all_years <- seq(min_year, max_year)

# Active-by-year expansion
tech_levels <- eia_units %>% distinct(Technology) %>% arrange(Technology) %>% pull()

eia_active_by_year <- eia_units %>%
  mutate(Year = purrr::map(start_year, ~seq(.x, max_year))) %>%
  select(-start_year) %>%
  unnest(Year) %>%
  as_tibble()

audit_n(eia_active_by_year, "eia_active_by_year")
message(sprintf("[AUDIT] Technologies: %s; Year span: %s..%s (n=%s)",
                length(tech_levels), min_year, max_year, length(all_years)))

# ---- 4) COUNTY × Technology × Year (zero-filled) ----
cat("\n=== COUNTY × Technology × Year panel ===\n")

county_dim <- tigris_county_state_cbsa_2020 %>%
  select(COUNTY_GEOID_2020, COUNTY_NAME_2020, STATE_ABBR, STATEFP, STATE_NAME,
         CBSAFP, METRO_AREA_NAME_2020, FCC_PEA_Name, FCC_PEA_Number)

audit_n(county_dim, "county_dim")

county_agg <- eia_active_by_year %>%
  filter(!is.na(COUNTY_GEOID_2020)) %>%
  group_by(COUNTY_GEOID_2020, Technology, Year) %>%
  summarise(operational_nameplate_mw = sum(nameplate_mw, na.rm = TRUE), .groups = "drop")

audit_n(county_agg, "county_agg (non-zero universe)")

county_skeleton <- county_dim %>%
  tidyr::crossing(
    tibble(Technology = tech_levels),
    tibble(Year       = all_years)
  )

audit_n(county_skeleton, "county_skeleton (zero-filled universe)")

# Skeleton size check
expected_cty_rows <- nrow(county_dim) * length(tech_levels) * length(all_years)
message(sprintf("[AUDIT] Expected county_skeleton rows = %s; observed = %s",
                format(expected_cty_rows, big.mark=","), format(nrow(county_skeleton), big.mark=",")))

county_capacity_by_tech_year <- county_skeleton %>%
  left_join(county_agg, by = c("COUNTY_GEOID_2020", "Technology", "Year")) %>%
  mutate(operational_nameplate_mw = tidyr::replace_na(operational_nameplate_mw, 0)) %>%
  arrange(COUNTY_GEOID_2020, Technology, Year)

audit_n(county_capacity_by_tech_year, "county_capacity_by_tech_year")

# Share of (still) zeros (this will often be large—diagnostic only)
n_zero_cty <- sum(county_capacity_by_tech_year$operational_nameplate_mw == 0)
message(sprintf("[AUDIT] County×Tech×Year zeros: %s of %s (%.2f%%)",
                format(n_zero_cty, big.mark=","), format(nrow(county_capacity_by_tech_year), big.mark=","),
                pct(n_zero_cty, nrow(county_capacity_by_tech_year))))

# ---- 5) CD119 × Technology × Year (zero-filled) ----
cat("\n=== CD119 × Technology × Year panel ===\n")

cd_dim <- tigris_CD_119 %>%
  select(STATEFP, STATE_ABBR, STATE_NAME, CD119_GEOID)

audit_n(cd_dim, "cd_dim")

cd119_agg <- eia_active_by_year %>%
  filter(!is.na(CD119_GEOID)) %>%
  group_by(CD119_GEOID, Technology, Year) %>%
  summarise(operational_nameplate_mw = sum(nameplate_mw, na.rm = TRUE), .groups = "drop")

audit_n(cd119_agg, "cd119_agg")

cd_skeleton <- cd_dim %>%
  tidyr::crossing(
    tibble(Technology = tech_levels),
    tibble(Year       = all_years)
  )

audit_n(cd_skeleton, "cd_skeleton")

expected_cd_rows <- nrow(cd_dim) * length(tech_levels) * length(all_years)
message(sprintf("[AUDIT] Expected cd_skeleton rows = %s; observed = %s",
                format(expected_cd_rows, big.mark=","), format(nrow(cd_skeleton), big.mark=",")))

cd119_capacity_by_tech_year <- cd_skeleton %>%
  left_join(cd119_agg, by = c("CD119_GEOID", "Technology", "Year")) %>%
  mutate(operational_nameplate_mw = tidyr::replace_na(operational_nameplate_mw, 0)) %>%
  arrange(CD119_GEOID, Technology, Year)

audit_n(cd119_capacity_by_tech_year, "cd119_capacity_by_tech_year")

# ---- 6) Metros, States, PEAs from county panel ----
cat("\n=== Aggregate county panel to Metro, State, PEA ===\n")

metro_area_capacity_by_year <- county_capacity_by_tech_year %>%
  filter(!is.na(CBSAFP)) %>%
  group_by(METRO_AREA_NAME_2020, CBSAFP, Technology, Year) %>%
  summarise(operational_nameplate_mw = sum(operational_nameplate_mw, na.rm = TRUE), .groups = "drop")

state_capacity_by_tech_year <- county_capacity_by_tech_year %>%
  filter(!is.na(STATEFP)) %>%
  group_by(STATE_ABBR, STATEFP, STATE_NAME, Technology, Year) %>%
  summarise(operational_nameplate_mw = sum(operational_nameplate_mw, na.rm = TRUE), .groups = "drop")

economic_area_capacity_by_tech_year <- county_capacity_by_tech_year %>%
  filter(!is.na(FCC_PEA_Name)) %>%
  group_by(FCC_PEA_Name, FCC_PEA_Number, Technology, Year) %>%
  summarise(operational_nameplate_mw = sum(operational_nameplate_mw, na.rm = TRUE), .groups = "drop")

audit_n(metro_area_capacity_by_year,        "metro_area_capacity_by_year")
audit_n(state_capacity_by_tech_year,        "state_capacity_by_tech_year")
audit_n(economic_area_capacity_by_tech_year,"economic_area_capacity_by_tech_year")

# ---- 7) Map Technology → Clean/Fossil/Other ----
tech_to_clean <- function(tech) {
  dplyr::case_when(
    tech %in% c(
      "Conventional Steam Coal",
      "Petroleum Liquids",
      "Petroleum Coke",
      "Natural Gas Steam Turbine",
      "Natural Gas Fired Combined Cycle",
      "Natural Gas Fired Combustion Turbine",
      "Natural Gas Internal Combustion Engine",
      "Other Natural Gas",
      "Other Gases",
      "Coal Integrated Gasification Combined Cycle",
      "Natural Gas with Compressed Air Storage"
    ) ~ "Fossil",
    tech %in% c(
      "Conventional Hydroelectric",
      "Hydroelectric Pumped Storage",
      "Onshore Wind Turbine",
      "Offshore Wind Turbine",
      "Solar Photovoltaic",
      "Solar Thermal with Energy Storage",
      "Solar Thermal without Energy Storage",
      "Geothermal",
      "Batteries",
      "Flywheels",
      "Wood/Wood Waste Biomass",
      "Other Waste Biomass",
      "Landfill Gas",
      "Municipal Solid Waste",
      "Nuclear"
    ) ~ "Clean",
    TRUE ~ "Other"
  )
}

# ---- 8) Build tidy fact tables & keep codes for auditing ----
cat("\n=== Build unified fact table (retain geo_code) ===\n")

# Counties
county_fact <- county_capacity_by_tech_year %>%
  transmute(
    geo       = "County",
    geo_name  = COUNTY_NAME_2020,
    geo_code  = COUNTY_GEOID_2020,            # 5-digit county FIPS
    Technology,
    Year      = as.integer(Year),
    operational_nameplate_mw
  )

# Congressional Districts (119th)
cd_fact <- cd119_capacity_by_tech_year %>%
  mutate(
    district_2 = substr(CD119_GEOID, 3, 4),
    cd_label   = paste0(STATE_ABBR, "-", ifelse(district_2 == "00", "AL", district_2))
  ) %>%
  transmute(
    geo       = "Congressional District",
    geo_name  = cd_label,                      # "AL-06", "AK-AL"
    geo_code  = CD119_GEOID,                   # 4-char GEOID (e.g., "0106")
    Technology,
    Year      = as.integer(Year),
    operational_nameplate_mw
  )

# States
state_fact <- state_capacity_by_tech_year %>%
  transmute(
    geo       = "State",
    geo_name  = STATE_NAME,                    # "Alabama"
    geo_code  = STATEFP,                       # 2-digit FIPS (as chars, e.g., "01")
    Technology,
    Year      = as.integer(Year),
    operational_nameplate_mw
  )

# Metros (CBSA)
metro_fact <- metro_area_capacity_by_year %>%
  transmute(
    geo       = "Metro Area",
    geo_name  = METRO_AREA_NAME_2020,          # "Abilene, TX"
    geo_code  = CBSAFP,                         # 5-digit CBSAFP
    Technology,
    Year      = as.integer(Year),
    operational_nameplate_mw
  )

# Economic Areas (FCC PEA)
pea_fact <- economic_area_capacity_by_tech_year %>%
  transmute(
    geo       = "Economic Area",
    geo_name  = FCC_PEA_Name,                   # "Montgomery, AL"
    geo_code  = as_chr(FCC_PEA_Number),         # numeric → char
    Technology,
    Year      = as.integer(Year),
    operational_nameplate_mw
  )

# Unified fact
fact_all <- bind_rows(county_fact, cd_fact, state_fact, metro_fact, pea_fact)

audit_n(fact_all, "fact_all (all geos x tech x year)")

# ---- 9) Cumulative capacity by geo × technology × year ----
cat("\n=== Compute cumulative capacity ===\n")

fact_all_cum <- fact_all %>%
  arrange(geo, geo_name, Technology, Year) %>%
  group_by(geo, geo_name, geo_code, Technology) %>%
  mutate(cum_cap = cumsum(operational_nameplate_mw)) %>%
  ungroup()

audit_n(fact_all_cum, "fact_all_cum")

# ---- 10) Back-compat "final_results" (retain geo_code) ----
cat("\n=== Build final_results (back-compat shape) ===\n")

final_results <- fact_all_cum %>%
  mutate(clean = tech_to_clean(Technology)) %>%
  # keep only Clean/Fossil to mirror legacy behavior
  filter(clean %in% c("Clean", "Fossil")) %>%
  transmute(
    # legacy columns by geo "slot"
    State.Name = ifelse(geo == "State", geo_name, NA_character_),
    cd_119     = ifelse(geo == "Congressional District", geo_name, NA_character_),
    PEA        = ifelse(geo == "Economic Area", geo_name, NA_character_),
    CBSA.Title = ifelse(geo == "Metro Area", geo_name, NA_character_),
    GeoName    = ifelse(geo == "County", geo_name, NA_character_),
    
    # added: carry geo metadata for audits
    geo        = geo,
    geo_name   = geo_name,
    geo_code   = geo_code,
    
    `Operating Year` = as.character(Year),
    Technology,
    clean,
    cum_cap
  )

audit_n(final_results, "final_results")

# ---- 11) rengen (Clean vs Fossil snapshots + metrics) ----
cat("\n=== Build rengen snapshots ===\n")

snap_years <- c(2019L, 2021L, 2024L)          # adjust if needed
year_univ  <- unique(as.integer(fact_all_cum$Year))
snap_years <- snap_years[snap_years %in% year_univ]  # guard if early data

safe_div <- function(num, den) ifelse(is.finite(num/den), num/den, NA_real_)

rengen <- final_results %>%
  group_by(
    geo,             # use geo and geo_code for precise identity
    geo_code,
    geo_name,
    clean,
    `Operating Year`
  ) %>%
  summarise(cum_cap = sum(cum_cap, na.rm = TRUE), .groups = "drop") %>%
  filter(!is_blank(geo_name)) %>%
  filter(`Operating Year` %in% as.character(snap_years)) %>%
  tidyr::pivot_wider(names_from = `Operating Year`, values_from = cum_cap) %>%
  mutate(
    change_19_24  = if ("2019" %in% names(.)) round(`2024` - `2019`, 1) else NA_real_,
    growth_19_24  = if ("2019" %in% names(.)) round(100 * safe_div(`2024`, `2019`) - 100, 1) else NA_real_,
    change_21_24  = if ("2021" %in% names(.)) round(`2024` - `2021`, 1) else NA_real_,
    growth_21_24  = if ("2021" %in% names(.)) round(100 * safe_div(`2024`, `2021`) - 100, 1) else NA_real_ 
  ) %>%
  select(-any_of(c("2019", "2021"))) %>%
  tidyr::pivot_wider(
    names_from  = clean,
    values_from = c(`2024`, growth_19_24, change_19_24, growth_21_24, change_21_24),
    names_sep   = "_"
  ) %>%
  mutate(`2024_Fossil` = dplyr::coalesce(`2024_Fossil`, 0)) %>%
  mutate(clean_share   = round(100 * safe_div(`2024_Clean`, (`2024_Clean` + `2024_Fossil`)), 1)) %>%
  arrange(geo, geo_name)

audit_n(rengen, "rengen (one row per geography)")

# ---- 12) Tech-cap snapshots (2014/2021/2024 deltas) ----
cat("\n=== Build tech_cap snapshots ===\n")

tech_cap <- final_results %>%
  group_by(geo, geo_code, geo_name, Technology, `Operating Year`) %>%
  summarise(cum_cap = sum(cum_cap, na.rm = TRUE), .groups = "drop") %>%
  filter(!is_blank(geo_name)) %>%
  filter(`Operating Year` %in% c("2014", "2021", "2024")) %>%
  tidyr::pivot_wider(names_from = `Operating Year`, values_from = cum_cap) %>%
  mutate(
    growth_14_24 = round(`2024` - `2014`, 1),
    growth_21_24 = round(`2024` - `2021`, 1)
  ) %>%
  arrange(geo, geo_name, Technology)

audit_n(tech_cap, "tech_cap")

# ======================================================
# 13) **KEY AUDITS** vs geo_long (counts & mismatches)
# ======================================================
cat("\n=== AUDITS vs geo_long (counts & mismatches) ===\n")

# Normalize codes for reliable matching across sources
normalize_geo_code <- function(geo_type, code) {
  # Returns a normalized code string per geo type
  dplyr::case_when(
    geo_type == "State"                  ~ pad2(code),      # "01"
    geo_type == "County"                 ~ pad5(code),      # "01001"
    geo_type == "Congressional District" ~ pad4(code),      # "0106"
    geo_type == "Metro Area"             ~ pad5(code),      # "10180"
    geo_type == "Economic Area"          ~ as_chr(as.integer(code)), # "164"
    TRUE ~ as_chr(code)
  )
}

# (A) Build a registry of geographies inside rengen
rengen_geos <- rengen %>%
  transmute(
    geo_type = geo,
    geo_name,
    geo_code = geo_code
  ) %>%
  distinct()

audit_n(rengen_geos, "rengen_geos (registry)")

# (B) Ensure geo_long uses consistent column names & normalize codes
if (!all(c("geo_type", "geo_name", "geo_code") %in% names(geo_long))) {
  stop("geo_long must have columns: geo_type, geo_name, geo_code")
}

geo_long_norm <- geo_long %>%
  mutate(
    geo_code_norm = normalize_geo_code(geo_type, geo_code)
  ) %>%
  distinct(geo_type, geo_name, geo_code = geo_code_norm)

audit_n(geo_long_norm, "geo_long_norm")

# (C) Normalize codes inside rengen too
rengen_geos_norm <- rengen_geos %>%
  mutate(geo_code_norm = normalize_geo_code(geo_type, geo_code)) %>%
  transmute(geo_type, geo_name, geo_code = geo_code_norm) %>%
  distinct()

audit_n(rengen_geos_norm, "rengen_geos_norm")

# (D) Count by type
counts_geo_long <- geo_long_norm %>%
  count(geo_type, name = "n_geo_long") %>% arrange(geo_type)

counts_rengen <- rengen_geos_norm %>%
  count(geo_type, name = "n_rengen") %>% arrange(geo_type)

counts_join <- counts_geo_long %>%
  full_join(counts_rengen, by = "geo_type") %>%
  replace_na(list(n_geo_long = 0L, n_rengen = 0L)) %>%
  mutate(delta = n_rengen - n_geo_long)

print(counts_join)

# (E) Overall counts (this fixes your original error: use geo_type, not 'geo')
geo_long_count <- geo_long_norm %>%
  filter(!is_blank(geo_name)) %>%
  distinct(geo_type, geo_name) %>%
  nrow()

rengen_count <- rengen_geos_norm %>%
  distinct(geo_type, geo_name) %>%
  nrow()

cat("\n--- Overall distinct geographies ---\n")
cat("geo_long distinct (geo_type, geo_name): ", geo_long_count, "\n", sep = "")
cat("rengen   distinct (geo_type, geo_name): ", rengen_count,    "\n", sep = "")

# (F) Set differences by type (where, how, why)
by_type <- sort(unique(c(geo_long_norm$geo_type, rengen_geos_norm$geo_type)))

for (gt in by_type) {
  cat("\n[CHECK] Geo type: ", gt, "\n", sep = "")
  lhs <- geo_long_norm  %>% filter(geo_type == gt)
  rhs <- rengen_geos_norm %>% filter(geo_type == gt)
  
  # By code is more reliable than by name (names differ e.g., "Autauga County" vs "Autauga County, Alabama")
  only_in_geo_long <- anti_join(lhs, rhs, by = c("geo_type", "geo_code"))
  only_in_rengen   <- anti_join(rhs, lhs, by = c("geo_type", "geo_code"))
  
  cat(sprintf("  - In geo_long not in rengen: %s\n", nrow(only_in_geo_long)))
  cat(sprintf("  - In rengen   not in geo_long: %s\n", nrow(only_in_rengen)))
  
  # Print small samples to understand *why*
  if (nrow(only_in_geo_long) > 0) {
    cat("    * Sample missing from rengen:\n")
    print(head(only_in_geo_long, 10))
  }
  if (nrow(only_in_rengen) > 0) {
    cat("    * Sample missing from geo_long:\n")
    print(head(only_in_rengen, 10))
  }
}

glimpse(rengen)

# ==============================================================
# Electricity grid → geographies with 100% coverage of geo_long
#  - Zero NAs / NaNs in key metrics
#  - Every row in `geo_long` receives a value (impute if needed)
# ==============================================================
# -----------------------
# Helpers / configuration
# -----------------------
DEBUG <- TRUE
dcat <- function(...) if (DEBUG) cat(...)
dbg  <- function(x, title = deparse(substitute(x))) {
  if (!DEBUG) return(invisible(NULL))
  cat("\n====", title, "====\n", sep = " ")
  if (inherits(x, "sf")) {
    cat("Rows:", nrow(x), " Cols:", ncol(x), "  CRS:", sf::st_crs(x)$epsg, "\n")
    print(head(as.data.frame(sf::st_drop_geometry(x)), 3), row.names = FALSE)
  } else {
    cat("Rows:", nrow(x), " Cols:", ncol(x), "\n")
    print(dplyr::glimpse(x, width = 80))
  }
  invisible(NULL)
}
norm_key <- function(x) x %>%
  toupper() %>%
  str_replace_all("&", "AND") %>%
  str_replace_all("PUD NO\\.", "PUBLIC UTILITY DISTRICT NO.") %>%
  str_replace_all("[^A-Z0-9 ]+", " ") %>%
  str_squish()

pick_col <- function(df, pat){
  nm <- names(df)
  h  <- nm[str_detect(nm, regex(pat, TRUE))]
  ifelse(length(h), h[1], NA_character_)
}

# Safe weighted mean: if weights are all zero/NA → fall back to unweighted mean.
wmean_safe <- function(x, w){
  if (length(x) == 0) return(NA_real_)
  w <- replace_na(w, 0)
  if (all(is.na(x))) return(NA_real_)
  sw <- sum(w, na.rm = TRUE)
  if (is.na(sw) || sw == 0) {
    mean(x, na.rm = TRUE)
  } else {
    stats::weighted.mean(x, w, na.rm = TRUE)
  }
}
# ---------------
# Preconditions
# ---------------
territory_path <- nz_chr(Sys.getenv("ELECTRIC_TERRITORIES_SHP")); if(is.na(territory_path)){ cand <- file.path(paths$raw_data,"Electric_Retail_Service_Territories.shp"); territory_path <- if(file.exists(cand)) cand else NA_character_ }
retail_territories_raw <- st_read(territory_path); cat("Glimpse of retail_territories_raw..."); glimpse(retail_territories_raw)

need <- c("retail_territories_raw", "tigris_counties_2020_raw", "geo", "geographies",
          "county_gdp_clean", "geo_long")
miss <- need[!sapply(need, exists)]
if (length(miss)) stop("Missing required objects in environment: ", paste(miss, collapse = ", "))

# Normalize some column names that sometimes vary
if ("CBSA Title" %in% names(geo) && !("CBSA.Title" %in% names(geo))) {
  geo <- dplyr::rename(geo, CBSA.Title = `CBSA Title`)
}
if ("CBSA Code" %in% names(geo) && !("CBSA.Code" %in% names(geo))) {
  geo <- dplyr::rename(geo, CBSA.Code = `CBSA Code`)
}

# -------------------------------
# 1) Electricity Maps 2024 (raw)
# -------------------------------
zones <- c(
  "US-CAR-YAD","US-SW-AZPS","US-MIDW-AECI","US-NW-AVA","US-CAL-BANC","US-NW-BPAT",
  "US-CAL-CISO","US-NW-TPWR","US-FLA-TAL","US-CAR-DUK","US-FLA-FPC","US-CAR-CPLE",
  "US-CAR-CPLW","US-SW-EPE","US-TEX-ERCO","US-FLA-FMPP","US-FLA-FPL","US-FLA-GVL",
  "US-NW-GRID","US-NW-IPCO","US-CAL-IID","US-NE-ISNE","US-FLA-JEA","US-CAL-LDWP",
  "US-MIDW-LGEE","US-MIDW-MISO","US-NW-NEVP","US-NY-NYIS","US-NW-NWMT","US-MIDA-PJM",
  "US-NW-CHPD","US-NW-DOPD","US-NW-GCPD","US-NW-PACE","US-NW-PACW","US-NW-PGE",
  "US-NW-PSCO","US-SW-PNM","US-NW-PSEI","US-SW-SRP","US-NW-SCL","US-FLA-SEC",
  "US-CAR-SCEG","US-CAR-SC","US-SE-SOCO","US-CENT-SWPP","US-CENT-SPA","US-FLA-TEC",
  "US-TEN-TVA","US-SW-TEPC","US-CAL-TIDC","US-SW-WALC","US-NW-WACM","US-NW-WAUW"
)

em_list <- lapply(zones, function(z){
  u <- paste0("https://data.electricitymaps.com/2025-01-27/", z, "_2024_yearly.csv")
  tryCatch(read.csv(u, check.names = FALSE), error = function(e) tibble(zone = z, err = as.character(e)))
})
electricity_maps_2024_raw <- bind_rows(em_list) %>% fix_df()
dbg(electricity_maps_2024_raw, "electricity_maps_2024_raw")

# -------------------------------
# 2) Retail territories → counties
# -------------------------------
# Re-wrap as sf (tell sf which column is geometry, and carry over the CRS from the sfc column)
counties_sf <- st_as_sf(
  tigris_counties_2020_raw,
  sf_column_name = "geometry",
  crs = st_crs(tigris_counties_2020_raw$geometry)
)

# Now you can transform safely
counties_sf <- st_transform(counties_sf, 4326)

dcat("[DEBUG] counties CRS:", st_crs(counties_sf)$epsg, "\n")

territories_to_county <- retail_territories_raw %>%
  st_transform(st_crs(counties_sf)) %>%
  st_make_valid()

sf::sf_use_s2(FALSE)
territories_to_county <- st_join(territories_to_county, counties_sf, join = st_intersects)
sf::sf_use_s2(TRUE)

territories_to_county <- territories_to_county %>%
  st_drop_geometry() %>%
  transmute(
    GEOID = sprintf("%05d", as.integer(GEOID)),
    CNTRL_AREA = norm_key(CNTRL_AREA)
  ) %>%
  distinct()

# ----------------------------------------
# 3) Clean Electricity Maps zone metadata
# ----------------------------------------
ci_col  <- pick_col(electricity_maps_2024_raw, "^Carbon\\s*Intensity.*\\(direct\\)$")
ren_col <- pick_col(electricity_maps_2024_raw, "^Renewable[\\._ ]*Percentage$")
if (any(is.na(c(ci_col, ren_col)))) stop("Could not find CI/Renewable columns in electricity_maps_2024_raw.")

emap_fix <- c(
  "Northwestern Energy"="NORTHWESTERN ENERGY (NWMT)",
  "Duke Energy Progress West"="DUKE ENERGY PROGRESS WEST",
  "Gridforce Energy Management, LLC"="GRIDFORCE ENERGY MANAGEMENT LLC",
  "Jacksonville Electric Authority"="JEA",
  "Midcontinent Independent Transmission System Operator, Inc."="MIDCONTINENT INDEPENDENT TRANSMISSION SYSTEM OPERATOR, INC.",
  "PUD No. 1 of Chelan County"="PUBLIC UTILITY DISTRICT NO. 1 OF CHELAN COUNTY",
  "PUD No. 2 of Grant County, Washington"="PUBLIC UTILITY DISTRICT NO. 2 OF GRANT COUNTY, WASHINGTON",
  "Pacificorp East"="PACIFICORP - EAST",
  "Pacificorp West"="PACIFICORP - WEST"
)

em24 <- electricity_maps_2024_raw %>%
  rename(`Zone Name` = any_of(c("Zone Name","Zone.Name")),
         `Zone Id`   = any_of(c("Zone Id","Zone.Id"))) %>%
  mutate(
    `Zone Name`    = coalesce(emap_fix[`Zone Name`], `Zone Name`),
    cntrl_area_key = norm_key(`Zone Name`),
    ci_direct      = suppressWarnings(as.numeric(.data[[ci_col]])),
    ren_share      = suppressWarnings(as.numeric(.data[[ren_col]]))
  ) %>%
  select(`Zone Id`,`Zone Name`,cntrl_area_key,ci_direct,ren_share)

# ------------------------------------------------------
# 4) GDP weights (county-level)
#     - pick most recent GDP col; normalize to 5-char FIPS
# ------------------------------------------------------
gdp_cols <- grep("^gdp_\\d{4}$|^gdp$", names(county_gdp_clean), value = TRUE)
if (!length(gdp_cols)) stop("county_gdp_clean must have a 'gdp' or 'gdp_YYYY' column.")
gdp_col <- gdp_cols[order(gdp_cols, decreasing = TRUE)][1]

gdp_county_final <- county_gdp_clean %>%
  mutate(fips = sprintf("%05d", as.integer(.data[["fips"]]))) %>%
  transmute(GEOID = fips, gdp = as.numeric(.data[[gdp_col]])) %>%
  group_by(GEOID) %>%
  summarise(gdp = sum(gdp, na.rm = TRUE), .groups = "drop")

dbg(gdp_county_final, "gdp_county_final")

# ------------------------------------------------------
# 5) Build per-county join table with attributes + GDP
# ------------------------------------------------------
em_counties <- territories_to_county %>%
  inner_join(em24, by = c("CNTRL_AREA" = "cntrl_area_key")) %>%
  left_join(select(geo, fips, State.Name, cd_119, percent_district, PEA, CBSA.Title, GeoName, gdp),
            by = c("GEOID" = "fips")) %>%
  left_join(gdp_county_final %>% rename(gdp_county = gdp), by = "GEOID") %>%
  mutate(
    gdp_any = coalesce(gdp, gdp_county, 0)
  )

# ------------------------------------------------------
# 6) Primary aggregation (fast path)
#     - zero-weight → unweighted fallback
# ------------------------------------------------------
agg_one <- function(key){
  if (!key %in% names(em_counties)) return(NULL)
  df <- filter(em_counties, !is.na(.data[[key]]))
  
  if (key == "cd_119") {
    df %>%
      group_by(.data[[key]]) %>%
      summarise(
        `Electricity Consumption Carbon Intensity (CO2eq/kWh)` =
          wmean_safe(ci_direct, replace_na(gdp_county, 0) * replace_na(percent_district, 0) / 100),
        `Electricity Consumption Renewable Percentage` =
          wmean_safe(ren_share,  replace_na(gdp_county, 0) * replace_na(percent_district, 0) / 100),
        .groups = "drop"
      )
  } else {
    df %>%
      distinct(.data[[key]], ci_direct, ren_share, gdp_any) %>%
      group_by(.data[[key]]) %>%
      summarise(
        `Electricity Consumption Carbon Intensity (CO2eq/kWh)` =
          wmean_safe(ci_direct, replace_na(gdp_any, 0)),
        `Electricity Consumption Renewable Percentage` =
          wmean_safe(ren_share,  replace_na(gdp_any, 0)),
        .groups = "drop"
      )
  }
}

elec_grid <- bind_rows(lapply(geographies, agg_one)) %>%
  ungroup() %>%
  mutate(
    geo      = case_when(!is.na(State.Name) ~ "State",
                         !is.na(cd_119)     ~ "Congressional District",
                         !is.na(PEA)        ~ "Economic Area",
                         !is.na(GeoName)    ~ "County",
                         !is.na(CBSA.Title) ~ "Metro Area",
                         TRUE               ~ NA_character_),
    geo_name = coalesce(State.Name, cd_119, PEA, GeoName, CBSA.Title)
  ) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  select(-State.Name, -cd_119, -PEA, -CBSA.Title, -GeoName)

# ------------------------------------------------------
# 7) Coverage backstop stage (guarantee 100% of geo_long)
#     A) Build county-level metrics (per GEOID)
#     B) For any missing (geo_type, geo_name) in geo_long,
#        re-aggregate from its member counties using GDP weights.
#        If still empty, fall back to state average; else national.
# ------------------------------------------------------

# A) County metrics (if multiple BAs touch a county, equal-share fallback)
county_metrics <- em_counties %>%
  group_by(GEOID) %>%
  summarise(
    # Equal-share of BAs within a county (no intra-county BA loads available)
    ci_direct_cm = mean(ci_direct, na.rm = TRUE),
    ren_share_cm = mean(ren_share, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  left_join(gdp_county_final, by = "GEOID")

# Precompute State-level fallback from counties (robust everywhere)
# Join state name to counties via `geo`
state_by_county <- geo %>%
  select(fips, State.Name) %>%
  mutate(fips = sprintf("%05d", as.integer(fips))) %>%
  distinct()

state_metrics <- county_metrics %>%
  left_join(state_by_county, by = c("GEOID" = "fips")) %>%
  filter(!is.na(State.Name)) %>%
  group_by(State.Name) %>%
  summarise(
    ci_state = wmean_safe(ci_direct_cm, gdp),
    ren_state = wmean_safe(ren_share_cm, gdp),
    .groups = "drop"
  )

# National fallback
national_metrics <- county_metrics %>%
  summarise(
    ci_nat  = wmean_safe(ci_direct_cm, gdp),
    ren_nat = wmean_safe(ren_share_cm, gdp)
  )

# Helper: list counties (GEOIDs) for each geo type/name using `geo`
geo_col_map <- c(
  "State"                  = "State.Name",
  "Congressional District" = "cd_119",
  "Economic Area"          = "PEA",
  "County"                 = "GeoName",
  "Metro Area"             = "CBSA.Title"
)

counties_for_geo <- function(geo_type, geo_name) {
  key <- geo_col_map[[geo_type]]
  if (is.na(key) || !key %in% names(geo)) return(character(0))
  geo %>%
    filter(.data[[key]] == geo_name) %>%
    transmute(GEOID = sprintf("%05d", as.integer(fips))) %>%
    distinct(GEOID) %>%
    pull(GEOID)
}

# Aggregation from a set of counties with GDP weights; fallbacks if needed
agg_from_counties <- function(geo_type, geo_name) {
  geos <- counties_for_geo(geo_type, geo_name)
  # If we can't find counties directly, try to infer state and fall back
  if (!length(geos)) {
    # Try state-level by name (works if geo_type == "State")
    if (geo_type == "State") {
      st_row <- state_metrics %>% filter(State.Name == geo_name)
      if (nrow(st_row)) {
        return(tibble(
          `Electricity Consumption Carbon Intensity (CO2eq/kWh)` = st_row$ci_state[1],
          `Electricity Consumption Renewable Percentage` = st_row$ren_state[1]
        ))
      }
    }
    return(tibble(
      `Electricity Consumption Carbon Intensity (CO2eq/kWh)` = national_metrics$ci_nat[1],
      `Electricity Consumption Renewable Percentage` = national_metrics$ren_nat[1]
    ))
  }
  
  df <- county_metrics %>% filter(GEOID %in% geos)
  if (!nrow(df)) {
    # County list exists but we have no county metrics → fallback to state or national
    # Try majority state among the counties
    st_mode <- geo %>%
      filter(fips %in% as.integer(geos)) %>%
      count(State.Name, sort = TRUE) %>%
      slice_head(n = 1) %>%
      pull(State.Name)
    if (length(st_mode) && st_mode %in% state_metrics$State.Name) {
      st_row <- state_metrics %>% filter(State.Name == st_mode)
      return(tibble(
        `Electricity Consumption Carbon Intensity (CO2eq/kWh)` = st_row$ci_state[1],
        `Electricity Consumption Renewable Percentage` = st_row$ren_state[1]
      ))
    }
    return(tibble(
      `Electricity Consumption Carbon Intensity (CO2eq/kWh)` = national_metrics$ci_nat[1],
      `Electricity Consumption Renewable Percentage` = national_metrics$ren_nat[1]
    ))
  }
  
  tibble(
    `Electricity Consumption Carbon Intensity (CO2eq/kWh)` = wmean_safe(df$ci_direct_cm, df$gdp),
    `Electricity Consumption Renewable Percentage`         = wmean_safe(df$ren_share_cm, df$gdp)
  )
}

# Identify coverage gap against geo_long
# geo_long columns: geo_type, geo_name, geo_code
elec_key <- elec_grid %>% transmute(geo, geo_name)
target_key <- geo_long %>% transmute(geo = geo_type, geo_name)

missing_keys <- anti_join(target_key, elec_key, by = c("geo","geo_name")) %>% distinct()

# Compute backstop values and bind
if (nrow(missing_keys)) {
  backstop_vals <- missing_keys %>%
    mutate(agg = map2(geo, geo_name, agg_from_counties)) %>%
    unnest(agg)
  
  elec_grid <- elec_grid %>%
    bind_rows(backstop_vals)
}

# Final tidy + ranks
elec_grid <- elec_grid %>%
  group_by(geo) %>%
  mutate(
    `Grid Carbon Intensity Rank`      = rank(-`Electricity Consumption Carbon Intensity (CO2eq/kWh)`, ties.method = "first"),
    `Grid Renewables Percentage Rank` = rank(-`Electricity Consumption Renewable Percentage`,          ties.method = "first")
  ) %>%
  ungroup()

# ---------------------------------
# 8) Hard guarantees / validations
# ---------------------------------
# Ensure the set of (geo, geo_name) matches geo_long exactly
elec_grid <- elec_grid %>%
  semi_join(target_key, by = c("geo","geo_name"))

# Assert: 100% coverage and no NA/NaN in key metrics
key_na <- elec_grid %>%
  filter(is.na(`Electricity Consumption Carbon Intensity (CO2eq/kWh)`) |
           is.na(`Electricity Consumption Renewable Percentage`) |
           is.nan(`Electricity Consumption Carbon Intensity (CO2eq/kWh)`) |
           is.nan(`Electricity Consumption Renewable Percentage`))
if (nrow(key_na)) {
  stop("Post-backstop still has NA/NaN metrics. Investigate unexpected gaps.")
}

gap <- anti_join(target_key, elec_grid %>% select(geo, geo_name), by = c("geo","geo_name"))
if (nrow(gap)) {
  stop("Coverage gap remains after backstop (unexpected). Missing examples: ",
       paste(utils::head(paste(gap$geo, gap$geo_name, sep = " = "), 10), collapse = "; "), " …")
}

cat("\n[OK] 100% coverage of geo_long with zero NA/NaN in key metrics.\n")
dbg(elec_grid, "elec_grid (final, 100% coverage)")

# =====================================================================
# CBP 2023 pipeline → manshare + manpay_geo (aligned to geo_long)
# =====================================================================

# --- Utilities ---------------------------------------------------------------
suppressPackageStartupMessages({
  library(dplyr); library(tidyr); library(stringr); library(sf)
})
options(dplyr.summarise.inform = FALSE)

soft_assert <- function(ok, msg) { if (!ok) message("⚠️ ", msg); invisible(ok) }
to_num      <- function(x) suppressWarnings(as.numeric(x))
norm_name   <- function(x) stringr::str_squish(x)
territory_state_fips <- c("60","66","69","72","78")  # AS, GU, MP, PR, VI

# Strip plain ASCII quotes added by some CSV/logging paths
strip_outer_quotes <- function(x) stringr::str_replace_all(x, '^"+|"+$', '')

# Remove C0/C1 control chars (keeps \t, \n if desired; here we drop all)
strip_control_bytes <- function(x) stringr::str_replace_all(x, "[\\x00-\\x1F\\x7F-\\x9F]", "")

# Classic single-pass mojibake fixes seen in Puerto Rico + misc.
fix_mojibake_simple <- function(x) {
  repl <- c(
    "Do√±a"      = "Doña",
    "Pe√±uelas"  = "Peñuelas",
    "A√±asco"    = "Añasco",
    "Mayag√ºez"  = "Mayagüez",
    "Rinc√ón"    = "Rincón",
    "Cata√±o"    = "Cataño",
    "Lo√≠za"     = "Loíza",
    "Manat√í"    = "Manatí",
    "R√≠o"       = "Río",
    "Germ√án"    = "Germán",
    # Common non‑PR offenders we’re seeing
    "Ca√±on"     = "Cañon",
    "Espa√±ola"  = "Española"
  )
  stringr::str_replace_all(x, repl)
}

# Attempt to repair "UTF‑8 seen as Latin‑1/Windows‑1252" by round‑tripping
fix_reencode_once <- function(x) {
  y1 <- suppressWarnings(iconv(iconv(x, from = "UTF-8", to = "latin1"),        from = "latin1",        to = "UTF-8"))
  y2 <- suppressWarnings(iconv(iconv(x, from = "UTF-8", to = "windows-1252"),  from = "windows-1252",  to = "UTF-8"))
  bad_ct <- function(s) stringr::str_count(s, "[ÃÂâ√]")
  choose <- ifelse(bad_ct(y2) < bad_ct(y1), y2, y1)
  choose[is.na(choose)] <- x[is.na(choose)]
  choose
}

# Full text fixer: quotes/control → re-encode (twice) → simple fixes → squish
fix_text <- function(x) {
  if (is.null(x)) return(x)
  x <- as.character(x)
  x <- strip_outer_quotes(x)
  x <- strip_control_bytes(x)
  x <- fix_reencode_once(x)
  x <- fix_reencode_once(x)
  x <- fix_mojibake_simple(x)
  x <- norm_name(x)
  x
}

# ASCII transliteration for compare keys
strip_diacritics <- function(x) { y <- suppressWarnings(iconv(x, to = "ASCII//TRANSLIT")); ifelse(is.na(y), x, y) }

# Compare key: always run through fix_text first
name_cmp <- function(x) norm_name(strip_diacritics(fix_text(x)))

# Format numeric to string with blanks for NA
fmt_num <- function(x, digits = NULL) {
  if (!is.null(digits) && is.numeric(x)) x <- round(x, digits)
  ifelse(is.na(x), "", as.character(x))
}

# Small helper for concise debug dumps
print_mismatches <- function(df, heading, nmax = 200) {
  cat("\n---", heading, "---\n")
  cat("Count:", nrow(df), "\n")
  if (nrow(df) > 0) {
    if (nrow(df) > nmax) {
      cat("(showing first", nmax, ")\n")
      print(df %>% transmute(geo_type, geo_name) %>% head(nmax), n=nmax)
    } else {
      print(df %>% transmute(geo_type, geo_name), n=Inf)
    }
  }
}

# Targeted text diagnostics
debug_text_issues <- function(df, label, col = "geo_name", n = 10) {
  v <- df[[col]]
  pat_bad <- "[ÃÂâ√]|\\\\u00"
  idx_bad <- which(stringr::str_detect(v, pat_bad))
  if (length(idx_bad) > 0) {
    cat("\n--- Text diagnostics:", label, "---\n")
    cat("Rows with suspected mojibake:", length(idx_bad), "\n")
    print(df[idx_bad, , drop=FALSE] %>% dplyr::select(any_of(col)) %>% head(n), n=Inf)
  }
}

# --- Robust column-detection helpers ------------------------------------------
norm_cols <- function(nms) gsub("[^a-z0-9]+", "", tolower(nms))

find_col <- function(df, candidates = character(), keywords = character(), label = "column", required = TRUE) {
  nms      <- names(df)
  nms_norm <- norm_cols(nms)
  
  # 1) exact match on normalized candidates
  for (cand in candidates) {
    c_norm <- norm_cols(cand)
    hit <- which(nms_norm == c_norm)
    if (length(hit) == 1) {
      cat("•", label, "→", nms[hit], "(exact)\n")
      return(nms[hit])
    }
  }
  # 2) partial match on candidates
  for (cand in candidates) {
    c_norm <- norm_cols(cand)
    hit <- which(stringr::str_detect(nms_norm, fixed(c_norm)))
    if (length(hit) == 1) {
      cat("•", label, "→", nms[hit], "(partial)\n")
      return(nms[hit])
    }
  }
  # 3) all-keyword containment (e.g., c("planning","region"))
  if (length(keywords)) {
    kw <- norm_cols(keywords)
    ok <- sapply(nms_norm, function(x) all(stringr::str_detect(x, kw)))
    if (sum(ok) == 1) {
      hit <- which(ok)
      cat("•", label, "→", nms[hit], "(keywords)\n")
      return(nms[hit])
    }
    # choose best score if multiple
    if (sum(ok) > 1) {
      scores <- sapply(nms_norm[ok], function(x) sum(stringr::str_detect(x, kw)))
      hit <- which(ok)[which.max(scores)]
      cat("•", label, "→", nms[hit], "(keywords-best)\n")
      return(nms[hit])
    }
  }
  # 4) failure path
  if (required) {
    cat("\n⚠️ Could not find", label, ". Available columns:\n")
    print(nms)
    stop(paste("Required", label, "not found. See column list above."))
  } else {
    cat("•", label, "not found (optional).\n")
    return(NA_character_)
  }
}

# --- Fetch CBP (fetch before use) ---------------------------------------------
cbp_2023_us_raw <- getCensus(name="cbp", vars=c("NAICS2017","PAYANN","EMP"),
                             region="us:*", vintage=2023)
if (exists("dbg")) dbg(cbp_2023_us_raw, "cbp_2023_us_raw")

cbp_2023_cnty_raw <- getCensus(name="cbp",
                               vars=c("STATE","COUNTY","NAICS2017","PAYANN","EMP"),
                               region="county:*", vintage=2023)
if (exists("dbg")) dbg(cbp_2023_cnty_raw, "cbp_2023_cnty_raw")

# --- 0) Lookups (STATE, COUNTY, CBSA, PEA, CD119) -----------------------------
# States (2024)
lkp_state <- tigris_states_2024_raw %>%
  transmute(state_fips = STATEFP,
            state_abbr = STUSPS,
            State.Name = fix_text(NAME))

# Counties (2020 geog, drop geometry)
lkp_county <- tigris_counties_2020_raw %>%
  sf::st_drop_geometry() %>%
  transmute(
    county_geoid = GEOID,
    county_name  = fix_text(NAMELSAD),
    state_fips   = substr(GEOID, 1, 2)
  )

# CBSA + PEA (county base 2020; titles will be swapped to tigris NAME)
lkp_cbsa_pea <- COUNTY_CROSSWALK_SUPPLEMENT_GDP_PEA %>%
  transmute(county_geoid = COUNTY_GEOID,
            CBSA.Code   = CBSA_GEOID,
            CBSA.Title  = fix_text(CBSA_NAME),
            PEA         = fix_text(PEA_NAME),
            PEA_NO      = PEA_NUMBER)

# Authoritative CBSA names from tigris
lkp_cbsa_names <- tigris_cbsa_2020_raw %>%
  sf::st_drop_geometry() %>%
  transmute(CBSA.Code = GEOID, CBSA.Name = fix_text(NAME))

# Early CBSA name QA (should catch Cañon/Española here)
debug_text_issues(lkp_cbsa_names, "lkp_cbsa_names (raw fixed)", "CBSA.Name", n=10)

# County→CD119 factors (national GeoCorr)
lkp_cd119_nat <- geocorr_county_2020_cd_119 %>%
  transmute(
    county_geoid = COUNTY_GEOID,
    CD119_code   = CD119_code,
    state_fips   = State_code,
    co_to_cd119  = `county-to-cd119 allocation factor`
  ) %>%
  mutate(cd_119 = paste0(lkp_state$state_abbr[match(state_fips, lkp_state$state_fips)],
                         "-", str_pad(CD119_code, 2, pad = "0")))

# Connecticut-specific county (legacy) → CD119 bridge
cat("\n--- Detecting column names in geocorr_ct_county_cd_119 ---\n")
gc_ct_names <- names(geocorr_ct_county_cd_119); print(gc_ct_names)

gc_ct_col_county   <- find_col(geocorr_ct_county_cd_119,
                               candidates = c("County code","County Code","County_code","County"),
                               keywords   = c("county","code"),
                               label = "CT county code")
gc_ct_col_cd       <- find_col(geocorr_ct_county_cd_119,
                               candidates = c("Congressional district code (119th Congress)",
                                              "CD119_code","cd119","CongressionalDistrictCode119"),
                               keywords   = c("congressional","119"),
                               label = "CD119 code")
gc_ct_col_alloc    <- find_col(geocorr_ct_county_cd_119,
                               candidates = c("CTcounty-to-cd119 allocation factor",
                                              "ctcounty to cd119 allocation factor"),
                               keywords   = c("allocation","cd119"),
                               label = "CTcounty→CD119 allocation factor")

lkp_cd119_ct <- geocorr_ct_county_cd_119 %>%
  transmute(
    county_geoid = .data[[gc_ct_col_county]],
    CD119_code   = .data[[gc_ct_col_cd]],
    co_to_cd119  = to_num(.data[[gc_ct_col_alloc]]),
    cd_119       = paste0("CT-", str_pad(CD119_code, 2, pad = "0"))
  )

# Prefer CT-specific rows over national
lkp_cd119 <- bind_rows(
  lkp_cd119_nat %>% filter(!startsWith(county_geoid, "09")),
  lkp_cd119_ct
) %>%
  filter(!is.na(co_to_cd119), co_to_cd119 > 0)

# --- 1) US manufacturing share for LQ baseline --------------------------------
manshare_us <- cbp_2023_us_raw %>%
  filter(NAICS2017 %in% c("31-33","00")) %>%
  select(-PAYANN) %>%
  tidyr::pivot_wider(names_from = NAICS2017, values_from = EMP) %>%
  mutate(man_share_us = ifelse(as.numeric(`00`) > 0,
                               as.numeric(`31-33`) / as.numeric(`00`) * 100,
                               NA_real_)) %>%
  transmute(man_share_us = round(man_share_us, 1))
man_share_us_val <- manshare_us$man_share_us
if (!is.finite(man_share_us_val) || is.na(man_share_us_val)) man_share_us_val <- 9

# --- 2) CBP 2023 county GEOIDs; drop territories in CBP -----------------------
cbp_cnty <- cbp_2023_cnty_raw %>%
  mutate(county_geoid = paste0(str_pad(STATE,  2, pad = "0"),
                               str_pad(COUNTY, 3, pad = "0"))) %>%
  filter(!substr(county_geoid, 1, 2) %in% territory_state_fips)

# --- 3) CT PR (2023) → legacy counties (2020) reallocation --------------------
cat("\n--- Detecting column names in ct_fips_changes_raw ---\n")
ct_names <- names(ct_fips_changes_raw); print(ct_names)

ct_col_county   <- find_col(ct_fips_changes_raw,
                            candidates = c("County code","County Code","County_code","County"),
                            keywords   = c("county","code"),
                            label = "Legacy County code (2020)")
ct_col_pr       <- find_col(ct_fips_changes_raw,
                            candidates = c("Connecticut planning region","Planning region code","Planning region"),
                            keywords   = c("planning","region"),
                            label = "CT Planning Region code (2023)")
ct_col_pr2ct    <- find_col(ct_fips_changes_raw,
                            candidates = c("county-to-CTcounty allocation factor","county to ctcounty allocation factor"),
                            keywords   = c("county","ctcounty","allocation"),
                            label = "County→CTcounty allocation factor")
ct_col_ct2pr    <- find_col(ct_fips_changes_raw,
                            candidates = c("CTcounty-to-county allocation factor","ctcounty to county allocation factor"),
                            keywords   = c("ctcounty","county","allocation"),
                            label = "CTcounty→County allocation factor",
                            required = FALSE)

# Build & normalize CT weights (defensive)
ct_alloc_raw <- ct_fips_changes_raw %>%
  transmute(
    ctcounty_geoid = stringr::str_pad(as.character(.data[[ct_col_county]]), 5, pad = "0"),
    pr_geoid       = stringr::str_pad(as.character(.data[[ct_col_pr]]),     5, pad = "0"),
    w_pr_to_ct     = to_num(.data[[ct_col_pr2ct]]),             # PR→County
    w_ct_to_pr     = if (!is.na(ct_col_ct2pr)) to_num(.data[[ct_col_ct2pr]]) else NA_real_  # County→PR (optional)
  )

# Show sample of CT alloc table for sanity
cat("\n--- ct_alloc_raw sample ---\n"); print(head(ct_alloc_raw, 10), n=10)

ct_map <- ct_alloc_raw %>%
  mutate(
    w_ct_to_pr = tidyr::replace_na(w_ct_to_pr, 0),
    w_pr_to_ct = tidyr::replace_na(w_pr_to_ct, 0)
  ) %>%
  group_by(pr_geoid) %>%
  mutate(w_pr_to_ct = if (sum(w_pr_to_ct) > 0) w_pr_to_ct / sum(w_pr_to_ct) else w_pr_to_ct) %>%
  ungroup() %>%
  group_by(ctcounty_geoid) %>%
  mutate(w_ct_to_pr = if (sum(w_ct_to_pr) > 0) w_ct_to_pr / sum(w_ct_to_pr) else w_ct_to_pr) %>%
  ungroup()

qa_pr <- ct_map %>% group_by(pr_geoid)       %>% summarise(s = sum(w_pr_to_ct), .groups="drop")
qa_ct <- ct_map %>% group_by(ctcounty_geoid) %>% summarise(s = sum(w_ct_to_pr), .groups="drop")
soft_assert(all(abs(qa_pr$s - 1) < 1e-6), "CT PR→County weights do not sum to 1 (after normalization).")
soft_assert(all(abs(qa_ct$s - 1) < 1e-6), "CT County→PR weights do not sum to 1 (after normalization).")

reallocate_ct_pr_to_counties <- function(cbp_df, ct_map) {
  stopifnot(all(c("STATE","COUNTY","NAICS2017","PAYANN","EMP","county_geoid") %in% names(cbp_df)))
  pr_keys    <- unique(ct_map$pr_geoid)
  cbp_ct_pr  <- cbp_df %>% filter(county_geoid %in% pr_keys)
  cbp_non_ct <- cbp_df %>% filter(!county_geoid %in% pr_keys)
  if (nrow(cbp_ct_pr) == 0L) return(cbp_df)
  
  before <- cbp_ct_pr %>% group_by(NAICS2017) %>%
    summarise(PAYANN = sum(PAYANN, na.rm=TRUE), EMP = sum(EMP, na.rm=TRUE), .groups="drop")
  
  cbp_ct_alloc <- cbp_ct_pr %>%
    inner_join(ct_map %>% select(pr_geoid, ctcounty_geoid, w_pr_to_ct),
               by = c("county_geoid" = "pr_geoid"), relationship = "many-to-many") %>%
    mutate(PAYANN = PAYANN * w_pr_to_ct,
           EMP    = EMP    * w_pr_to_ct,
           STATE        = substr(ctcounty_geoid, 1, 2),
           COUNTY       = substr(ctcounty_geoid, 3, 5),
           county_geoid = ctcounty_geoid) %>%
    group_by(STATE, COUNTY, county_geoid, NAICS2017) %>%
    summarise(PAYANN = sum(PAYANN, na.rm=TRUE),
              EMP    = sum(EMP,    na.rm=TRUE), .groups="drop")
  
  after <- cbp_ct_alloc %>% group_by(NAICS2017) %>%
    summarise(PAYANN = sum(PAYANN, na.rm=TRUE), EMP = sum(EMP, na.rm=TRUE), .groups="drop")
  
  chk <- before %>% left_join(after, by="NAICS2017", suffix=c("_b","_a")) %>%
    mutate(dP = PAYANN_a - PAYANN_b, dE = EMP_a - EMP_b)
  soft_assert(all(abs(chk$dP) < 1e-4 & abs(chk$dE) < 1e-4),
              "CT totals changed after PR→county reallocation.")
  
  bind_rows(cbp_non_ct, cbp_ct_alloc) %>% arrange(STATE, COUNTY, NAICS2017)
}
cbp_2023 <- reallocate_ct_pr_to_counties(cbp_cnty, ct_map)

# Guard: no CT PR rows remain
pr_geoids     <- unique(ct_map$pr_geoid)
leftover_prs  <- cbp_2023 %>% filter(county_geoid %in% pr_geoids) %>% distinct(county_geoid)
soft_assert(nrow(leftover_prs) == 0, paste("Some CT PR GEOIDs remain:", paste(leftover_prs$county_geoid, collapse=", ")))

# --- 4) County metrics ---------------------------------------------------------
cbp_cnty_00 <- cbp_2023 %>%
  filter(NAICS2017 == "00") %>%
  select(county_geoid, EMP00 = EMP)

cbp_cnty_mfg <- cbp_2023 %>%
  filter(NAICS2017 == "31-33") %>%
  select(county_geoid, PAYANN_mfg = PAYANN, EMP_mfg = EMP) %>%
  mutate(worker_pay = if_else(EMP_mfg > 0, PAYANN_mfg / EMP_mfg * 1000, NA_real_))

county_base <- lkp_county %>%
  left_join(lkp_state, by = "state_fips") %>%
  select(county_geoid, county_name, State.Name)

county_metrics <- county_base %>%
  left_join(cbp_cnty_00,  by = "county_geoid") %>%
  left_join(cbp_cnty_mfg, by = "county_geoid") %>%
  mutate(
    man_share_raw = dplyr::case_when(
      is.na(EMP00) ~ NA_real_,
      !is.na(EMP00) & (is.na(EMP_mfg) | EMP_mfg == 0) ~ 0,
      EMP00 > 0 ~ round(EMP_mfg / EMP00 * 100, 1),
      TRUE ~ NA_real_
    ),
    worker_pay = if_else(EMP_mfg > 0, PAYANN_mfg / EMP_mfg * 1000, NA_real_)
  ) %>%
  mutate(county_name = fix_text(county_name),
         State.Name  = fix_text(State.Name)) %>%
  filter(!is.na(EMP00))   # keep only counties with CBP "00" rows

# --- 5) CD119 rollup (county→CD weights; includes CT) -------------------------
cd119_emp <- lkp_cd119 %>%
  inner_join(cbp_cnty_00,  by = "county_geoid") %>%
  inner_join(cbp_cnty_mfg, by = "county_geoid") %>%
  mutate(EMP00_w   = EMP00   * co_to_cd119,
         EMP_mfg_w = EMP_mfg * co_to_cd119,
         PAY_w     = PAYANN_mfg * co_to_cd119) %>%
  group_by(cd_119) %>%
  summarise(EMP00   = sum(EMP00_w,   na.rm=TRUE),
            EMP_mfg = sum(EMP_mfg_w, na.rm=TRUE),
            PAY_mfg = sum(PAY_w,     na.rm=TRUE), .groups="drop") %>%
  mutate(
    man_share = dplyr::case_when(
      is.na(EMP00) ~ NA_real_,
      !is.na(EMP00) & (is.na(EMP_mfg) | EMP_mfg == 0) ~ 0,
      EMP00 > 0 ~ round(EMP_mfg / EMP00 * 100, 1),
      TRUE ~ NA_real_
    ),
    man_pay = if_else(EMP_mfg > 0, round(PAY_mfg / EMP_mfg * 1000, 2), NA_real_)
  )

# --- 6) State / CBSA / PEA rollups --------------------------------------------
# State (exclude territories for output parity with geo_long)
state_metrics <- county_metrics %>%
  mutate(state_fips = substr(county_geoid, 1, 2)) %>%
  filter(!state_fips %in% territory_state_fips) %>%
  group_by(state_fips) %>%
  summarise(EMP00 = sum(EMP00, na.rm=TRUE),
            EMP_mfg = sum(EMP_mfg, na.rm=TRUE),
            PAY_mfg = sum(PAYANN_mfg, na.rm=TRUE), .groups="drop") %>%
  left_join(lkp_state, by="state_fips") %>%
  mutate(
    man_share = dplyr::case_when(
      is.na(EMP00) ~ NA_real_,
      !is.na(EMP00) & (is.na(EMP_mfg) | EMP_mfg == 0) ~ 0,
      EMP00 > 0 ~ round(EMP_mfg / EMP00 * 100, 1),
      TRUE ~ NA_real_
    ),
    man_pay = if_else(EMP_mfg > 0, round(PAY_mfg / EMP_mfg * 1000, 2), NA_real_)
  ) %>%
  select(State.Name, man_share, man_pay)

# CBSA (join to tigris names for exact title alignment with geo_long)
cbsa_metrics <- county_metrics %>%
  inner_join(lkp_cbsa_pea %>% filter(!is.na(CBSA.Code)), by = "county_geoid") %>%
  group_by(CBSA.Code) %>%
  summarise(EMP00   = sum(EMP00,     na.rm=TRUE),
            EMP_mfg = sum(EMP_mfg,   na.rm=TRUE),
            PAY_mfg = sum(PAYANN_mfg,na.rm=TRUE), .groups="drop") %>%
  left_join(lkp_cbsa_names, by = "CBSA.Code") %>%
  mutate(
    CBSA.Name = fix_text(CBSA.Name),
    man_share = dplyr::case_when(
      is.na(EMP00) ~ NA_real_,
      !is.na(EMP00) & (is.na(EMP_mfg) | EMP_mfg == 0) ~ 0,
      EMP00 > 0 ~ round(EMP_mfg / EMP00 * 100, 1),
      TRUE ~ NA_real_
    ),
    man_pay = if_else(EMP_mfg > 0, round(PAY_mfg / EMP_mfg * 1000, 2), NA_real_)
  )

# PEA
pea_metrics <- county_metrics %>%
  inner_join(lkp_cbsa_pea %>% filter(!is.na(PEA)), by = "county_geoid") %>%
  group_by(PEA) %>%
  summarise(EMP00   = sum(EMP00,     na.rm=TRUE),
            EMP_mfg = sum(EMP_mfg,   na.rm=TRUE),
            PAY_mfg = sum(PAYANN_mfg,na.rm=TRUE), .groups="drop") %>%
  mutate(
    PEA      = fix_text(PEA),
    man_share = dplyr::case_when(
      is.na(EMP00) ~ NA_real_,
      !is.na(EMP00) & (is.na(EMP_mfg) | EMP_mfg == 0) ~ 0,
      EMP00 > 0 ~ round(EMP_mfg / EMP00 * 100, 1),
      TRUE ~ NA_real_
    ),
    man_pay = if_else(EMP_mfg > 0, round(PAY_mfg / EMP_mfg * 1000, 2), NA_real_)
  )

# County output (ensure "<County>, <State>")
county_out <- county_metrics %>%
  transmute(
    GeoName   = fix_text(paste0(county_name, ", ", State.Name)),
    man_share = man_share_raw,
    man_pay   = round(worker_pay, 2)
  )

# --- 7) Assemble numeric outputs ----------------------------------------------
manpay_geo_num <- bind_rows(
  state_metrics %>% transmute(geo="State",                  geo_name=fix_text(State.Name),  man_pay),
  cd119_emp     %>% transmute(geo="Congressional District", geo_name=fix_text(cd_119),      man_pay),
  pea_metrics   %>% transmute(geo="Economic Area",          geo_name=fix_text(PEA),         man_pay),
  county_out    %>% transmute(geo="County",                 geo_name=fix_text(GeoName),     man_pay),
  cbsa_metrics  %>% transmute(geo="Metro Area",             geo_name=fix_text(CBSA.Name),   man_pay)
) %>%
  filter(!is.na(geo_name), geo_name != "") %>%
  group_by(geo) %>% mutate(Manpay_rank = rank(-tidyr::replace_na(man_pay, -Inf), ties.method="min")) %>%
  ungroup()

manshare_num <- bind_rows(
  state_metrics %>% transmute(geo="State",                  geo_name=fix_text(State.Name), man_share),
  cd119_emp     %>% transmute(geo="Congressional District", geo_name=fix_text(cd_119),     man_share),
  pea_metrics   %>% transmute(geo="Economic Area",          geo_name=fix_text(PEA),        man_share),
  county_out    %>% transmute(geo="County",                 geo_name=fix_text(GeoName),    man_share),
  cbsa_metrics  %>% transmute(geo="Metro Area",             geo_name=fix_text(CBSA.Name),  man_share)
) %>%
  filter(!is.na(geo_name), geo_name != "") %>%
  group_by(geo) %>% mutate(Manshare_rank = rank(-tidyr::replace_na(man_share, -Inf), ties.method="min")) %>%
  ungroup() %>%
  mutate(manufacturing_lq = if_else(!is.na(man_share),
                                    round(man_share / man_share_us_val, 1),
                                    NA_real_))

# --- 8) Convert NA → blanks ("") for final emission ----------------------------
manpay_geo <- manpay_geo_num %>%
  mutate(
    geo_name    = fix_text(geo_name),
    man_pay     = fmt_num(man_pay, 2),
    Manpay_rank = ifelse(is.na(Manpay_rank), "", as.character(Manpay_rank))
  )

manshare <- manshare_num %>%
  mutate(
    geo_name         = fix_text(geo_name),
    man_share        = fmt_num(man_share, 1),
    Manshare_rank    = ifelse(is.na(Manshare_rank), "", as.character(Manshare_rank)),
    manufacturing_lq = fmt_num(manufacturing_lq, 1)
  )

# --- 9) Canonicalize tricky county name once (Doña Ana, NM) -------------------
canon_nm <- "Doña Ana County, New Mexico"
normalize_nm <- function(df) {
  df %>% mutate(
    geo_name = dplyr::if_else(geo == "County" & name_cmp(geo_name) == name_cmp(canon_nm),
                              canon_nm, geo_name)
  )
}
manpay_geo <- manpay_geo %>% normalize_nm() %>% distinct(geo, geo_name, .keep_all = TRUE)
manshare   <- manshare   %>% normalize_nm() %>% distinct(geo, geo_name, .keep_all = TRUE)

# Additional quick checks for common offenders in outputs
debug_text_issues(manpay_geo, "manpay_geo (post-format)")
debug_text_issues(manshare,   "manshare   (post-format)")

# --- 10) Alignment report + backfill for display parity with geo_long ----------
geo_long_norm <- geo_long %>%
  mutate(
    geo_type      = norm_name(geo_type),
    geo_name      = fix_text(geo_name),
    geo_name_norm = norm_name(geo_name),
    geo_name_cmp  = name_cmp(geo_name)
  )

out_states <- manpay_geo %>%
  filter(geo=="State") %>% transmute(geo_type="State",  geo_name, geo_name_cmp = name_cmp(geo_name))
out_cds    <- manshare   %>%
  filter(geo=="Congressional District") %>% transmute(geo_type="Congressional District", geo_name, geo_name_cmp = name_cmp(geo_name))
out_pea    <- manpay_geo %>%
  filter(geo=="Economic Area") %>% transmute(geo_type="Economic Area", geo_name, geo_name_cmp = name_cmp(geo_name))
out_cnty   <- manshare   %>%
  filter(geo=="County") %>% transmute(geo_type="County", geo_name, geo_name_cmp = name_cmp(geo_name))
out_cbsa   <- manpay_geo %>%
  filter(geo=="Metro Area") %>% transmute(geo_type="Metro Area", geo_name, geo_name_cmp = name_cmp(geo_name))

not_found_states <- anti_join(geo_long_norm %>% filter(geo_type=="State")                  %>% select(geo_type, geo_name, geo_name_cmp),
                              out_states %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_cds    <- anti_join(geo_long_norm %>% filter(geo_type=="Congressional District") %>% select(geo_type, geo_name, geo_name_cmp),
                              out_cds    %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_pea    <- anti_join(geo_long_norm %>% filter(geo_type=="Economic Area")          %>% select(geo_type, geo_name, geo_name_cmp),
                              out_pea    %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_cnty   <- anti_join(geo_long_norm %>% filter(geo_type=="County")                 %>% select(geo_type, geo_name, geo_name_cmp),
                              out_cnty   %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_cbsa   <- anti_join(geo_long_norm %>% filter(geo_type=="Metro Area")             %>% select(geo_type, geo_name, geo_name_cmp),
                              out_cbsa   %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))

cat("\n===== Alignment report: geo_long items with NO output (post-backfill) =====\n")
print_mismatches(not_found_states, "States")
print_mismatches(not_found_cds,    "Congressional Districts")
print_mismatches(not_found_pea,    "Economic Areas (PEA)")
print_mismatches(not_found_cnty,   "Counties")
print_mismatches(not_found_cbsa,   "Metro Areas (CBSA)")

# Backfill (display only) missing COUNTY/CBSA rows with blanks
if (nrow(not_found_cnty) > 0) {
  manpay_geo <- bind_rows(
    manpay_geo,
    not_found_cnty %>% transmute(geo="County", geo_name, man_pay="", Manpay_rank="")
  )
  manshare <- bind_rows(
    manshare,
    not_found_cnty %>% transmute(geo="County", geo_name, man_share="", Manshare_rank="", manufacturing_lq="")
  )
}
if (nrow(not_found_cbsa) > 0) {
  manpay_geo <- bind_rows(
    manpay_geo,
    not_found_cbsa %>% transmute(geo="Metro Area", geo_name, man_pay="", Manpay_rank="")
  )
  manshare <- bind_rows(
    manshare,
    not_found_cbsa %>% transmute(geo="Metro Area", geo_name, man_share="", Manshare_rank="", manufacturing_lq="")
  )
}

# Dedup any accidental duplicates after backfill
manpay_geo <- manpay_geo %>% distinct(geo, geo_name, .keep_all = TRUE)
manshare   <- manshare   %>% distinct(geo, geo_name, .keep_all = TRUE)

# Recompute alignment POST-BACKFILL for clean report (cmp-based only)
out_states <- manpay_geo %>% filter(geo=="State") %>% transmute(geo_type="State",  geo_name, geo_name_cmp = name_cmp(geo_name))
out_cds    <- manshare   %>% filter(geo=="Congressional District") %>% transmute(geo_type="Congressional District", geo_name, geo_name_cmp = name_cmp(geo_name))
out_pea    <- manpay_geo %>% filter(geo=="Economic Area") %>% transmute(geo_type="Economic Area", geo_name, geo_name_cmp = name_cmp(geo_name))
out_cnty   <- manshare   %>% filter(geo=="County") %>% transmute(geo_type="County", geo_name, geo_name_cmp = name_cmp(geo_name))
out_cbsa   <- manpay_geo %>% filter(geo=="Metro Area") %>% transmute(geo_type="Metro Area", geo_name, geo_name_cmp = name_cmp(geo_name))

not_found_states <- anti_join(geo_long_norm %>% filter(geo_type=="State")                  %>% select(geo_type, geo_name, geo_name_cmp),
                              out_states %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_cds    <- anti_join(geo_long_norm %>% filter(geo_type=="Congressional District") %>% select(geo_type, geo_name, geo_name_cmp),
                              out_cds    %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_pea    <- anti_join(geo_long_norm %>% filter(geo_type=="Economic Area")          %>% select(geo_type, geo_name, geo_name_cmp),
                              out_pea    %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_cnty   <- anti_join(geo_long_norm %>% filter(geo_type=="County")                 %>% select(geo_type, geo_name, geo_name_cmp),
                              out_cnty   %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))
not_found_cbsa   <- anti_join(geo_long_norm %>% filter(geo_type=="Metro Area")             %>% select(geo_type, geo_name, geo_name_cmp),
                              out_cbsa   %>% select(geo_type, geo_name_cmp), by=c("geo_type","geo_name_cmp"))

cat("\n===== Output-only items (present in outputs but NOT in geo_long) — cmp-based =====\n")
only_out_states <- anti_join(out_states %>% select(geo_type, geo_name, geo_name_cmp),
                             geo_long_norm %>% filter(geo_type=="State") %>% select(geo_type, geo_name_cmp),
                             by=c("geo_type","geo_name_cmp")) %>% select(geo_type, geo_name)
only_out_cds    <- anti_join(out_cds    %>% select(geo_type, geo_name, geo_name_cmp),
                             geo_long_norm %>% filter(geo_type=="Congressional District") %>% select(geo_type, geo_name_cmp),
                             by=c("geo_type","geo_name_cmp")) %>% select(geo_type, geo_name)
only_out_pea    <- anti_join(out_pea    %>% select(geo_type, geo_name, geo_name_cmp),
                             geo_long_norm %>% filter(geo_type=="Economic Area") %>% select(geo_type, geo_name_cmp),
                             by=c("geo_type","geo_name_cmp")) %>% select(geo_type, geo_name)
only_out_cnty   <- anti_join(out_cnty   %>% select(geo_type, geo_name, geo_name_cmp),
                             geo_long_norm %>% filter(geo_type=="County") %>% select(geo_type, geo_name_cmp),
                             by=c("geo_type","geo_name_cmp")) %>% select(geo_type, geo_name)
only_out_cbsa   <- anti_join(out_cbsa   %>% select(geo_type, geo_name, geo_name_cmp),
                             geo_long_norm %>% filter(geo_type=="Metro Area") %>% select(geo_type, geo_name_cmp),
                             by=c("geo_type","geo_name_cmp")) %>% select(geo_type, geo_name)

print_mismatches(only_out_states, "States")
print_mismatches(only_out_cds,    "Congressional Districts")
print_mismatches(only_out_pea,    "Economic Areas (PEA)")
print_mismatches(only_out_cnty,   "Counties")
print_mismatches(only_out_cbsa,   "Metro Areas (CBSA)")

# Targeted check for problem names in outputs
cat("\n===== Targeted name checks (should show proper UTF-8) =====\n")
cat("Doña Ana (any):\n"); print((manshare$geo_name[manshare$geo=="County"] %>% unique())[stringr::str_detect((manshare$geo_name[manshare$geo=="County"] %>% unique()), "Do")][1:5])
cat("Cañon / Canon City (Metro Area):\n"); print((manpay_geo$geo_name[manpay_geo$geo=="Metro Area"] %>% unique())[stringr::str_detect((manpay_geo$geo_name[manpay_geo$geo=="Metro Area"] %>% unique()), "Canon|Cañon")][1:5])
cat("Española / Espanola (Metro Area):\n"); print((manpay_geo$geo_name[manpay_geo$geo=="Metro Area"] %>% unique())[stringr::str_detect((manpay_geo$geo_name[manpay_geo$geo=="Metro Area"] %>% unique()), "Espan|Españ")][1:5])

# --- 11) Extra QA (succinct) ---------------------------------------------------
cat("\n=== Quick QA ===\n")
cat("US man_share_us_val:", man_share_us_val, "\n")
cat("Output counts by geo:\n")
print(manpay_geo %>% count(geo) %>% arrange(desc(n)))
cat("Distinct CDs in output:",
    manshare %>% filter(geo == "Congressional District") %>% dplyr::pull(geo_name) %>% dplyr::n_distinct(),
    "\n")

# --- Final debug prints (if dbg() exists) -------------------------------------
if (exists("dbg")) {
  dbg(manpay_geo, "manpay_geo (final)")
  dbg(manshare,   "manshare (final)")
}

# ===================================================================
# County GDP by Industry (BEA CAGDP11/CAGDP2) — hardened + succinct
# Goal: produce county_gdp_ind_final that aligns EXACTLY to geo_long
# Key upgrades:
#   • Strict FIPS cleaning + removal of 000xx artifacts
#   • HI 15901 split, VA 519xx decompositions, CT 091xx → 090xx mapping
#   • Many-to-many joins handled safely (no spurious warnings)
#   • Uses BEA LineCode (not text) for robustness across label changes
#   • Final rows/ordering forced to geo_long (or a faithful fallback)
#   • Dense, targeted debugging at each stage
# ABSOLUTELY NOTHING OMITTED.
# ===================================================================

suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(stringr)
  library(readr)
  library(purrr)
})

# ------------------------ Debug helpers -----------------------------------
if (!exists("dbg")) {
  dbg <- function(x, label = deparse(substitute(x)), n = 6) {
    cat("\n====", label, "====\n")
    cat("Rows:", nrow(x), "Cols:", ncol(x), "\n")
    print(dplyr::glimpse(dplyr::as_tibble(x), width = 95))
    if (nrow(x) > 0) { cat("Head:\n"); print(utils::head(x, n)) }
    invisible(x)
  }
}
if (!exists("dbg_count_na")) {
  dbg_count_na <- function(df, cols, label="NA counts") {
    cat("\n-- NA counts:", label, "--\n")
    out <- sapply(cols, function(cn) sum(is.na(df[[cn]])))
    print(out)
    invisible(out)
  }
}
msg <- function(...) cat("\n#", sprintf(...), "\n")

# dplyr-1.1+ compatible "many-to-many ok" joins (fallback for older dplyr)
mm_left_join <- function(x, y, by, ...) {
  if (utils::packageVersion("dplyr") >= "1.1.0") {
    dplyr::left_join(x, y, by = by, relationship = "many-to-many", ...)
  } else dplyr::left_join(x, y, by = by, ...)
}
mm_inner_join <- function(x, y, by, ...) {
  if (utils::packageVersion("dplyr") >= "1.1.0") {
    dplyr::inner_join(x, y, by = by, relationship = "many-to-many", ...)
  } else dplyr::inner_join(x, y, by = by, ...)
}

# ------------------------ General helpers ---------------------------------
na_tokens <- c("(D)","(L)","(S)","(NA)","(N/A)","(X)","(T)","(C)","(Z)")
numify    <- function(x) readr::parse_number(x, na = na_tokens, locale = locale(grouping_mark = ","))
nf5       <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

# Strong county-equivalent filter: keep 50 states + DC; drop territories & US/state totals & 00xxx artifacts
is_real_county <- function(fips5) {
  fips5 <- nf5(fips5)
  st    <- substr(fips5, 1, 2)
  last3 <- substr(fips5, 3, 5)
  valid_states <- sprintf("%02d", c(1:56))
  territories  <- c("60","66","69","72","78") # AS, GU, MP, PR, VI
  is_state_ok  <- st %in% setdiff(valid_states, territories)
  not_state_total <- last3 != "000"
  not_us_total    <- fips5 != "00000"
  not_weird_000xx <- substr(fips5, 1, 2) != "00" # drops 00002, 00011, etc.
  is_state_ok & not_state_total & not_us_total & not_weird_000xx
}

# Clean & longify BEA table (CAGDP11 or CAGDP2)
longify_bea <- function(df, name) {
  yr_cols <- names(df)[grepl("^\\d{4}$", names(df))]
  df %>%
    mutate(
      GeoFIPS = nf5(str_extract(GeoFIPS, "\\d+")),
      GeoName = GeoName %>%
        str_replace_all("\\*", "") %>%
        str_replace_all("\\s*\\(.*?\\)", "") %>%
        str_squish(),
      Description = str_squish(Description),
      Unit        = str_squish(Unit)
    ) %>%
    filter(is_real_county(GeoFIPS)) %>%
    pivot_longer(all_of(yr_cols), names_to = "Year", values_to = "Value_raw") %>%
    mutate(
      Year  = as.integer(Year),
      Value = numify(Value_raw),
      Table = name
    ) %>%
    select(Table, GeoFIPS, GeoName, Year, Value, Region, LineCode,
           IndustryClassification, Description, Unit)
}

# ------------------------ Load BEA raw ------------------------------------
safe_unzip_pick <- function(zip_url, pattern, label) {
  zf <- tempfile(fileext = ".zip")
  download.file(zip_url, zf, mode = "wb", quiet = TRUE)
  lst <- try(unzip(zf, list = TRUE), silent = TRUE)
  stopifnot(!inherits(lst, "try-error"))
  pick <- lst$Name[grepl(pattern, lst$Name)][1]
  stopifnot(!is.na(pick))
  exd <- tempdir()
  unzip(zf, files = pick, exdir = exd)
  out <- read.csv(file.path(exd, pick), check.names = FALSE)
  out <- if (exists("fix_df")) fix_df(out) else tibble::as_tibble(out)
  dbg(out, paste0(label, " (raw)"))
  out
}

cagdp11_raw <- safe_unzip_pick(
  "https://apps.bea.gov/regional/zip/CAGDP11.zip",
  "^CAGDP11__ALL_AREAS_\\d{4}_\\d{4}\\.csv$",
  "CAGDP11"
)
cagdp2_raw <- safe_unzip_pick(
  "https://apps.bea.gov/regional/zip/CAGDP2.zip",
  "^CAGDP2__ALL_AREAS_\\d{4}_\\d{4}\\.csv$",
  "CAGDP2"
)

CAGDP11_LONG <- longify_bea(cagdp11_raw, "CAGDP11")
CAGDP2_LONG  <- longify_bea(cagdp2_raw,  "CAGDP2")
dbg(CAGDP11_LONG, "CAGDP11_LONG")
dbg(CAGDP2_LONG,  "CAGDP2_LONG")

# ------------------------ Crosswalks (HI / VA / CT) -----------------------
detect_pop <- function() {
  cand <- list(
    if (exists("county_2020")) county_2020 else NULL,
    if (exists("us_communities")) us_communities else NULL,
    if (exists("geo")) geo else NULL
  ) %>% compact()
  for (df in cand) {
    nm <- names(df)
    fips_col <- nm[grepl("^fips$|^Fips$|^GEOID$|^GEOID_?fips$", nm, ignore.case = TRUE)][1]
    pop_col  <- nm[grepl("pop|population|P001001|TOT_POP", nm, ignore.case = TRUE)][1]
    if (!is.na(fips_col) && !is.na(pop_col)) {
      out <- df %>%
        transmute(fips = nf5(!!sym(fips_col)), pop = suppressWarnings(as.numeric(!!sym(pop_col)))) %>%
        group_by(fips) %>% summarise(pop = sum(pop, na.rm = TRUE), .groups = "drop")
      if (nrow(out) > 0) return(out)
    }
  }
  NULL
}
pop_lookup <- detect_pop()
if (is.null(pop_lookup)) {
  warning("No population column found for VA/HI allocation. Falling back to equal splits.")
}

# HI: 15901 (Maui+Kalawao) → 15009 + 15005
hi_map <- tibble(
  from_fips = "15901",
  to_fips   = c("15009","15005"),
  alloc     = {
    if (!is.null(pop_lookup)) {
      pops <- pop_lookup %>% filter(fips %in% c("15009","15005")) %>% pull(pop)
      if (length(pops) == 2 && sum(pops, na.rm = TRUE) > 0) pops / sum(pops, na.rm = TRUE) else c(0.999, 0.001)
    } else c(0.999, 0.001)
  }
)

# VA: 519xx aggregates → components (pop-weighted when available)
va_combo_map <- tribble(
  ~from_fips, ~to_fips,
  "51901","51003", "51901","51540",
  "51903","51005", "51903","51580",
  "51907","51015", "51907","51790", "51907","51820",
  "51911","51031", "51911","51680",
  "51913","51035", "51913","51640",
  "51918","51053", "51918","51570", "51918","51730",
  "51919","51059", "51919","51600", "51919","51610",
  "51921","51069", "51921","51840",
  "51923","51081", "51923","51595",
  "51929","51089", "51929","51690",
  "51931","51095", "51931","51830",
  "51933","51121", "51933","51750",
  "51939","51143", "51939","51590",
  "51941","51149", "51941","51670",
  "51942","51153", "51942","51683", "51942","51685",
  "51944","51161", "51944","51775",
  "51945","51163", "51945","51530", "51945","51678",
  "51947","51165", "51947","51660",
  "51949","51175", "51949","51620",
  "51951","51177", "51951","51630",
  "51953","51191", "51953","51520",
  "51955","51195", "51955","51720",
  "51958","51199", "51958","51735"
) %>% group_by(from_fips) %>%
  mutate(alloc = {
    comps <- to_fips
    if (!is.null(pop_lookup)) {
      pops <- pop_lookup %>% filter(fips %in% comps) %>% pull(pop)
      if (length(pops) == length(comps) && sum(pops, na.rm = TRUE) > 0) pops / sum(pops, na.rm = TRUE)
      else rep(1/length(comps), length(comps))
    } else rep(1/length(comps), length(comps))
  }) %>% ungroup()

# CT: 091xx planning regions → 090xx counties (allocation factors provided)
stopifnot(exists("ct_fips_changes_raw"))
ct_pr_to_county <- ct_fips_changes_raw %>%
  transmute(
    from_fips = nf5(`Connecticut planning region`),
    to_fips   = nf5(`County code`),
    alloc     = as.numeric(`CTcounty-to-county allocation factor`)
  ) %>%
  filter(!is.na(alloc), alloc > 0)

dbg(hi_map,        "xwalk HI 15901 -> 15009/15005")
dbg(va_combo_map,  "xwalk VA 519xx -> components")
dbg(ct_pr_to_county,"xwalk CT PR -> counties")

# General-purpose expander
expand_by_xwalk <- function(df_long, xw, label) {
  before <- nrow(df_long)
  out <- df_long %>%
    mm_left_join(xw, by = c("GeoFIPS" = "from_fips")) %>%
    mutate(
      to_fips = if_else(is.na(to_fips), GeoFIPS, to_fips),
      alloc   = if_else(is.na(alloc),   1,       alloc),
      Value   = Value * alloc
    ) %>%
    group_by(Table, to_fips, Year, LineCode, IndustryClassification, Description, Unit) %>%
    summarise(Value = sum(Value, na.rm = TRUE), .groups = "drop") %>%
    left_join(
      df_long %>% select(GeoFIPS, GeoName) %>% distinct(),
      by = c("to_fips" = "GeoFIPS")
    ) %>%
    rename(GeoFIPS = to_fips, GeoName = GeoName)
  after <- nrow(out)
  msg("%s: rows %s -> %s", label, format(before, big.mark=","), format(after, big.mark=","))
  out
}

expand_specials <- function(df_long) {
  out <- df_long
  out <- expand_by_xwalk(out, hi_map,         "HI expand")
  out <- expand_by_xwalk(out, va_combo_map,   "VA expand")
  out <- expand_by_xwalk(out, ct_pr_to_county,"CT expand")
  out
}

C11_EXP <- expand_specials(CAGDP11_LONG)
C02_EXP <- expand_specials(CAGDP2_LONG)
dbg(C11_EXP, "CAGDP11 (expanded)")
dbg(C02_EXP, "CAGDP2 (expanded)")

# Coverage sanity (shared years only)
overlap_years <- intersect(unique(C11_EXP$Year), unique(C02_EXP$Year))
M11 <- C11_EXP %>% filter(Year %in% overlap_years) %>% distinct(Year, GeoFIPS)
M02 <- C02_EXP %>% filter(Year %in% overlap_years) %>% distinct(Year, GeoFIPS)
missing_in_11 <- anti_join(M02, M11, by = c("Year","GeoFIPS"))
missing_in_02 <- anti_join(M11, M02, by = c("Year","GeoFIPS"))
if (nrow(missing_in_11) == 0 && nrow(missing_in_02) == 0) {
  msg("[OK] No CAGDP coverage discrepancies after expansions.")
} else {
  if (nrow(missing_in_11) > 0) { msg("[WARN] In CAGDP2 not in CAGDP11:"); print(missing_in_11 %>% count(Year, name="n")) }
  if (nrow(missing_in_02) > 0) { msg("[WARN] In CAGDP11 not in CAGDP2:"); print(missing_in_02 %>% count(Year, name="n")) }
}

# ------------------------ Legacy wide-ish raws (compat only) --------------
county_gdp_ind <- cagdp11_raw %>%
  mutate(
    GeoFIPS     = nf5(str_trim(GeoFIPS)),
    LineCode    = suppressWarnings(as.integer(LineCode)),
    Description = str_squish(Description),
    Unit        = str_squish(Unit)
  )
county_gdp_ind2 <- cagdp2_raw %>%
  mutate(
    GeoFIPS     = nf5(str_trim(GeoFIPS)),
    LineCode    = suppressWarnings(as.integer(LineCode)),
    Description = str_squish(Description),
    Unit        = str_squish(Unit)
  )
yr_cols_raw <- intersect(as.character(2001:2023), names(county_gdp_ind2))
county_gdp_ind2 <- county_gdp_ind2 %>%
  mutate(across(all_of(yr_cols_raw), numify)) %>%
  rename_with(~ paste0("X", .x), all_of(yr_cols_raw))

# ------------------------ Build clean county-level subset ------------------
needed_linecodes <- c(1, 10, 11, 13, 60) # total, utilities, construction, durable mfg, prof/sci/tech
C02_NEED <- C02_EXP %>% filter(LineCode %in% needed_linecodes)

# ------------------------ Geo alignment scaffolding ------------------------
stopifnot(exists("geo"))
if (!exists("geographies")) {
  geographies <- c("State.Name","cd_119","PEA","CBSA.Title","GeoName")
}

# Helper to robustly extract chr columns (works if list/data.frame columns appear)
extract_chr_col <- function(df, col) {
  x <- df[[col]]
  if (is.null(x)) return(NULL)
  if (is.list(x) && !is.atomic(x)) {
    purrr::map_chr(x, function(.x) {
      if (is.null(.x)) return(NA_character_)
      if (is.atomic(.x)) return(as.character(.x[1]))
      if (is.data.frame(.x)) {
        vals <- unlist(.x, use.names = FALSE)
        vals <- vals[!is.na(vals)]
        if (length(vals)) return(as.character(vals[1])) else return(NA_character_)
      }
      as.character(.x)
    })
  } else as.character(x)
}

# Build master target keys from geo_long if present & valid; else derive from geo
get_geo_long_keys <- function() {
  if (exists("geo_long") && is.data.frame(geo_long)) {
    gl_cols <- names(geo_long)
    msg("geo_long present. Columns: %s", paste(gl_cols, collapse=", "))
    if (all(c("geo","geo_name") %in% gl_cols)) {
      g <- tibble(
        geo      = extract_chr_col(geo_long, "geo"),
        geo_name = extract_chr_col(geo_long, "geo_name")
      ) %>%
        mutate(geo = str_squish(geo), geo_name = str_squish(geo_name)) %>%
        filter(!is.na(geo), !is.na(geo_name), geo != "", geo_name != "") %>%
        distinct() %>%
        mutate(.ord = row_number())
      return(g)
    } else {
      msg("[WARN] geo_long lacks required columns `geo` and/or `geo_name`. Falling back to `geo`.")
    }
  }
  # Fallback: derive a faithful long key set from `geo`
  g <- bind_rows(
    geo %>% filter(!is.na(State.Name))      %>% transmute(geo="State",                   geo_name=State.Name),
    geo %>% filter(!is.na(cd_119))          %>% transmute(geo="Congressional District",  geo_name=cd_119),
    geo %>% filter(!is.na(PEA))             %>% transmute(geo="Economic Area",           geo_name=PEA),
    geo %>% filter(!is.na(`CBSA.Title`))    %>% transmute(geo="Metro Area",              geo_name=`CBSA.Title`),
    geo %>% filter(!is.na(GeoName))         %>% transmute(geo="County",                  geo_name=GeoName)
  ) %>% mutate(geo = as.character(geo), geo_name = as.character(geo_name)) %>%
    distinct() %>% mutate(.ord = row_number())
  msg("[INFO] Derived geo_long_keys from `geo` (rows=%s).", nrow(g))
  g
}
geo_long_keys <- get_geo_long_keys()
dbg(geo_long_keys, "geo_long_keys (target keys)")

# Build per-geography county→geo mappings (unique pairs)
geo_key <- geo %>%
  mutate(fips = nf5(fips)) %>%
  select(fips, all_of(geographies), percent_district) %>%
  distinct()

make_mapping <- function(geog) {
  base <- geo_key %>% select(fips, !!sym(geog), percent_district) %>% distinct()
  if (geog == "cd_119") {
    out <- base %>% filter(!is.na(!!sym(geog))) %>%
      rename(geo_id = !!sym(geog), weight = percent_district) %>%
      mutate(weight = coalesce(as.numeric(weight), 0) / 100)
  } else {
    out <- base %>% filter(!is.na(!!sym(geog))) %>%
      rename(geo_id = !!sym(geog)) %>%
      mutate(weight = 1)
  }
  out %>% distinct(fips, geo_id, .keep_all = TRUE)
}
geo_maps <- setNames(lapply(geographies, make_mapping), geographies)

# Duplicate audit on maps
for (geog in names(geo_maps)) {
  dup_ct <- geo_maps[[geog]] %>% count(fips, geo_id) %>% filter(n > 1)
  if (nrow(dup_ct)) {
    msg("[WARN] Mapping duplicates for %s: %s rows (showing up to 10)", geog, nrow(dup_ct))
    print(utils::head(dup_ct, 10))
  }
}

# ------------------------ Aggregate GDP by geography -----------------------
# Years needed for growth calcs; keep LineCode THROUGH aggregation
C02_NEED_YRS <- C02_NEED %>%
  filter(Year %in% c(2013, 2018, 2022, 2023)) %>%
  select(GeoFIPS, Year, LineCode, Description, Value)

# County×Line wide (for clean weighted sums)
C02_WIDE <- C02_NEED_YRS %>%
  mutate(Y = paste0("Y", Year)) %>%
  select(-Year) %>%
  pivot_wider(names_from = Y, values_from = Value) %>%
  rename(fips = GeoFIPS) %>%
  mutate(across(starts_with("Y"), ~coalesce(., 0)))  # replace NA with 0 before weighting/summing
dbg(C02_WIDE, "C02_WIDE (county x line; Y2013/Y2018/Y2022/Y2023)")

# Aggregate with weights; keep LineCode (robust to text drift)
results_list <- list()
for (geog in geographies) {
  mp <- geo_maps[[geog]]
  joined <- C02_WIDE %>% mm_inner_join(mp, by = "fips")
  agg <- joined %>%
    group_by(geo_id, LineCode) %>%
    summarise(
      GDP13 = sum(Y2013 * weight, na.rm = TRUE),
      GDP18 = sum(Y2018 * weight, na.rm = TRUE),
      GDP22 = sum(Y2022 * weight, na.rm = TRUE),
      GDP23 = sum(Y2023 * weight, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    mutate(geo = dplyr::case_when(
      geog == "State.Name" ~ "State",
      geog == "cd_119"     ~ "Congressional District",
      geog == "PEA"        ~ "Economic Area",
      geog == "CBSA.Title" ~ "Metro Area",
      geog == "GeoName"    ~ "County",
      TRUE ~ geog
    )) %>%
    rename(geo_name = geo_id)
  msg("Agg (%s): %s rows", geog, format(nrow(agg), big.mark=","))
  results_list[[geog]] <- agg
}
county_gdp_industry <- bind_rows(results_list) %>% distinct()
dbg(county_gdp_industry, "county_gdp_industry (aggregated, by LineCode)")

# ------------------------ Growth + contribution shares --------------------
# Growth: if base==0 → NA (avoid infinite), but we already zero-filled inputs
safe_growth <- function(n1, n0) {
  out <- (n1 / dplyr::na_if(n0, 0) - 1) * 100
  out[is.nan(out) & n1 == 0 & n0 == 0] <- 0
  round(out, 1)
}

countygdp_industry2 <- county_gdp_industry %>%
  mutate(
    gdp_10yr = safe_growth(GDP23, GDP13),
    gdp_5yr  = safe_growth(GDP23, GDP18),
    gdp_1yr  = safe_growth(GDP23, GDP22)
  ) %>%
  group_by(geo, LineCode) %>%
  mutate(
    total_gdp_diff_2223 = sum(GDP23 - GDP22, na.rm = TRUE),
    gdp_22_23 = dplyr::if_else(total_gdp_diff_2223 == 0, 0,
                               round(((GDP23 - GDP22) / total_gdp_diff_2223) * 100, 1)),
    total_gdp_diff_1323 = sum(GDP23 - GDP13, na.rm = TRUE),
    gdp_13_23 = dplyr::if_else(total_gdp_diff_1323 == 0, 0,
                               round(((GDP23 - GDP13) / total_gdp_diff_1323) * 100, 1))
  ) %>%
  ungroup() %>%
  select(geo, geo_name, LineCode, gdp_10yr, gdp_5yr, gdp_1yr, GDP23, gdp_22_23, gdp_13_23)

dbg(countygdp_industry2, "countygdp_industry2 (growth + shares)")

# Contribution sanity: should sum ~100 within each (geo, LineCode)
contrib_check <- countygdp_industry2 %>%
  group_by(geo, LineCode) %>%
  summarise(sum_share_22_23 = round(sum(gdp_22_23, na.rm = TRUE), 1),
            sum_share_13_23 = round(sum(gdp_13_23, na.rm = TRUE), 1), .groups = "drop")
msg("Contribution check (first 12 rows):")
print(utils::head(contrib_check, 12))

# ------------------------ Wide tables for legacy outputs ------------------
# Map the specific LineCodes to output variable stems
line_to_var <- c(`1`="total", `13`="durable_man", `60`="prof_science_tech")

county_gdp_5yr <- countygdp_industry2 %>%
  filter(as.character(LineCode) %in% names(line_to_var)) %>%
  mutate(var = paste0(line_to_var[as.character(LineCode)], "_5yrgdp")) %>%
  select(geo, geo_name, var, gdp_5yr) %>%
  distinct() %>%
  pivot_wider(names_from = var, values_from = gdp_5yr)

county_gdp_contr <- countygdp_industry2 %>%
  filter(as.character(LineCode) %in% names(line_to_var)) %>%
  mutate(var = paste0(line_to_var[as.character(LineCode)], "_gdp_2223_contr")) %>%
  select(geo, geo_name, var, gdp_22_23) %>%
  distinct() %>%
  pivot_wider(names_from = var, values_from = gdp_22_23)

county_gdp_10yr <- countygdp_industry2 %>%
  filter(LineCode == 1) %>%
  transmute(geo, geo_name, total_gdp_10yr = gdp_10yr) %>%
  distinct()

county_gdp_1yr <- countygdp_industry2 %>%
  filter(LineCode == 1) %>%
  transmute(geo, geo_name, total_gdp_1yr = gdp_1yr) %>%
  distinct()

# ------------------------ Align to geo_long_keys & finalize ---------------
# Force EXACT key coverage + ordering to geo_long (or fallback) using .ord
county_gdp_ind_final <- geo_long_keys %>%
  select(geo, geo_name, .ord) %>%
  left_join(county_gdp_10yr,  by = c("geo","geo_name")) %>%
  left_join(county_gdp_1yr,   by = c("geo","geo_name")) %>%
  left_join(county_gdp_5yr,   by = c("geo","geo_name")) %>%
  left_join(county_gdp_contr, by = c("geo","geo_name")) %>%
  arrange(.ord) %>%
  select(-.ord)

dbg(county_gdp_ind_final, "county_gdp_ind_final (final)")

# Alignment checks vs target keys
missing_in_final <- anti_join(geo_long_keys %>% select(geo, geo_name),
                              county_gdp_ind_final %>% select(geo, geo_name) %>% distinct(),
                              by = c("geo","geo_name"))
extra_in_final   <- anti_join(county_gdp_ind_final %>% select(geo, geo_name) %>% distinct(),
                              geo_long_keys %>% select(geo, geo_name),
                              by = c("geo","geo_name"))

msg("Keys missing in final (should be 0): %s", nrow(missing_in_final))
if (nrow(missing_in_final)) print(utils::head(missing_in_final, 20))
msg("Extra keys in final (should be 0): %s", nrow(extra_in_final))
if (nrow(extra_in_final)) print(utils::head(extra_in_final, 20))

# NA diagnostics
dbg_count_na(
  county_gdp_ind_final,
  c("geo","geo_name","total_gdp_10yr","total_gdp_1yr",
    "total_5yrgdp","durable_man_5yrgdp","prof_science_tech_5yrgdp",
    "total_gdp_2223_contr","durable_man_gdp_2223_contr","prof_science_tech_gdp_2223_contr"),
  "county_gdp_ind_final -- columns"
)

# Focused diagnostics for potential sparse lines (esp. prof_science_tech)
na_prof <- county_gdp_ind_final %>%
  filter(is.na(prof_science_tech_5yrgdp)) %>%
  count(geo, name = "n_na") %>% arrange(desc(n_na))
msg("Top NA counts for prof_science_tech_5yrgdp by geo (first 10):")
print(utils::head(na_prof, 10))

# Sanity: confirm geo categories overlap between target keys and aggregates
cat_overlap <- setdiff(unique(geo_long_keys$geo), unique(countygdp_industry2$geo))
if (length(cat_overlap)) {
  msg("[WARN] geo categories in geo_long with no aggregates: %s", paste(cat_overlap, collapse=", "))
} else {
  msg("[OK] All geo categories in geo_long are covered by aggregates.")
}

# ===================================================================
# END
# ===================================================================


 
#ACS 5-year 2023 vitality stats
acs_vars <- c("NAME","B19013_001E","B17020_001E","B99172_001E","C18120_003E","C18120_002E","B23025_001E","B25004_001E","B01003_001E")
acs_5yr_23_raw <- getCensus(name="acs/acs5", vars=acs_vars, region="county:*", regionin="state:*", vintage=2023) %>% fix_df(); dbg(acs_5yr_23_raw,"acs_5yr_23_raw")
acs_5yr_23 <- acs_5yr_23_raw %>% mutate(county_geoid=paste0(stringr::str_pad(state,2,pad="0"),stringr::str_pad(county,3,pad="0")))  %>% fix_df(); dbg(acs_5yr_23,"acs_5yr_23 (with county_geoid)")

# --- Treat ACS sentinel codes as NA before any calculations ---
acs_sentinels <- c(-666666666, -222222222, -888888888, -999999999)
to_na <- function(x) { x <- suppressWarnings(as.numeric(x)); dplyr::na_if(x, acs_sentinels[1]) |> 
  dplyr::na_if(acs_sentinels[2]) |> dplyr::na_if(acs_sentinels[3]) |> 
  dplyr::na_if(acs_sentinels[4]) }

acs_5yr_23 <- acs_5yr_23 %>%
  mutate(
    across(c(B19013_001E, B17020_001E, B99172_001E, C18120_003E, C18120_002E,
             B23025_001E, B25004_001E, B01003_001E), to_na)
  )


# ------------------------------------------------------------
# Vitality Stats — CT county fix + robust pipeline (append-only)
# ------------------------------------------------------------

# --- 0) Small helpers ----------------------------------------------------------
if (!exists("dbg")) {
  dbg <- function(x, name = deparse(substitute(x)), n = 5) {
    cat("\n====", name, "====\n")
    cat("Rows:", nrow(x), " Cols:", ncol(x), "\n")
    print(dplyr::as_tibble(x) %>% head(n))
    invisible(x)
  }
}

approx_equal <- function(a, b, tol = 1e-6) isTRUE(all.equal(as.numeric(a), as.numeric(b), tolerance = tol))
assert_approx_equal <- function(a, b, what, tol = 1e-6) {
  if (!approx_equal(a, b, tol)) stop(sprintf("[CHECK FAILED] %s not conserved (%.6f vs %.6f)", what, as.numeric(a), as.numeric(b)))
}

# --- 1) Clean & prepare CT crosswalk (planning regions ↔ legacy counties) -----
# ct_fips_changes_raw already exists and has a header row we drop.
ct_xwalk <- ct_fips_changes_raw %>%
  filter(str_detect(CTcounty, "^09\\d\\d\\d$"),
         str_detect(county, "^09\\d\\d\\d$")) %>%
  transmute(
    ct_county_geoid = str_pad(CTcounty, 5, pad = "0"),
    pr_geoid        = str_pad(county, 5, pad = "0"),
    pr_name         = CountyName,
    ct_county_name0 = CTCountyName,
    pop20           = suppressWarnings(parse_number(pop20)),
    share_pr_to_ct  = suppressWarnings(parse_number(afact2)), # PR -> county
    share_ct_to_pr  = suppressWarnings(parse_number(afact))    # county -> PR
  ) %>%
  mutate(ct_county_name = str_replace(ct_county_name0, " CT$", " County, Connecticut"))

dbg(ct_xwalk, "ct_xwalk (cleaned)")

# Sanity: shares ≈ 1
xw_check1 <- ct_xwalk %>% group_by(pr_geoid)        %>% summarise(sum_share = sum(share_pr_to_ct, na.rm = TRUE), .groups="drop")
xw_check2 <- ct_xwalk %>% group_by(ct_county_geoid) %>% summarise(sum_share = sum(share_ct_to_pr, na.rm = TRUE), .groups="drop")
if (any(abs(xw_check1$sum_share - 1) > 1e-3)) warning("Some PR -> county shares do not sum to ~1")
if (any(abs(xw_check2$sum_share - 1) > 1e-3)) warning("Some CT county -> PR shares do not sum to ~1")

# --- 2) CT county names from 2020 tigris counties -----------------------------
ct_names_ref <- tigris_counties_2020_raw %>%
  sf::st_drop_geometry() %>%
  filter(STATEFP == "09") %>%
  transmute(
    ct_county_geoid = GEOID,
    NAME_ref = paste0(NAMELSAD, ", Connecticut")
  )

# --- 3) Split ACS into CT (planning regions) vs non-CT ------------------------
stopifnot("county_geoid" %in% names(acs_5yr_23))
acs_ct_pr  <- acs_5yr_23 %>% filter(state == "09")
acs_non_ct <- acs_5yr_23 %>% filter(state != "09")
dbg(acs_ct_pr,  "acs_ct_pr (as returned by ACS, planning regions)")
dbg(acs_non_ct, "acs_non_ct (untouched)")

# Identify variable types
count_vars  <- c("B17020_001E","B99172_001E","C18120_003E","C18120_002E","B23025_001E","B25004_001E","B01003_001E")
median_like <- "B19013_001E"

# --- 4) Reallocate CT planning region values back to *legacy* CT counties -----
n_ct_before <- nrow(acs_ct_pr)

acs_ct_alloc_expanded <- acs_ct_pr %>%
  inner_join(ct_xwalk %>% select(pr_geoid, ct_county_geoid, share_pr_to_ct),
             by = c("county_geoid" = "pr_geoid")) %>%
  mutate(w_pop_alloc = B01003_001E * share_pr_to_ct) %>%      # weight for medians
  mutate(across(all_of(count_vars), ~ .x * share_pr_to_ct))   # allocate additive counts

dbg(acs_ct_alloc_expanded, "acs_ct_alloc_expanded (CT only, expanded by shares)")

acs_ct_counties <- acs_ct_alloc_expanded %>%
  group_by(ct_county_geoid) %>%
  summarise(
    across(all_of(count_vars), \(x) sum(x, na.rm = TRUE)),
    B19013_001E = if (sum(w_pop_alloc, na.rm = TRUE) > 0)
      sum(B19013_001E * w_pop_alloc, na.rm = TRUE) / sum(w_pop_alloc, na.rm = TRUE)
    else NA_real_,
    .groups = "drop"
  ) %>%
  mutate(
    state        = "09",
    county       = str_sub(ct_county_geoid, 3, 5),
    county_geoid = ct_county_geoid
  ) %>%
  left_join(ct_names_ref, by = "ct_county_geoid") %>%
  mutate(NAME = coalesce(NAME_ref, paste0(ct_county_geoid, " (CT legacy county)"))) %>%
  select(state, county, NAME, all_of(c(median_like, count_vars)), county_geoid)

dbg(acs_ct_counties, "acs_ct_counties (legacy 8 counties reconstructed)")

# Guard: we should have exactly 8 legacy CT counties
stopifnot(nrow(acs_ct_counties) == 8)

# --- 5) Conservation checks (no silent drift) ---------------------------------
ct_tot_before <- acs_ct_pr %>% summarise(across(all_of(count_vars), ~ sum(.x, na.rm = TRUE)))
ct_tot_after  <- acs_ct_counties %>% summarise(across(all_of(count_vars), ~ sum(.x, na.rm = TRUE)))
for (v in count_vars) assert_approx_equal(ct_tot_before[[v]], ct_tot_after[[v]], paste0("CT total for ", v), tol = 1e-4)

# --- 6) Stitch back the full ACS table ----------------------------------------
acs_5yr_23_fixed <- bind_rows(acs_non_ct, acs_ct_counties) %>% arrange(state, county)
dbg(acs_5yr_23_fixed, "acs_5yr_23_fixed (CT legacy counties in place)")

# Keep the working name expected by downstream code
acs_5yr_23 <- acs_5yr_23_fixed

# --- 7) Legacy vitality-stat transforms ---------------------------------------
acs_5yr_23 <- acs_5yr_23 %>%
  rename(
    med_house_inc = B19013_001E,
    pov_tot       = B17020_001E,  # legacy behavior
    pov_family    = B99172_001E,
    empl          = C18120_003E,
    lab_force     = C18120_002E,
    emp_21        = B23025_001E,
    vacancy       = B25004_001E,
    pop           = B01003_001E
  ) %>%
  mutate(
    unemp        = (1 - empl / lab_force) * 100,
    pov_rate     = (1 - pov_tot / pop) * 100,  # legacy parity
    emp_pop      = (empl / pop) * 100,
    med_inc_perc = med_house_inc / median(med_house_inc, na.rm = TRUE) * 100
  )

# --- 8) Join to geo (for labels & crosswalks) ---------------------------------
acs_5yr_23 <- acs_5yr_23 %>%
  #Add in a "fips" column that is just county_geoid; make it a new column in the data frame in addition to county_geoid
  mutate(fips = county_geoid) %>%
  left_join(geo, by = "fips")

dbg(acs_5yr_23, "acs_5yr_23 (ready for geography aggregation)")

# --- 9) Vitality Stats aggregation (warning-free & CD dedupe) ------------------
# Vector of metrics to aggregate
metric_cols <- c("med_house_inc", "med_inc_perc", "pov_rate", "emp_pop", "vacancy", "unemp")

results_list <- list()
for (geog in geographies) {
  if (geog == "cd_119") {
    # Deduplicate by county within each district and pre-compute weights
    base_cd <- acs_5yr_23 %>%
      distinct(cd_119, county_geoid, pop, percent_district, !!!syms(metric_cols)) %>%
      mutate(w = pop * percent_district / 100)
    
    vit <- base_cd %>%
      group_by(cd_119) %>%
      summarise(
        across(all_of(metric_cols), \(x) {
          if (sum(w, na.rm = TRUE) > 0) weighted.mean(x, w = w, na.rm = TRUE) else NA_real_
        }),
        .groups = "drop"
      )
  } else {
    vit <- acs_5yr_23 %>%
      group_by(!!sym(geog)) %>%
      # Retain legacy distinct logic (parity with your snippet)
      distinct(!!sym(geog), pop, !!!syms(metric_cols)) %>%
      summarise(
        across(all_of(metric_cols), \(x) weighted.mean(x, w = .data$pop, na.rm = TRUE)),
        .groups = "drop"
      )
  }
  results_list[[geog]] <- vit
}

vit <- bind_rows(results_list) %>%
  mutate(geo = case_when(
    !is.na(State.Name) ~ "State",
    !is.na(cd_119)     ~ "Congressional District",
    !is.na(PEA)        ~ "Economic Area",
    !is.na(GeoName)    ~ "County",
    TRUE               ~ "Metro Area"
  )) %>%
  mutate(geo_name = case_when(
    !is.na(State.Name) ~ State.Name,
    !is.na(cd_119)     ~ cd_119,
    !is.na(PEA)        ~ PEA,
    !is.na(GeoName)    ~ GeoName,
    TRUE               ~ CBSA.Title
  )) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  select(geo, geo_name, all_of(metric_cols)) %>%
  group_by(geo) %>%
  mutate(med_inc_rank = rank(-med_house_inc)) %>%
  ungroup()

dbg(vit, "vit (final)")

# --- 10) Population table (legacy-compatible, CD dedupe) -----------------------
results_list <- list()
for (geog in geographies) {
  if (geog == "cd_119") {
    pop_df <- acs_5yr_23 %>%
      distinct(cd_119, county_geoid, pop, percent_district) %>%
      group_by(cd_119) %>%
      summarise(pop = sum(pop * percent_district / 100, na.rm = TRUE), .groups = "drop")
  } else {
    pop_df <- acs_5yr_23 %>%
      group_by(!!sym(geog)) %>%
      distinct(!!sym(geog), pop) %>%
      summarise(pop = sum(pop, na.rm = TRUE), .groups = "drop")
  }
  results_list[[geog]] <- pop_df
}

pop <- bind_rows(results_list) %>%
  mutate(geo = case_when(
    !is.na(State.Name) ~ "State",
    !is.na(cd_119)     ~ "Congressional District",
    !is.na(PEA)        ~ "Economic Area",
    !is.na(GeoName)    ~ "County",
    TRUE               ~ "Metro Area"
  )) %>%
  mutate(geo_name = case_when(
    !is.na(State.Name) ~ State.Name,
    !is.na(cd_119)     ~ cd_119,
    !is.na(PEA)        ~ PEA,
    !is.na(GeoName)    ~ GeoName,
    TRUE               ~ CBSA.Title
  )) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  select(geo, geo_name, pop)

dbg(pop, "pop (final)")

# ---- Property Values ----
county_property_values_raw <- suppressWarnings(read.csv(file.path(paths$raw_data,"county_property_values.csv"), check.names=FALSE)) %>% fix_df()
dbg(county_property_values_raw,"county_property_values_raw")

#Create county_geoid column as character, padding with leading zeros if necessary, using GEOID as base
county_property_values_raw <- county_property_values_raw %>%
  mutate(GEOID = str_pad(as.character(GEOID), 5, pad = "0"))
dbg(county_property_values_raw,"county_property_values_raw (with padded GEOID)")

# helper to standardize any GEOID-like field to 5-char string
std_geoid <- function(x) stringr::str_pad(as.character(x), 5, pad = "0")

county_prop <- county_property_values_raw %>%
  # keep GEOID as 5-char character
  mutate(GEOID = std_geoid(GEOID)) %>%
  select(-NAME) %>%
  # make sure geo$fips is also 5-char character before joining
  left_join(
    geo %>% mutate(fips = std_geoid(fips)),
    by = c("GEOID" = "fips")
  ) %>%
  # keep TIGRIS GEOID as character; only ALAND needs numeric
  left_join(
    tigris_counties_2020_raw %>%
      sf::st_drop_geometry() %>%
      transmute(
        GEOID = std_geoid(GEOID),
        ALAND = as.numeric(ALAND)
      ),
    by = "GEOID"
  )

dbg(county_prop,"county_prop after joins")

results_list <- list()
for (geog in geographies) {
  prop <- if (geog=="cd_119") {
    county_prop %>% group_by(!!rlang::sym(geog)) %>%
      summarize(PropertyValueUSD=weighted.mean(PropertyValueUSD,w=ALAND*percent_district/100,na.rm=TRUE))
  } else {
    county_prop %>% group_by(!!rlang::sym(geog)) %>%
      distinct(!!rlang::sym(geog),PropertyValueUSD,ALAND,.keep_all=TRUE) %>%
      summarize(PropertyValueUSD=weighted.mean(PropertyValueUSD,w=ALAND,na.rm=TRUE))
  }
  dbg(prop,paste0("prop aggregated at ",geog))
  results_list[[geog]] <- prop
}

# keep 'prop' numeric all the way through
prop <- dplyr::bind_rows(results_list) %>%
  mutate(
    geo = case_when(!is.na(State.Name) ~ "State", !is.na(cd_119) ~ "Congressional District",
                    !is.na(PEA) ~ "Economic Area", !is.na(GeoName) ~ "County", TRUE ~ "Metro Area"),
    geo_name = case_when(!is.na(State.Name) ~ State.Name, !is.na(cd_119) ~ cd_119,
                         !is.na(PEA) ~ PEA, !is.na(GeoName) ~ GeoName, TRUE ~ CBSA.Title)
  ) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  select(geo, geo_name, PropertyValueUSD) %>%
  group_by(geo) %>%
  mutate(PropertyValue_Rank = rank(-PropertyValueUSD, ties.method = "min")) %>%
  ungroup()

# (Optional) export-friendly copy where you blank NA as strings
prop_export <- prop %>% mutate(
  across(where(is.numeric), ~ ifelse(is.na(.), "", as.character(.)))
)
dbg(prop, "prop (final)")

# --- read TechPot once (assumes paths + fix_df available) ---
techpot_county_raw <- suppressWarnings(read.csv(
  file.path(paths$raw_data, "NREL SLOPE", "techpot_baseline", "techpot_baseline_county.csv"),
  check.names = FALSE
)) %>% fix_df()

# --- helpers ---
normalize_name <- function(x) {
  x %>% str_trim() %>% str_to_lower() %>%
    str_replace_all("\\bst\\.?\\b", "saint") %>%
    str_replace_all("\\bste\\.?\\b", "sainte") %>%
    str_replace_all("[[:punct:]&&[^']]", " ") %>%  # keep apostrophes
    str_squish()
}
repair_county_norm <- function(x) {
  x %>%
    str_replace("^o brien$", "o'brien") %>%
    str_replace("^prince george s$", "prince george's") %>%
    str_replace("^queen anne s$", "queen anne's") %>%
    str_replace("^saint mary s$", "saint mary's")
}

# --- TIGRIS lookups (territories excluded) ---
territory_statefps <- c("60","66","69","72","74","78")  # AS, GU, MP, PR, UM, VI

tigris_states_for_techpot_lookup <- tigris_states_2024_raw %>%
  st_drop_geometry() %>%                                 # <-- drop geometry here
  filter(!STATEFP %in% territory_statefps) %>%
  transmute(
    STATEFP, STUSPS,
    TIGRIS_STATE_NAME = NAME,
    state_name_norm = normalize_name(NAME)
  )

# keep county geometry + CBSA for final enrichment
tigris_counties_for_techpot_lookup <- tigris_counties_2020_raw %>%
  filter(!STATEFP %in% territory_statefps) %>%
  transmute(
    GEOID, STATEFP, CBSAFP,
    TIGRIS_COUNTY_NAME = NAME,      # short name (e.g., "O'Brien")
    TIGRIS_NAMELSAD    = NAMELSAD,  # full (e.g., "O'Brien County")
    geometry
  ) %>%
  left_join(tigris_states_for_techpot_lookup, by = "STATEFP") %>%
  mutate(county_name_norm = normalize_name(TIGRIS_COUNTY_NAME)) %>%
  distinct(STATEFP, county_name_norm, .keep_all = TRUE)

# --- TechPot unique county-state pairs (names only, then repair) ---
techpot_counties_unique <- techpot_county_raw %>%
  select(`County Name`, `State Name`) %>% distinct() %>%
  mutate(
    tp_state_name_norm  = normalize_name(`State Name`),
    tp_county_name_norm = normalize_name(`County Name`),
    tp_county_name_norm_repaired = repair_county_norm(tp_county_name_norm)
  ) %>%
  left_join(
    tigris_states_for_techpot_lookup %>% select(STATEFP, state_name_norm),
    by = c("tp_state_name_norm" = "state_name_norm")
  ) %>%
  filter(!is.na(STATEFP)) %>%
  distinct(STATEFP, tp_county_name_norm, .keep_all = TRUE)

# --- two-pass match: normalized then repaired to get county_geoid_from_tigris ---
tp_join1 <- techpot_counties_unique %>%
  left_join(
    tigris_counties_for_techpot_lookup %>%
      st_drop_geometry() %>% select(STATEFP, county_name_norm, GEOID),
    by = c("STATEFP", "tp_county_name_norm" = "county_name_norm")
  )

tp_join2 <- tp_join1 %>%
  left_join(
    tigris_counties_for_techpot_lookup %>%
      st_drop_geometry() %>% select(STATEFP, county_name_norm, GEOID) %>%
      rename(GEOID_repaired = GEOID),
    by = c("STATEFP", "tp_county_name_norm_repaired" = "county_name_norm")
  ) %>%
  mutate(county_geoid_from_tigris = coalesce(GEOID, GEOID_repaired)) %>%
  select(-GEOID, -GEOID_repaired)

# --- final enriched output (sf): techpot_county_with_geoid ---------------
techpot_county_with_geoid <- tp_join2 %>%
  left_join(
    tigris_counties_for_techpot_lookup %>%
      select(
        GEOID,
        county_name_full = TIGRIS_NAMELSAD,
        state_fips = STATEFP,
        geometry,
        cbsa_code = CBSAFP
      ),
    by = c("county_geoid_from_tigris" = "GEOID")
  ) %>%
  transmute(
    county_name_techpot = `County Name`,
    state_name_techpot  = `State Name`,
    state_fips,
    county_geoid_from_tigris,
    county_name_full,
    cbsa_code,
    geometry
  ) %>%
  st_as_sf()

dbg(techpot_county_with_geoid, "techpot_county_with_geoid (final)")
#Print out all unique state_name_techpot values in alphabetical order, and their total number
unique_states_techpot <- sort(unique(techpot_county_with_geoid$state_name_techpot))
cat("Unique states in TechPot data (", length(unique_states_techpot), "):\n", paste(unique_states_techpot, collapse=", "), "\n")

# --- continue: build TechPot county-level potentials and aggregate by geography ---

# libs needed for the rest of the pipeline
library(tidyr)
suppressPackageStartupMessages({
  if (!"tigris" %in% (.packages())) {
    # safe to load; only used for optional lookups if your preloaded objects aren't present
    library(tigris)
  }
})
options(tigris_use_cache = TRUE, tigris_class = "sf")

# 1) Identify the TechPot generation column robustly (name varies across exports)
tech_gen_col <- names(techpot_county_raw) %>%
  stringr::str_subset(stringr::regex("technical\\s*generation\\s*potential", ignore_case = TRUE)) %>%
  { .[1] }

if (is.na(tech_gen_col)) stop("Could not locate the Technical Generation Potential column in techpot_county_raw.")

# 2) Long-form TechPot at the county level + attach county/state/CBSA keys
techpot_county_long <- techpot_county_raw %>%
  dplyr::select(
    `County Name`, `State Name`,
    Technology = dplyr::any_of("Technology"),
    tech_gen = dplyr::all_of(tech_gen_col)
  ) %>%
  dplyr::mutate(
    tech = dplyr::case_when(
      Technology == "land_based_wind"                      ~ "Wind Potential (MWh)",
      Technology == "utility_pv"                           ~ "Utility Solar Potential (MWh)",
      Technology %in% c("residential_pv", "commercial_pv") ~ "Rooftop Solar Potential (MWh)",
      TRUE ~ NA_character_
    )
  ) %>%
  dplyr::filter(!is.na(tech)) %>%
  dplyr::left_join(
    techpot_county_with_geoid %>%
      sf::st_drop_geometry() %>%
      dplyr::transmute(
        `County Name` = county_name_techpot,
        `State Name`  = state_name_techpot,
        county_geoid  = county_geoid_from_tigris,
        state_fips    = state_fips,
        cbsa_code     = cbsa_code
      ),
    by = c("County Name", "State Name")
  ) %>%
  # Keep only counties that matched to our 50 states + DC lookup
  dplyr::filter(!is.na(county_geoid))

# 3) Readable name lookups
county_lookup <- tigris_counties_for_techpot_lookup %>%
  sf::st_drop_geometry() %>%
  dplyr::transmute(
    county_geoid = GEOID,
    county_name_full = TIGRIS_NAMELSAD,
    state_fips = STATEFP,
    STUSPS,
    State.Name = TIGRIS_STATE_NAME
  )

state_lookup <- tigris_states_for_techpot_lookup %>%
  dplyr::transmute(
    state_fips = STATEFP,
    STUSPS,
    State.Name = TIGRIS_STATE_NAME
  )

# CBSA title lookup (best-effort: use preloaded object if present; otherwise try tigris)
cbsa_lookup <- tryCatch({
  obj <- get0("tigris_cbsa_2020_raw", inherits = TRUE)
  if (!is.null(obj)) {
    obj %>% sf::st_drop_geometry() %>%
      dplyr::transmute(cbsa_code = CBSAFP, CBSA.Title = NAME) %>%
      dplyr::distinct()
  } else {
    tigris::core_based_statistical_areas(year = 2020, cb = TRUE) %>%
      sf::st_drop_geometry() %>%
      dplyr::transmute(cbsa_code = CBSAFP, CBSA.Title = NAME) %>%
      dplyr::distinct()
  }
}, error = function(e) {
  tibble::tibble(cbsa_code = character(), CBSA.Title = character())
})

# 4) Aggregate by major geographies

## County
tech_pot_by_county <- techpot_county_long %>%
  dplyr::group_by(county_geoid, tech) %>%
  dplyr::summarize(tech_pot = sum(tech_gen, na.rm = TRUE), .groups = "drop") %>%
  dplyr::left_join(county_lookup, by = "county_geoid") %>%
  dplyr::transmute(
    geo = "County",
    geo_name = paste0(dplyr::coalesce(county_name_full, ""), dplyr::if_else(!is.na(STUSPS), paste0(", ", STUSPS), "")),
    tech, tech_pot
  )

## State
tech_pot_by_state <- techpot_county_long %>%
  dplyr::group_by(state_fips, tech) %>%
  dplyr::summarize(tech_pot = sum(tech_gen, na.rm = TRUE), .groups = "drop") %>%
  dplyr::left_join(state_lookup, by = "state_fips") %>%
  dplyr::transmute(
    geo = "State",
    geo_name = dplyr::coalesce(State.Name, ""),
    tech, tech_pot
  )

## Metro Areas (CBSA)
tech_pot_by_cbsa <- techpot_county_long %>%
  dplyr::filter(!is.na(cbsa_code) & cbsa_code != "") %>%
  dplyr::group_by(cbsa_code, tech) %>%
  dplyr::summarize(tech_pot = sum(tech_gen, na.rm = TRUE), .groups = "drop") %>%
  dplyr::left_join(cbsa_lookup, by = "cbsa_code") %>%
  dplyr::transmute(
    geo = "Metro Area",
    geo_name = dplyr::coalesce(CBSA.Title, ""),
    tech, tech_pot
  )

## Congressional Districts (119th) — area-weighted county splits
county_cd119_share <- tryCatch({
  xw <- get0("county_to_cd119_xwalk", inherits = TRUE)
  if (!is.null(xw)) {
    xw %>%
      dplyr::transmute(
        county_geoid = as.character(county_geoid),
        cd_119       = as.character(cd_119),
        share        = dplyr::if_else(is.na(share), 0, share)  # in [0,1]
      )
  } else {
    # Build from shapes if no crosswalk provided (may be slow the first time)
    cd_sf <- get0("tigris_cd_2024_raw", inherits = TRUE)
    if (is.null(cd_sf)) {
      cd_sf <- tigris::congressional_districts(year = 2024, cb = TRUE)
    }
    counties_sf <- tigris_counties_for_techpot_lookup %>%
      sf::st_transform(5070) %>%
      dplyr::select(GEOID, geometry)
    cd_sf <- cd_sf %>% sf::st_transform(5070) %>%
      dplyr::select(cd_119 = GEOID, geometry)
    
    suppressWarnings(sf::st_intersection(
      counties_sf %>% dplyr::mutate(county_area = sf::st_area(geometry)),
      cd_sf
    )) %>%
      dplyr::mutate(
        inter_area = sf::st_area(geometry),
        share = as.numeric(inter_area / county_area)
      ) %>%
      sf::st_drop_geometry() %>%
      dplyr::transmute(county_geoid = GEOID, cd_119, share) %>%
      dplyr::filter(share > 0, !is.na(share))
  }
}, error = function(e) {
  tibble::tibble(county_geoid = character(), cd_119 = character(), share = numeric())
})

tech_pot_by_cd <- techpot_county_long %>%
  dplyr::select(county_geoid, tech, tech_gen) %>%
  dplyr::inner_join(county_cd119_share, by = "county_geoid") %>%
  dplyr::group_by(cd_119, tech) %>%
  dplyr::summarize(tech_pot = sum(tech_gen * share, na.rm = TRUE), .groups = "drop") %>%
  dplyr::transmute(
    geo = "Congressional District",
    geo_name = dplyr::coalesce(cd_119, ""),
    tech, tech_pot
  )

## BEA Economic Areas (PEA) — use crosswalk if available
county_pea_xwalk <- tryCatch({
  xw <- get0("county_to_pea_xwalk", inherits = TRUE)
  if (!is.null(xw)) {
    xw %>%
      dplyr::transmute(
        county_geoid = as.character(county_geoid),
        PEA          = as.character(pea_code),
        PEA_Name     = as.character(dplyr::coalesce(pea_name, ""))
      )
  } else {
    xw2 <- get0("bea_pea_county_xwalk_raw", inherits = TRUE)
    if (!is.null(xw2)) {
      xw2 %>%
        dplyr::transmute(
          county_geoid = as.character(FIPS),
          PEA          = as.character(PEA),
          PEA_Name     = as.character(dplyr::coalesce(PEA_Name, ""))
        ) %>% dplyr::distinct()
    } else {
      tibble::tibble(county_geoid = character(), PEA = character(), PEA_Name = character())
    }
  }
}, error = function(e) {
  tibble::tibble(county_geoid = character(), PEA = character(), PEA_Name = character())
})

tech_pot_by_pea <- techpot_county_long %>%
  dplyr::select(county_geoid, tech, tech_gen) %>%
  dplyr::inner_join(county_pea_xwalk, by = "county_geoid") %>%
  dplyr::group_by(PEA, PEA_Name, tech) %>%
  dplyr::summarize(tech_pot = sum(tech_gen, na.rm = TRUE), .groups = "drop") %>%
  dplyr::transmute(
    geo = "Economic Area",
    geo_name = dplyr::if_else(PEA_Name == "" | is.na(PEA_Name), PEA, PEA_Name),
    tech, tech_pot
  )

# 5) Combine all available geographies and proceed to the wide form + rankings
tech_pot_long_all <- dplyr::bind_rows(
  tech_pot_by_state,
  tech_pot_by_cd,
  tech_pot_by_pea,
  tech_pot_by_county,
  tech_pot_by_cbsa
) %>%
  # character fields: blanks instead of NA
  dplyr::mutate(dplyr::across(where(is.character), ~ tidyr::replace_na(., ""))) %>%
  # keep rows that have a label
  dplyr::filter(geo_name != "")

tech_pot_geo <- tech_pot_long_all %>%
  tidyr::pivot_wider(
    names_from  = tech,
    values_from = tech_pot,
    values_fn   = list(tech_pot = ~ sum(.x, na.rm = TRUE))
  ) %>%
  # ---- ensure blanks (not NA) for missing geography text ----
dplyr::mutate(dplyr::across(where(is.character), ~ tidyr::replace_na(., ""))) %>%
  # ---- rankings within each geo type (descending potential) ----
dplyr::group_by(geo) %>%
  dplyr::mutate(
    Solar_potential_rank             = dplyr::min_rank(-as.numeric(`Utility Solar Potential (MWh)`)),
    Wind_potential_rank              = dplyr::min_rank(-as.numeric(`Wind Potential (MWh)`)),
    Rooftop_solar_potential_rank     = dplyr::min_rank(-as.numeric(`Rooftop Solar Potential (MWh)`))
  ) %>%
  dplyr::ungroup()

# Quick debug peek
dbg(tech_pot_geo, "tech_pot_geo (final)")

# === Robust drop-in replacement for renewable supply curves pipeline ===

suppressPackageStartupMessages({
  library(dplyr)
  library(stringr)
  library(purrr)
  library(tibble)
})

options(dplyr.summarise.inform = FALSE)

# -------------------------- Logging & utilities --------------------------
DEBUG_LEVEL <- getOption("supplycurve.debug_level", default = 1L)  # 0=silent,1=info,2=debug,3=trace
MAX_SHOW    <- getOption("supplycurve.max_show",   default = 10L)

.note   <- function(...) if (DEBUG_LEVEL >= 1L) message(sprintf(...))
.debug  <- function(...) if (DEBUG_LEVEL >= 2L) message(sprintf(...))
.trace  <- function(...) if (DEBUG_LEVEL >= 3L) message(sprintf(...))
.warnf  <- function(...) warning(sprintf(...), call. = FALSE)
.failf  <- function(...) stop(sprintf(...), call. = FALSE)
.rule   <- function(x, ch = "=") if (DEBUG_LEVEL >= 1L) message(paste0("\n", paste(rep(ch, 4), collapse=""), " ", x, " ", paste(rep(ch, 4), collapse="")))

dbg_head <- function(df, nm = deparse(substitute(df)), n = 5) {
  if (DEBUG_LEVEL < 2L) return(invisible(df))
  message("\n==== ", nm, " ====")
  message("class: ", paste(class(df), collapse = ", "))
  message("rows x cols: ", nrow(df), " x ", ncol(df))
  print(utils::head(df, n))
  invisible(df)
}

norm_fips <- function(x) {
  x <- as.character(x)
  x <- trimws(x)
  x <- ifelse(is.na(x) | x == "", NA_character_, x)
  x <- stringr::str_replace_all(x, "[^0-9]", "")   # keep digits only
  x <- stringr::str_pad(x, 5, pad = "0")
  # If after cleaning the string isn't 5 digits, set NA (caught later)
  x[!grepl("^[0-9]{5}$", x)] <- NA_character_
  x
}

validate_fips <- function(v, nm, sample_n = MAX_SHOW) {
  bad_idx <- which(is.na(v))
  if (length(bad_idx) > 0) {
    .warnf("%s: %d invalid/NA FIPS after normalization. Showing up to %d examples.",
           nm, length(bad_idx), sample_n)
    .debug(paste("Bad FIPS sample:", paste(utils::head(bad_idx, sample_n), collapse = ", ")))
  }
}

check_required_cols <- function(df, nm, required) {
  missing <- setdiff(required, names(df))
  if (length(missing) > 0) .failf("Missing required columns in %s: %s", nm, paste(missing, collapse = ", "))
}

check_dups <- function(df, key, nm, show = MAX_SHOW) {
  dups <- df %>% count(.data[[key]], name = "n") %>% filter(n > 1)
  if (nrow(dups) > 0) {
    .warnf("Duplicates in %s on key %s: %d (showing %d)", nm, key, nrow(dups), min(nrow(dups), show))
    print(utils::head(dups, show))
  } else {
    .debug("No duplicates in %s on key %s", nm, key)
  }
  invisible(dups)
}

na_report <- function(df, cols, nm, show = MAX_SHOW) {
  out <- purrr::map_dfr(cols, ~tibble(
    column = .x,
    na_cnt = sum(is.na(df[[.x]])),
    non_na = sum(!is.na(df[[.x]]))
  ))
  .note("NA report for %s:\n%s", nm, paste(capture.output(print(out)), collapse = "\n"))
  invisible(out)
}

`%||%` <- function(x, y) if (!is.null(x)) x else y
wavg <- function(x, w) {
  w <- as.numeric(w); x <- as.numeric(x)
  if (all(is.na(x)) || all(is.na(w)) || sum(w[!is.na(w)], na.rm = TRUE) <= 0) return(NA_real_)
  stats::weighted.mean(x, w = w, na.rm = TRUE)
}
sum_safe <- function(x) {
  if (all(is.na(x))) return(NA_real_)
  s <- sum(x, na.rm = TRUE)
  if (is.na(s)) NA_real_ else s
}

apply_fix_df <- function(df) {
  if (exists("fix_df", mode = "function")) tryCatch(fix_df(df), error = function(e) df) else df
}

dedup_county <- function(df, nm, value_col, weight_col) {
  d0 <- nrow(df)
  dups <- check_dups(df, "county_geoid", nm)
  if (nrow(dups) > 0) {
    .warnf("%s: aggregating duplicates to county level (weighted by %s)", nm, weight_col)
    df <- df %>%
      group_by(county_geoid) %>%
      summarise(
        across(all_of(value_col), ~ wavg(.x, .data[[weight_col]])),
        across(all_of(weight_col), sum_safe),
        .groups = "drop"
      )
  }
  d1 <- nrow(df)
  if (d1 < d0) .note("%s: rows %d -> %d after deduplication.", nm, d0, d1)
  df
}

pct_sanitize <- function(p, nm = "percent") {
  p <- as.numeric(p)
  bad <- which(!is.na(p) & (p < 0 | p > 100))
  if (length(bad) > 0) .warnf("%s: %d out-of-range values detected; clamping to [0,100].", nm, length(bad))
  p <- pmin(pmax(p, 0), 100)
  p
}

# -------------------------- Load + normalize inputs --------------------------
.rule("Load raw CSVs")

solar_lcoe_county_raw <- suppressWarnings(
  read.csv(file.path(paths$raw_data, "solar_lcoe_county.csv"), check.names = FALSE)
) %>% apply_fix_df()
wind_lcoe_county_raw  <- suppressWarnings(
  read.csv(file.path(paths$raw_data, "wind_lcoe_county.csv"),  check.names = FALSE)
) %>% apply_fix_df()
geothermal_county_raw <- suppressWarnings(
  read.csv(file.path(paths$raw_data, "geothermal_county.csv"),  check.names = FALSE)
) %>% apply_fix_df()

derive_county_geoid <- function(df, nm) {
  src <- intersect(c("county_geoid", "cnty_fips", "fips", "FIPS", "CountyFIPS"), names(df))
  if (length(src) == 0) .failf("%s: could not find a FIPS column (looked for county_geoid/cnty_fips/fips/FIPS/CountyFIPS).", nm)
  if (!"county_geoid" %in% names(df)) {
    df <- df %>% rename(county_geoid = !!rlang::sym(src[1]))  # <-- use sym(), no tidyselect warning
  }
  df <- df %>% mutate(county_geoid = norm_fips(county_geoid))
  validate_fips(df$county_geoid, nm)
  df
}

solar_lcoe_county_raw <- derive_county_geoid(solar_lcoe_county_raw, "solar_lcoe_county_raw")
wind_lcoe_county_raw  <- derive_county_geoid(wind_lcoe_county_raw,  "wind_lcoe_county_raw")
geothermal_county_raw <- derive_county_geoid(geothermal_county_raw, "geothermal_county_raw")

dbg_head(solar_lcoe_county_raw, "solar_lcoe_county_raw")
dbg_head(wind_lcoe_county_raw,  "wind_lcoe_county_raw")
dbg_head(geothermal_county_raw, "geothermal_county_raw")

# -------------------------- Schema checks per tech --------------------------
check_required_cols(solar_lcoe_county_raw, "solar_lcoe_county_raw",
                    c("county_geoid", "Solar_total_lcoe", "Solar_capacity_mw"))
check_required_cols(wind_lcoe_county_raw,  "wind_lcoe_county_raw",
                    c("county_geoid", "Wind_total_lcoe", "Wind_capacity_mw"))
check_required_cols(geothermal_county_raw, "geothermal_county_raw",
                    c("county_geoid", "Geothermal_total_lcoe", "Geothermal_capacity_mw"))

# -------------------------- Build tech tables (dedup-safe) --------------------------
.rule("Tech tables → county level")

solar_county <- solar_lcoe_county_raw %>%
  transmute(
    county_geoid,
    solar_mean_lcoe      = Solar_total_lcoe,
    solar_total_lcoe     = Solar_total_lcoe,
    solar_capacity_mw_dc = Solar_capacity_mw
  ) %>%
  dedup_county("solar_county", value_col = "solar_total_lcoe", weight_col = "solar_capacity_mw_dc")

wind_county <- wind_lcoe_county_raw %>%
  transmute(
    county_geoid,
    wind_mean_lcoe   = Wind_total_lcoe,
    wind_total_lcoe  = Wind_total_lcoe,
    wind_capacity_mw = Wind_capacity_mw
  ) %>%
  dedup_county("wind_county", value_col = "wind_total_lcoe", weight_col = "wind_capacity_mw")

geothermal_county <- geothermal_county_raw %>%
  transmute(
    county_geoid,
    geothermal_capacity_MW   = Geothermal_capacity_mw,
    geothermal_resource_lcoe = Geothermal_total_lcoe %||% Geothermal_total_lcoe,
    geothermal_total_lcoe    = Geothermal_total_lcoe
  ) %>%
  dedup_county("geothermal_county", value_col = "geothermal_total_lcoe", weight_col = "geothermal_capacity_MW")

# -------------------------- County scaffold (names only; no geometry) --------------------------
county_scaffold <- tigris_counties_2020_raw %>%
  transmute(
    county_geoid = norm_fips(GEOID),
    county       = NAMELSAD
  )

check_dups(county_scaffold, "county_geoid", "county_scaffold")

# -------------------------- Crosswalk QA: LCOE union vs GEO vs TIGRIS --------------------------
.rule("Crosswalk QA")

# Union of all county GEOIDs referenced by any tech
all_county_geoids_for_lcoe <- tibble(
  county_geoid = sort(unique(c(geothermal_county$county_geoid,
                               wind_county$county_geoid,
                               solar_county$county_geoid)))
)

# GEO prep
geo_for_lcoe <- geo %>% mutate(fips = norm_fips(fips))
validate_fips(geo_for_lcoe$fips, "geo$fips")
dbg_head(geo_for_lcoe, "geo (with normalized fips)")

# Attach names from GEO
all_county_geoids_for_lcoe <- all_county_geoids_for_lcoe %>%
  left_join(geo_for_lcoe %>% distinct(fips, GeoName), by = c("county_geoid" = "fips"))

# TIGRIS prep
tigris_counties_2020_raw_for_lcoe <- tigris_counties_2020_raw %>%
  mutate(GEOID = norm_fips(GEOID)) %>%
  select(STATEFP, GEOID, NAMELSAD)

# Attach names from TIGRIS
all_county_geoids_for_lcoe <- all_county_geoids_for_lcoe %>%
  left_join(tigris_counties_2020_raw_for_lcoe %>% select(GEOID, NAMELSAD),
            by = c("county_geoid" = "GEOID"))

dbg_head(all_county_geoids_for_lcoe, "all_county_geoids_for_lcoe (with GeoName & NAMELSAD)")

# Coverage diagnostics
geo_unique_fips <- geo_for_lcoe %>% distinct(fips) %>% pull(fips)
lcoe_set         <- all_county_geoids_for_lcoe$county_geoid
territory_statefps <- c("60","66","69","72","74","78")  # AS, GU, MP, PR, UM, VI
tigris_stateside <- tigris_counties_2020_raw_for_lcoe %>% filter(!STATEFP %in% territory_statefps)

# LCOE → GEO
lcoe_not_in_geo <- setdiff(lcoe_set, geo_unique_fips)
.note("LCOE counties not found in geo$fips: %d", length(lcoe_not_in_geo))
if (length(lcoe_not_in_geo)) print(utils::head(lcoe_not_in_geo, MAX_SHOW))

# GEO → LCOE (restrict to counties present in TIGRIS to avoid non-county GEO rows in `geo`)
geo_not_in_lcoe <- setdiff(intersect(geo_unique_fips, tigris_stateside$GEOID), lcoe_set)
.note("geo$fips (state-side) not in LCOE union: %d", length(geo_not_in_lcoe))
if (length(geo_not_in_lcoe)) print(utils::head(geo_not_in_lcoe, MAX_SHOW))

# LCOE → TIGRIS
lcoe_not_in_tigris <- setdiff(lcoe_set, tigris_stateside$GEOID)
.note("LCOE counties not found in TIGRIS (excluding territories): %d", length(lcoe_not_in_tigris))
if (length(lcoe_not_in_tigris)) print(utils::head(lcoe_not_in_tigris, MAX_SHOW))

# TIGRIS → LCOE
tigris_not_in_lcoe <- setdiff(tigris_stateside$GEOID, lcoe_set)
.note("TIGRIS counties not in LCOE union (excluding territories): %d", length(tigris_not_in_lcoe))
if (length(tigris_not_in_lcoe)) print(utils::head(tigris_not_in_lcoe, MAX_SHOW))

# -------------------------- Quick unmatched checks vs scaffold --------------------------
solar_unmatched <- anti_join(solar_county, county_scaffold, by = "county_geoid")
wind_unmatched  <- anti_join(wind_county,  county_scaffold, by = "county_geoid")
geo_unmatched   <- anti_join(geo_for_lcoe %>% rename(county_geoid = fips) %>% distinct(county_geoid),
                             county_scaffold, by = "county_geoid")
.note("solar_unmatched rows: %d", nrow(solar_unmatched)); dbg_head(solar_unmatched, "solar_unmatched")
.note("wind_unmatched rows: %d",  nrow(wind_unmatched));  dbg_head(wind_unmatched,  "wind_unmatched")
.note("geo_unmatched rows: %d",   nrow(geo_unmatched));   dbg_head(geo_unmatched,   "geo_unmatched")

# -------------------------- Assemble renewable_supplycurve --------------------------
.rule("Join into renewable_supplycurve")

# Ensure GEO FIPS normalized
geo <- geo_for_lcoe

renewable_supplycurve <- county_scaffold %>%
  left_join(solar_county,      by = "county_geoid") %>%
  left_join(wind_county,       by = "county_geoid") %>%
  left_join(geothermal_county, by = "county_geoid") %>%
  left_join(geo,               by = c("county_geoid" = "fips"))

dbg_head(renewable_supplycurve, "renewable_supplycurve (post-join)")

# NA report on critical columns
na_report(renewable_supplycurve,
          c("solar_total_lcoe","solar_capacity_mw_dc",
            "wind_total_lcoe","wind_capacity_mw",
            "geothermal_total_lcoe","geothermal_capacity_MW",
            "cd_119","state_abbr","PEA","CBSA.Code"),
          "renewable_supplycurve")

# Unique GeoNames where LCOE missing (kept for parity with previous debug)
unique_geo_names_na_solar_lcoe <- sort(unique(renewable_supplycurve$GeoName[is.na(renewable_supplycurve$solar_mean_lcoe)]))
.note("Unique GeoName values with NA solar_mean_lcoe: %d", length(unique_geo_names_na_solar_lcoe))
if (length(unique_geo_names_na_solar_lcoe)) print(utils::head(unique_geo_names_na_solar_lcoe, MAX_SHOW))

unique_geo_names_na_wind_lcoe <- sort(unique(renewable_supplycurve$GeoName[is.na(renewable_supplycurve$wind_mean_lcoe)]))
.note("Unique GeoName values with NA wind_mean_lcoe: %d", length(unique_geo_names_na_wind_lcoe))
if (length(unique_geo_names_na_wind_lcoe)) print(utils::head(unique_geo_names_na_wind_lcoe, MAX_SHOW))

# If any 'sf' slipped in, drop geometry
if ("sf" %in% class(renewable_supplycurve)) {
  .note("Dropping sf geometry from renewable_supplycurve to avoid st_union during summarize().")
  renewable_supplycurve <- sf::st_drop_geometry(renewable_supplycurve)
}
if ("sf" %in% class(renewable_supplycurve)) .failf("renewable_supplycurve is still sf!")

# -------------------------- Aggregation per geography --------------------------
.rule("Aggregate by requested geographies")

# Default fallback if 'geographies' isn’t pre-defined by caller
if (!exists("geographies", inherits = TRUE)) {
  geographies <- intersect(c("GeoName","PEA","CBSA.Code","cd_119","State.Name"),
                           names(renewable_supplycurve))
  .note("Auto-detected geographies: %s", paste(geographies, collapse = ", "))
}

# Helpful lookups (especially CBSA title for naming)
cbsa_lookup <- renewable_supplycurve %>%
  distinct(CBSA.Code, CBSA.Title) %>%
  filter(!is.na(CBSA.Code) & CBSA.Code != "")

results_list <- list()

for (geog in geographies) {
  .rule(sprintf("Aggregating for geog: %s", geog), "-")
  if (!geog %in% names(renewable_supplycurve)) {
    .warnf("Geography '%s' not present; skipping.", geog)
    next
  }
  
  # Group snapshot
  grp_sizes <- renewable_supplycurve %>%
    count(.data[[geog]], name = "n_counties") %>%
    arrange(desc(n_counties))
  .note("Groups: %s | Max counties in a group: %s",
        nrow(grp_sizes),
        ifelse(nrow(grp_sizes)>0, max(grp_sizes$n_counties), NA))
  if (nrow(grp_sizes)) print(utils::head(grp_sizes, MAX_SHOW))
  
  # Duplication probe: multiple county rows within the same geog (often from GEO join)
  dup_probe <- renewable_supplycurve %>%
    group_by(.data[[geog]], county_geoid) %>%
    summarise(n = n(), .groups = "drop") %>%
    filter(n > 1)
  if (nrow(dup_probe) > 0) {
    .warnf("Detected duplicated county entries within '%s' groups: %d (showing up to %d)", geog, nrow(dup_probe), MAX_SHOW)
    print(utils::head(dup_probe, MAX_SHOW))
  }
  
  t0 <- proc.time()[["elapsed"]]
  
  if (geog == "cd_119") {
    if (!"percent_district" %in% names(renewable_supplycurve))
      .failf("percent_district missing for cd_119 weighting")
    
    supplycurve <- renewable_supplycurve %>%
      mutate(percent_district = pct_sanitize(percent_district, nm = "percent_district")) %>%
      group_by(.data[[geog]]) %>%
      summarize(
        solar_totallcoe       = wavg(solar_total_lcoe,      solar_capacity_mw_dc   * percent_district / 100),
        wind_totallcoe        = wavg(wind_total_lcoe,       wind_capacity_mw       * percent_district / 100),
        geothermal_totallcoe  = wavg(geothermal_total_lcoe, geothermal_capacity_MW * percent_district / 100),
        solar_capacitymw_dc   = sum_safe(solar_capacity_mw_dc   * percent_district / 100),
        wind_capacitymw       = sum_safe(wind_capacity_mw       * percent_district / 100),
        geothermal_capacityMW = sum_safe(geothermal_capacity_MW * percent_district / 100),
        .groups = "drop"
      )
  } else {
    # Use distinct on value columns within geog to resist row multiplication from joins
    supplycurve <- renewable_supplycurve %>%
      group_by(.data[[geog]]) %>%
      distinct(.data[[geog]],
               solar_total_lcoe, wind_total_lcoe, geothermal_total_lcoe,
               solar_capacity_mw_dc, wind_capacity_mw, geothermal_capacity_MW,
               .keep_all = FALSE) %>%
      summarize(
        solar_totallcoe       = wavg(solar_total_lcoe,      solar_capacity_mw_dc),
        wind_totallcoe        = wavg(wind_total_lcoe,       wind_capacity_mw),
        geothermal_totallcoe  = wavg(geothermal_total_lcoe, geothermal_capacity_MW),
        solar_capacitymw_dc   = sum_safe(solar_capacity_mw_dc),
        wind_capacitymw       = sum_safe(wind_capacity_mw),
        geothermal_capacityMW = sum_safe(geothermal_capacity_MW),
        .groups = "drop"
      )
  }
  
  t1 <- proc.time()[["elapsed"]]
  .note("Aggregation time for %s: %.2fs", geog, t1 - t0)
  
  na_report(supplycurve,
            c("solar_totallcoe","wind_totallcoe","geothermal_totallcoe",
              "solar_capacitymw_dc","wind_capacitymw","geothermal_capacityMW"),
            paste0("supplycurve (", geog, ")"))
  
  zero_cap <- supplycurve %>%
    mutate(total_cap = rowSums(across(c(solar_capacitymw_dc, wind_capacitymw, geothermal_capacityMW)),
                               na.rm = TRUE)) %>%
    filter(is.na(total_cap) | total_cap == 0)
  if (nrow(zero_cap) > 0) {
    .warnf("%d groups have zero/NA total capacity after aggregation; showing first %d:", nrow(zero_cap), min(nrow(zero_cap), MAX_SHOW))
    print(utils::head(zero_cap, MAX_SHOW))
  }
  
  # Carry the grouping column forward; also carry CBSA.Code if that’s the geog (for naming later)
  results_list[[geog]] <- supplycurve %>% mutate(!!geog := .data[[geog]])
}

# -------------------------- Combine + label + ranks --------------------------
.rule("Combine, label, and rank")

supplycurve_geo <- bind_rows(results_list) %>%
  mutate(
    geo = case_when(
      !is.na(State.Name) ~ "State",
      !is.na(cd_119)     ~ "Congressional District",
      !is.na(PEA)        ~ "Economic Area",
      !is.na(GeoName)    ~ "County",
      !is.na(CBSA.Title) ~ "Metro Area",
      TRUE               ~ "Unknown"
    ),
    geo_name = case_when(
      !is.na(State.Name) ~ State.Name,
      !is.na(cd_119)     ~ cd_119,
      !is.na(PEA)        ~ PEA,
      !is.na(GeoName)    ~ GeoName,
      !is.na(CBSA.Title) ~ CBSA.Title,
      TRUE               ~ NA_character_
    )
  ) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  select(geo, geo_name, solar_totallcoe:geothermal_capacityMW) %>%
  group_by(geo) %>%
  mutate(
    Solar_potential_rank      = ifelse(is.na(solar_capacitymw_dc),   NA_integer_, min_rank(-as.numeric(solar_capacitymw_dc))),
    Wind_potential_rank       = ifelse(is.na(wind_capacitymw),       NA_integer_, min_rank(-as.numeric(wind_capacitymw))),
    Geothermal_potential_rank = ifelse(is.na(geothermal_capacityMW), NA_integer_, min_rank(-as.numeric(geothermal_capacityMW))),
    Solar_cost_rank           = ifelse(is.na(solar_totallcoe),       NA_integer_, min_rank(as.numeric(solar_totallcoe))),
    Wind_cost_rank            = ifelse(is.na(wind_totallcoe),        NA_integer_, min_rank(as.numeric(wind_totallcoe))),
    Geothermal_cost_rank      = ifelse(is.na(geothermal_totallcoe),  NA_integer_, min_rank(as.numeric(geothermal_totallcoe)))
  ) %>%
  ungroup()


dbg(supplycurve_geo, "supplycurve_geo (final)")
.rule("Pipeline complete")

#IRA BIL (Federal Funding) Data
ira_bil_raw <- tryCatch(
  readxl::read_excel(file.path(paths$raw_data,"Investment Data - SHARED.xlsx"), sheet=3),
  error=function(e) tibble()
) %>% fix_df(); dbg(ira_bil_raw,"ira_bil_raw")
sf::sf_use_s2(TRUE)

ira_bil_geocoded <- ira_bil_raw %>%
  mutate(
    Longitude = suppressWarnings(as.numeric(Longitude)),
    Latitude  = suppressWarnings(as.numeric(Latitude)),
    Longitude = ifelse(Longitude < -180 | Longitude > 180, NA_real_, Longitude),
    Latitude  = ifelse(Latitude < -90 | Latitude > 90, NA_real_, Latitude)
  ) %>%
  filter(!is.na(Latitude), !is.na(Longitude)) %>%
  st_as_sf(coords = c("Longitude","Latitude"), crs=4326, remove=FALSE) %>%
  st_join(tigris_counties_2020_raw %>% st_transform(4326) %>% transmute(COUNTY_GEOID_2020=GEOID, COUNTY_NAME_2020=NAME, COUNTY_NAMELSAD_2020=NAMELSAD)) %>%
  st_join(tigris_congressional_districts_2024_raw %>% st_transform(4326) %>% transmute(CD119_GEOID=GEOID)) %>%
  st_join(tigris_cbsa_2020_raw %>% st_transform(4326) %>% transmute(CBSA_2020_CODE=GEOID, CBSA_2020_TITLE=NAME)) %>%
  st_join(tigris_states_2024_raw %>% st_transform(4326) %>% transmute(STATE_ABBR=STUSPS, STATE_NAME=NAME, STATE_FIPS=STATEFP)) %>%
  st_join(tigris_counties_2024_raw %>% st_transform(4326) %>% transmute(COUNTY_GEOID_2024=GEOID, COUNTY_NAME_2024=NAME, COUNTY_NAMELSAD_2024=NAMELSAD))
dbg(ira_bil_geocoded,"ira_bil_geocoded")

# ---------------------------
# Federal Grants — finish pipeline (builds on objects already created)
# ---------------------------

library(dplyr)
library(tidyr)
library(janitor)
library(sf)

# 0) Quick peeks at what we already have
glimpse(geo)
dbg(geo, "geo (incoming)")
dbg(geographies, "geographies (incoming)")
dbg(ira_bil_geocoded, "ira_bil_geocoded (incoming)")

# 1) Normalize/standardize keys coming out of your geocoding joins
#    Prefer 2020 county FIPS (to match your geo), fall back to 2024 if needed.
ira_bil_keys <- ira_bil_geocoded %>%
  st_drop_geometry() %>%
  clean_names() %>%
  mutate(
    # Funding/amount fields
    funding_source = `funding_source` %||% `funding_source`,
    funding_amount = suppressWarnings(as.numeric(`funding_amount`)),
    
    # Prefer 2020 county FIPS; if missing, use 2024
    county_fips_2020 = coalesce(county_geoid_2020, county_geoid_2024),
    county_fips_2020 = if_else(nchar(county_fips_2020) == 5, county_fips_2020, NA_character_),
    
    # Congressional district (CD-119). Matches your GEOID_2 key style (SSDD).
    district_id = cd119_geoid,
    district_id = if_else(nchar(district_id) == 4, district_id, NA_character_),
    
    # State bits (mostly for sanity checks)
    state_fips_std = state_fips,
    state_name_std = state_name,
    state_abbr_std = state_abbr,
    
    # CBSA & County names (for reference only)
    cbsa_title_2020 = cbsa_2020_title,
    county_name_2020 = county_namelsad_2020
  ) %>%
  select(
    objectid, funding_source, program_name, project_name,
    funding_amount, district_id, county_fips_2020,
    cbsa_title_2020, state_name_std, state_abbr_std, state_fips_std
  )

dbg(ira_bil_keys, "ira_bil_keys (after key standardization)")
glimpse(ira_bil_keys)

# 1a) NA/Validity audits
ira_bil_audit <- list(
  rows_total           = nrow(ira_bil_keys),
  na_funding_amount    = sum(is.na(ira_bil_keys$funding_amount)),
  na_county_fips_2020  = sum(is.na(ira_bil_keys$county_fips_2020)),
  na_district_id       = sum(is.na(ira_bil_keys$district_id))
)
dbg(as.data.frame(ira_bil_audit), "audit: NA counts")

ira_bil_keys %>% count(funding_source, sort = TRUE) %>% dbg("counts by funding_source")
ira_bil_keys %>% filter(is.na(funding_amount)) %>% head(10) %>% dbg("sample rows with NA funding_amount")
ira_bil_keys %>% filter(is.na(county_fips_2020)) %>% head(10) %>% dbg("sample rows with missing county_fips_2020")
ira_bil_keys %>% filter(is.na(district_id)) %>% head(10) %>% dbg("sample rows with missing district_id")

# 2) Build the county+district summarization (mirrors your legacy approach)
#    Keep Funding Source split and sum amounts.
fed_inv_county <- ira_bil_keys %>%
  filter(!is.na(county_fips_2020)) %>%               # must have county to roll up
  mutate(
    # ensure numeric amount
    federal_funding = suppressWarnings(as.numeric(funding_amount))
  ) %>%
  group_by(district_id, county_fips_2020, funding_source) %>%
  summarize(
    federal_funds = sum(federal_funding, na.rm = TRUE),
    .groups = "drop"
  )

dbg(fed_inv_county, "fed_inv_county (grouped)") 

# 2a) Join to your geo table to leverage all of your previous crosswalk work
#     geo has: fips (county FIPS, 5-character), GEOID_2 (CD119), plus names for State/County/CD/PEA/CBSA, etc.
geo_keys <- geo %>%
  select(-percent_district) %>%
  distinct()

glimpse(geo_keys)

fed_inv_county_geo <- fed_inv_county %>%
  left_join(
    geo_keys,
    by = c("district_id" = "GEOID_2", "county_fips_2020" = "fips")
  )

dbg(fed_inv_county_geo, "fed_inv_county_geo (after join to geo)")
glimpse(fed_inv_county_geo)

# 2b) Quick join diagnostics
anti_cd <- anti_join(fed_inv_county, geo_keys, by = c("district_id" = "GEOID_2", "county_fips_2020" = "fips"))
dbg(anti_cd, "rows in fed_inv_county that didn't match geo (should be small/zero)")
anti_cd %>% count(funding_source, sort = TRUE) %>% dbg("unmatched by funding_source")

# ------------------------------------------
# 3) Rollups across requested geographies  (REPLACE YOUR SECTION WITH THIS)
# ------------------------------------------
stopifnot(all(geographies %in% names(fed_inv_county_geo)))

results_list <- vector("list", length(geographies))
names(results_list) <- geographies

for (geog in geographies) {
  tmp <- fed_inv_county_geo %>%
    transmute(
      geog_value = .data[[geog]],
      funding_source,
      federal_funds
    ) %>%
    filter(!is.na(geog_value), geog_value != "", geog_value != "NA-NA") %>%
    group_by(geog_value, funding_source) %>%
    summarize(federal_funds = sum(federal_funds, na.rm = TRUE), .groups = "drop") %>%
    mutate(rollup_key = geog, .before = 1)
  
  dbg(tmp, paste0("rollup (normalized) for ", geog))
  results_list[[geog]] <- tmp
}

# Stack (already normalized)
fed_inv_geo_long <- bind_rows(results_list)

dbg(fed_inv_geo_long, "fed_inv_geo_long (normalized & stacked)")
glimpse(fed_inv_geo_long)

# Quick QA: make sure we didn't lose levels
fed_inv_geo_long %>% count(rollup_key, sort = TRUE) %>% dbg("row counts by rollup_key")
fed_inv_geo_long %>% filter(is.na(geog_value)) %>% count(rollup_key) %>% dbg("NA geog_value by rollup_key (should be 0)")

# ------------------------------------------
# 4) De-dupe (safety) and pivot
# ------------------------------------------
dups <- fed_inv_geo_long %>%
  count(rollup_key, geog_value, funding_source, name = "n") %>%
  filter(n > 1L)
dbg(dups, "DUP CHECK before pivot")

fed_inv_geo_long_u <- fed_inv_geo_long %>%
  group_by(rollup_key, geog_value, funding_source) %>%
  summarize(federal_funds = sum(federal_funds, na.rm = TRUE), .groups = "drop")

dbg(fed_inv_geo_long_u, "fed_inv_geo_long_u (unique keys)")
glimpse(fed_inv_geo_long_u)

fed_inv_geo_wide <- fed_inv_geo_long_u %>%
  mutate(funding_source = case_when(
    funding_source == "BIL"     ~ "BIL_grants",
    funding_source == "IRA"     ~ "IRA_grants",
    TRUE                        ~ funding_source
  )) %>%
  tidyr::pivot_wider(
    names_from  = funding_source,
    values_from = federal_funds,
    values_fill = 0
  ) %>%
  mutate(
    total_bil_ira_grants = rowSums(across(any_of(c("BIL_grants","IRA_grants"))), na.rm = TRUE)
  )

dbg(fed_inv_geo_wide, "fed_inv_geo_wide (wide, numeric)")
glimpse(fed_inv_geo_wide)

# ------------------------------------------
# 5) Friendly labels and final shape (unchanged)
# ------------------------------------------
fed_inv_geo <- fed_inv_geo_wide %>%
  mutate(
    geo = case_when(
      rollup_key == "State.Name" ~ "State",
      rollup_key == "cd_119"     ~ "Congressional District",
      rollup_key == "PEA"        ~ "Economic Area",
      rollup_key == "GeoName"    ~ "County",
      rollup_key == "CBSA.Title" ~ "Metro Area",
      TRUE ~ rollup_key
    ),
    geo_name = geog_value
  ) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  select(
    geo, geo_name,
    BIL_grants = any_of("BIL_grants"),
    IRA_grants = any_of("IRA_grants"),
    total_bil_ira_grants
  ) %>%
  arrange(geo, geo_name)

dbg(fed_inv_geo, "fed_inv_geo (final)")
glimpse(fed_inv_geo)

# Bonus QA: you should now see multiple geo types
fed_inv_geo %>% count(geo, sort = TRUE) %>% dbg("Row counts by geo (expect > State only)")

# ------------------------------------------
# 6) Friendly labels and final shape
# ------------------------------------------
fed_inv_geo <- fed_inv_geo_wide %>%
  mutate(
    geo = case_when(
      rollup_key == "State.Name" ~ "State",
      rollup_key == "cd_119"     ~ "Congressional District",
      rollup_key == "PEA"        ~ "Economic Area",
      rollup_key == "GeoName"    ~ "County",
      rollup_key == "CBSA.Title" ~ "Metro Area",
      TRUE ~ rollup_key
    ),
    geo_name = geog_value
  ) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  select(
    geo, geo_name,
    BIL_grants = any_of("BIL_grants"),
    IRA_grants = any_of("IRA_grants"),
    total_bil_ira_grants
  ) %>%
  arrange(geo, geo_name)

dbg(fed_inv_geo, "fed_inv_geo (final)"); glimpse(fed_inv_geo)

# ------------------------------------------
# 7) Optional extra QA
# ------------------------------------------
# Top by total
fed_inv_geo %>%
  arrange(desc(total_bil_ira_grants)) %>%
  slice_head(n = 10) %>%
  dbg("Top 10 by total_bil_ira_grants")

# Counts per geo type
fed_inv_geo %>% count(geo, sort = TRUE) %>% dbg("Row counts by geo")

# =========================
# Life Expectancy (IHME) → ACS 5yr 2023 weighted aggregations (robust + debug)
# =========================

library(dplyr)
library(stringr)
library(purrr)
library(rlang)
library(tidyr)

# ---- 0) Helpers ----
`%||%` <- function(a,b) if (!is.null(a)) a else b

dbg <- get0("dbg", ifnotfound = function(x, name) { print(name); print(utils::head(x, 10)); invisible(x) })

geo_label_map <- c(
  "State.Name" = "State",
  "cd_119"     = "Congressional District",
  "PEA"        = "Economic Area",
  "CBSA.Title" = "Metro Area",
  "GeoName"    = "County"
)

agg_one_geo <- function(df, group_col_chr) {
  group_sym <- sym(group_col_chr)
  
  clean <- df %>%
    filter(!is.na(!!group_sym), !!group_sym != "") %>%
    mutate(usable = !is.na(le_val) & !is.na(weight_pop) & weight_pop > 0)
  
  coverage <- clean %>%
    group_by(!!group_sym) %>%
    summarize(
      pop_total  = sum(weight_pop %||% 0, na.rm = TRUE),
      pop_usable = sum(if_else(usable, weight_pop, 0), na.rm = TRUE),
      coverage   = if_else(pop_total > 0, pop_usable / pop_total, NA_real_),
      .groups = "drop"
    )
  
  estimates <- clean %>%
    filter(usable) %>%
    group_by(!!group_sym) %>%
    summarize(
      life_expectancy = weighted.mean(le_val, w = weight_pop, na.rm = TRUE),
      n_counties      = n(),
      .groups = "drop"
    ) %>%
    left_join(coverage, by = as.character(group_sym))
  
  low_cov <- estimates %>% filter(!is.na(coverage) & coverage < 0.98)
  if (nrow(low_cov) > 0) {
    dbg(low_cov %>% arrange(coverage) %>% head(25),
        paste0("LOW COVERAGE in ", group_col_chr, " (≤98%; top 25 worst)"))
  }
  
  out <- estimates %>%
    transmute(
      geo      = unname(geo_label_map[[group_col_chr]] %||% group_col_chr),
      geo_name = !!group_sym,
      life_expectancy = as.numeric(life_expectancy),
      pop_total, pop_usable, coverage, n_counties
    ) %>%
    filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA")
  
  dbg(out %>% arrange(coverage) %>% head(10),
      paste0("Sample aggregated results: ", group_col_chr))
  
  out
}

# ---- 1) Load IHME + slice to spec (2019 / <1 year / Total / Both) ----
life_expectancy_raw <- suppressWarnings(
  read.csv(
    file.path(
      paths$us_maps,"Econ","Life Expectancy","IHME_county_life_expectancy",
      "IHME_USA_LE_COUNTY_RACE_ETHN_2000_2019_LT_2019_BOTH_Y2022M06D16.csv"
    ),
    check.names = FALSE
  )
) %>% fix_df()
dbg(life_expectancy_raw, "life_expectancy_raw")

life_expectancy_2019 <- life_expectancy_raw %>%
  filter(
    year == 2019,
    age_name == "<1 year",
    race_name == "Total",
    sex_name == "Both"
  )
dbg(life_expectancy_2019, "life_expectancy_2019 (filtered: 2019/<1yr/Total/Both)")

# ---- 2) County subset + FIPS normalize ----
life_expectancy_county <- life_expectancy_2019 %>%
  filter(grepl("\\(", location_name)) %>%
  mutate(
    county_geoid = ifelse(nchar(fips) == 4, paste0("0", fips), as.character(fips)),
    county_geoid = str_pad(county_geoid, 5, pad = "0")
  ) %>%
  filter(nchar(county_geoid) == 5) %>%
  select(county_geoid, le_val = val, location_name)
dbg(life_expectancy_county, "life_expectancy_county (2019 slice + FIPS padded)")

# ---- 3) ACS 5yr 2023 as the sole source of weights + descriptors ----
# Ensure ACS fips as 5-char; prefer provided fips else build from state/county
acs_5yr_23_norm <- acs_5yr_23 %>%
  mutate(
    fips = if_else(!is.na(fips) & nchar(fips) > 0, fips,
                   str_pad(state, 2, pad = "0") %>% paste0(str_pad(county, 3, pad = "0"))),
    fips = str_pad(fips, 5, pad = "0")
  )

# Canonicalize to ONE ROW PER COUNTY FIPS to avoid many-to-many joins:
# - Prefer the row with the highest percent_district (ties broken by larger pop)
# - Then keep a single set of descriptors per fips
acs_5yr_23_dupe_counts <- acs_5yr_23_norm %>% count(fips, name = "n_rows_per_fips") %>% filter(n_rows_per_fips > 1)
dbg(acs_5yr_23_dupe_counts %>% head(10), "acs_5yr_23_dupe_counts (>1 row per fips)")

acs_5yr_23_canonical <- acs_5yr_23_norm %>%
  mutate(
    # Treat NA percent_district as -Inf so rows with real shares win
    percent_district_rank = replace_na(percent_district, -Inf)
  ) %>%
  arrange(fips, desc(percent_district_rank), desc(pop)) %>%
  group_by(fips) %>%
  slice_head(n = 1) %>%
  ungroup() %>%
  select(
    fips, pop,
    any_of(c("State.Name","cd_119","PEA","CBSA.Title","GeoName"))
  )

dbg(acs_5yr_23_canonical %>% select(fips, GeoName, pop) %>% head(10),
    "acs_5yr_23_canonical (key cols preview, 1 row per fips)")

# ---- 4) Legacy / renamed county FIPS handling (targeted fixes only) ----
legacy_fips_remap <- tibble::tribble(
  ~from,   ~to,     ~note,
  "12025", "12086", "Dade -> Miami-Dade (FL) legacy alignment"
  # Add more only if ACS23 uses the destination FIPS:
  # "02270","02158","Wade Hampton -> Kusilvak (AK)"
)

life_expectancy_county <- life_expectancy_county %>%
  left_join(legacy_fips_remap, by = c("county_geoid" = "from")) %>%
  mutate(county_geoid = if_else(!is.na(to), to, county_geoid)) %>%
  select(-to, -note)

# ---- 5) Diagnose crosswalk between IHME and ACS 2023 ----
ihme_not_in_acs <- life_expectancy_county %>%
  distinct(county_geoid, location_name) %>%
  anti_join(acs_5yr_23_canonical %>% distinct(fips), by = c("county_geoid" = "fips"))
dbg(ihme_not_in_acs, "IHME county FIPS not in ACS 5yr 2023 (post-remap)")

acs_not_in_ihme <- acs_5yr_23_canonical %>%
  distinct(fips, GeoName) %>%
  anti_join(life_expectancy_county %>% distinct(county_geoid), by = c("fips" = "county_geoid"))
dbg(acs_not_in_ihme %>% head(20), "ACS 2023 FIPS not in IHME (head)")

# ---- 6) Join weights + descriptors from ACS 2023 (canonical, 1:1) ----
life_expectancy_weighted <- life_expectancy_county %>%
  left_join(
    acs_5yr_23_canonical %>%
      select(
        fips, pop,
        any_of(geographies) # State.Name, cd_119, PEA, CBSA.Title, GeoName
      ),
    by = c("county_geoid" = "fips")
  ) %>%
  rename(weight_pop = pop)

dbg(life_expectancy_weighted, "life_expectancy_weighted (IHME + ACS23 joined)")

# Missing/zero weights or values
dbg(life_expectancy_weighted %>% filter(is.na(weight_pop) | weight_pop <= 0),
    "Rows with missing/zero weights (ACS23)")
dbg(life_expectancy_weighted %>% filter(is.na(le_val)),
    "Rows with missing life expectancy values (IHME)")

# ---- 7) Aggregate across geographies using ACS 2023 descriptors ----
results_list <- map(geographies, ~agg_one_geo(life_expectancy_weighted, .x))
life_geo <- bind_rows(results_list)
dbg(life_geo, "life_geo (aggregated across geographies)")

life_geo_final <- life_geo %>%
  select(geo, geo_name, life_expectancy)
dbg(life_geo_final, "life_geo_final (tidy output)")

# ---- 8) QA summaries ----
overall_coverage <- life_expectancy_weighted %>%
  summarize(
    counties_total        = n_distinct(county_geoid),
    counties_with_weights = n_distinct(county_geoid[!is.na(weight_pop) & weight_pop > 0]),
    counties_with_values  = n_distinct(county_geoid[!is.na(le_val)]),
    counties_usable       = n_distinct(county_geoid[!is.na(le_val) & !is.na(weight_pop) & weight_pop > 0])
  )
dbg(overall_coverage, "overall_coverage (county foundations, ACS23 weighting)")

worst_coverage <- life_geo %>%
  arrange(coverage) %>%
  filter(!is.na(coverage)) %>%
  head(15)
dbg(worst_coverage, "Worst coverage groups across all geographies (top 15)")

#Clean Investment Monitor tax credit-based data
investment_raw <- suppressWarnings(read.csv(file.path(cim_dir,"quarterly_actual_investment.csv"), skip=4, check.names=FALSE)) %>% fix_df(); dbg(investment_raw,"investment_raw")
socioecon_raw <- suppressWarnings(read.csv(file.path(cim_dir,"socioeconomics.csv"), skip=4, check.names=FALSE)) %>% fix_df()
tax_inv_cat_raw <- suppressWarnings(read.csv(file.path(cim_dir,"federal_actual_investment_by_category.csv"), skip=4, check.names=FALSE)) %>% fix_df()
tax_inv_state_raw <- suppressWarnings(read.csv(file.path(cim_dir,"federal_actual_investment_by_state.csv"), skip=4, check.names=FALSE)) %>% fix_df()
dbg(socioecon_raw,"socioecon_raw"); dbg(tax_inv_cat_raw,"tax_inv_cat_raw"); dbg(tax_inv_state_raw,"tax_inv_state_raw")

# =========================
# Tax Credit Allocation Pipeline (debug-heavy)
# =========================

suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(stringr)
  library(purrr)
  library(janitor)
  library(lubridate)
  library(zoo)
  library(rlang)
})

# -------------------------
# Debug helpers
# -------------------------
if (!exists("dbg")) {
  dbg <- function(x, title = deparse(substitute(x)), n = 5) {
    cat("\n====", title, "====\n")
    if (inherits(x, "data.frame")) {
      cat(sprintf("Rows: %s  Cols: %s\n", nrow(x), ncol(x)))
      print(dplyr::glimpse(x, width = 80))
      cat("Head:\n")
      print(utils::head(x, n))
    } else {
      str(x)
    }
  }
}

cli_msg  <- function(...) cli::cli_inform(list(message = sprintf(...)))
cli_ok   <- function(...) cli::cli_alert_success(sprintf(...))
cli_warn <- function(...) cli::cli_alert_warning(sprintf(...))
cli_oops <- function(...) cli::cli_alert_danger(sprintf(...))

# utility: assert columns exist
require_cols <- function(df, cols, df_name = deparse(substitute(df))) {
  miss <- setdiff(cols, names(df))
  if (length(miss)) {
    stop(sprintf("[%s] is missing required columns: %s",
                 df_name, paste(miss, collapse = ", ")), call. = FALSE)
  }
}

# robust left_join that tells you what got dropped/duplicated
safe_left_join <- function(x, y, by, suffix = c(".x",".y")) {
  before <- nrow(x)
  out <- suppressMessages(left_join(x, y, by = by, suffix = suffix))
  after <- nrow(out)
  if (after < before) cli_warn("Left-join reduced rows from {before} -> {after}. Check keys: {paste(by, collapse=', ')}")
  if (after > before) cli_msg("Left-join expanded rows from %s -> %s (many-to-one?).", before, after)
  out
}

# map from geographies vector to pretty label
geo_label <- function(geog) {
  switch(geog,
         "State.Name" = "State",
         "cd_119"     = "Congressional District",
         "PEA"        = "Economic Area",
         "GeoName"    = "County",
         "CBSA.Title" = "Metro Area",
         geog)
}

# parse flexible date (for Production_Date like "6/19/23")
parse_mdY <- function(x) suppressWarnings(lubridate::mdy(x))

# -------------------------
# Standardize inputs / names
# -------------------------
investment <- investment_raw
tax_inv_cat <- tax_inv_cat_raw
tax_inv_state <- tax_inv_state_raw

# sanity checks
require_cols(investment, c("Segment","State","Technology","quarter","Estimated_Actual_Quarterly_Expenditure"), "investment")
require_cols(tax_inv_cat, c("Segment","Category","quarter","Total Federal Investment"), "tax_inv_cat")
require_cols(tax_inv_state, c("State","quarter","Total Federal Investment"), "tax_inv_state")
require_cols(facilities_clean,
             c("unique_id","Segment","Technology","Subcategory","Decarb_Sector",
               "Project_Type","Investment_Status","Current_Facility_Status",
               "State","State.Name","cd_119","GeoName","PEA","CBSA.Title",
               "Estimated_Total_Facility_CAPEX","Production_Date"),
             "facilities_clean")

cli::cli_h1("Inputs overview")
dbg(investment, "investment")
dbg(tax_inv_cat, "tax_inv_cat")
dbg(tax_inv_state, "tax_inv_state")
dbg(facilities_clean, "facilities_clean (selected cols)")

# coerce Production_Date (chr) to Date, but keep original
facilities_use <- facilities_clean %>%
  mutate(Production_Date_parsed = parse_mdY(Production_Date))

miss_pd <- sum(is.na(facilities_use$Production_Date_parsed) & nzchar(facilities_use$Production_Date))
if (miss_pd > 0) cli_warn("%s Production_Date values failed to parse; they will be treated as NA.", miss_pd)

# -------------------------
# Category totals (modern verbs)
# -------------------------
cli::cli_h1("Federal tax credit category totals")

tax_inv_cat_tot <- tax_inv_cat %>%
  group_by(Segment, Category) %>%
  summarise(Total_Federal_Investment = sum(`Total Federal Investment`, na.rm = TRUE), .groups = "drop")

dbg(tax_inv_cat_tot, "tax_inv_cat_tot")

tax_inv_state_tot <- tax_inv_state %>%
  group_by(State) %>%
  summarise(Total_Federal_Investment = sum(`Total Federal Investment`, na.rm = TRUE), .groups = "drop")

dbg(tax_inv_state_tot, "tax_inv_state_tot")

# -------------------------
# Generic allocator by geography
# -------------------------
# - filter_fn: a function(df) -> df filtered for the credit
# - category_key: value to filter in tax_inv_cat_tot$Category
# - out_name: name of result column
allocate_credit_by_geo <- function(filter_fn, category_key, out_name) {
  results <- vector("list", length(geographies))
  names(results) <- geographies
  
  for (i in seq_along(geographies)) {
    geog <- geographies[[i]]
    cli::cli_h2(sprintf("Processing %s  |  category: %s", geo_label(geog), category_key))
    
    seg_cap <- facilities_use %>%
      filter_fn() %>%
      # keep only the geo col + minimal fields
      distinct(!!sym(geog), unique_id, Segment, Estimated_Total_Facility_CAPEX) %>%
      group_by(!!sym(geog), Segment) %>%
      summarise(Estimated_Total_Facility_CAPEX = sum(Estimated_Total_Facility_CAPEX, na.rm = TRUE), .groups = "drop")
    
    if (nrow(seg_cap) == 0) {
      cli_warn("No facilities match for %s; skipping.", geo_label(geog))
      results[[i]] <- tibble(geo = character(), geo_name = character()) %>%
        mutate("{out_name}" := numeric())
      next
    }
    # segment share within the category universe (robust to zero-denominators)
    seg_share <- seg_cap %>%
      group_by(Segment) %>%
      mutate(
        seg_total = sum(Estimated_Total_Facility_CAPEX, na.rm = TRUE),
        cap_share = dplyr::if_else(
          seg_total > 0,
          Estimated_Total_Facility_CAPEX / seg_total,
          0
        )
      ) %>%
      select(-seg_total) %>%
      ungroup()
    
    
    dbg(seg_share, sprintf("seg_cap/seg_share [%s]", geo_label(geog)))
    
    cat_tot <- tax_inv_cat_tot %>%
      filter(Category == !!category_key)
    
    if (nrow(cat_tot) == 0) {
      cli_warn("tax_inv_cat_tot has no rows for Category == '%s'. Result will be zero.", category_key)
    }
    
    out <- safe_left_join(
      seg_share,
      cat_tot,
      by = c("Segment")
    ) %>%
      mutate(Total_Federal_Investment = replace_na(Total_Federal_Investment, 0),
             "{out_name}" := Total_Federal_Investment * cap_share)
    
    # project the single geography column into labeled geo/geo_name
    out2 <- out %>%
      transmute(
        geo       = geo_label(geog),
        geo_name  = .data[[geog]],
        !!out_name := .data[[out_name]]
      ) %>%
      filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
      distinct()
    
    dbg(out2, sprintf("allocated [%s]", out_name))
    results[[i]] <- out2
  }
  
  bind_rows(results)
}

# -------------------------
# 45X: Advanced Manufacturing Tax Credits
# Facilities: CTM + tech subset, operating, not closed
# -------------------------
# 45X
filter_45x <- function(.data) {
  dplyr::filter(
    .data,
    Decarb_Sector == "Clean Tech Manufacturing",
    Technology %in% c("Solar","Wind","Critical Minerals","Batteries"),
    Investment_Status == "O",
    Current_Facility_Status != "C",
    !is.na(State.Name), !is.na(PEA), !is.na(CBSA.Title),
    !is.na(cd_119), !is.na(GeoName),
    State.Name != ""
  )
}
geo_45x <- allocate_credit_by_geo(filter_45x, "Advanced Manufacturing Tax Credits", "local_45x")

# -------------------------
# 45V & 45Q: Emerging Climate Technology Tax Credits (Hydrogen/Carbon Mgt/Ind.)
# -------------------------
# 45V & 45Q
filter_45vq <- function(.data) {
  dplyr::filter(
    .data,
    Segment == "Energy and Industry",
    Technology %in% c("Hydrogen","Carbon Management","Cement","Iron & Steel","Pulp & Paper"),
    Investment_Status == "O",
    !is.na(State.Name), !is.na(PEA), !is.na(CBSA.Title),
    !is.na(cd_119), !is.na(GeoName),
    State.Name != ""
  )
}

geo_45vq <- allocate_credit_by_geo(filter_45vq, "Emerging Climate Technology Tax Credits", "local_45vq")

# -------------------------
# 45Z & 40B: Emerging Climate Technology Tax Credits (Fuels)
# -------------------------
# 45Z & 40B
filter_45z_40b <- function(.data) {
  dplyr::filter(
    .data,
    Segment == "Energy and Industry",
    Technology %in% c("Sustainable Aviation Fuels","Clean Fuels"),
    Investment_Status == "O",
    !is.na(State.Name), !is.na(PEA), !is.na(CBSA.Title),
    !is.na(cd_119), !is.na(GeoName),
    State.Name != ""
  )
}

geo_45z_40b <- allocate_credit_by_geo(filter_45z_40b, "Emerging Climate Technology Tax Credits", "local_45z_40b")

# -------------------------
# Section 45 (clean electricity PTC/ITC proxy): Power, non-Other/Nuclear,
# after IRA (2022-08-15) by production date.
# -------------------------
# 45 (clean electricity), post-IRA
ira_start <- as.Date("2022-08-15")
filter_45 <- function(.data) {
  dplyr::filter(
    .data,
    Decarb_Sector == "Power",
    Investment_Status == "O",
    !is.na(State.Name), !is.na(PEA), !is.na(CBSA.Title),
    !is.na(cd_119), !is.na(GeoName),
    State.Name != "",
    !is.na(Production_Date_parsed) & Production_Date_parsed > as.Date("2022-08-15")
  )
}
geo_45 <- allocate_credit_by_geo(filter_45, "Clean Electricity Tax Credits", "local_45")
# -------------------------
# 30D: Zero Emission Vehicle Tax Credits (retail) — pop-apportioned to all geos
# -------------------------
cli::cli_h1("30D (Zero Emission Vehicle Tax Credits) - Pop-apportioned")

inv_30d_state <- investment %>%
  mutate(qtr = zoo::as.yearqtr(quarter, format = "%Y-Q%q")) %>%
  filter(
    Segment == "Retail",
    Technology %in% c("Zero Emission Vehicles"),
    qtr > zoo::as.yearqtr("2022 Q1")
  ) %>%
  group_by(State, Segment) %>%
  summarise(
    Estimated_Actual_Quarterly_Expenditure =
      sum(Estimated_Actual_Quarterly_Expenditure, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  group_by(Segment) %>%
  mutate(
    seg_total = sum(Estimated_Actual_Quarterly_Expenditure, na.rm = TRUE),
    cap_share = ifelse(seg_total > 0,
                       Estimated_Actual_Quarterly_Expenditure / seg_total,
                       0)
  ) %>%
  select(-seg_total) %>%
  ungroup()

dbg(inv_30d_state, "inv_30d_state (post-shares)")

# National 30D total -> state shares
cat_30d <- tax_inv_cat_tot %>%
  filter(Category == "Zero Emission Vehicle Tax Credits")

if (nrow(cat_30d) == 0) {
  cli_warn("No 30D total found in tax_inv_cat_tot; setting state_30d to 0.")
  cat_30d <- tibble(Segment = unique(inv_30d_state$Segment), Total_Federal_Investment = 0)
}

state_30d <- safe_left_join(
  inv_30d_state,
  cat_30d,
  by = "Segment"
) %>%
  mutate(
    Total_Federal_Investment = replace_na(Total_Federal_Investment, 0),
    state_30d = Total_Federal_Investment * cap_share
  ) %>%
  select(State, state_30d) %>%
  arrange(desc(state_30d))

dbg(state_30d, "state_30d (allocated)")

# ---- Population apportionment to all geographies (patched) ----
# Build a clean state lookup
state_lookup <- tibble(
  State.Name = c(state.name, "District of Columbia"),
  state_abbr = c(state.abb, "DC")
)

# Infer a 2-letter state code for each pop row using the geo_name pattern
# Handles:
#  - "AL-03", "ND-00"  (first two letters)
#  - "Some County, Colorado" (suffix is a state name)
#  - "Modesto, CA" / "Dickinson, ND" (suffix is a 2-letter code)
#  - State rows where geo_name is the full state name
pop_base <- pop %>%
  select(geo, geo_name, pop) %>%
  mutate(
    cd_prefix = stringr::str_match(geo_name, "^([A-Z]{2})-")[, 2],
    suffix    = stringr::str_trim(stringr::str_extract(geo_name, "(?<=, )[^,]+$"))
  ) %>%
  # join for cases where suffix is a full state name
  left_join(state_lookup, by = c("suffix" = "State.Name")) %>%
  rename(state_from_suffix_name = state_abbr) %>%   # <- keeps first join's abbr
  # join for rows where the whole geo_name is the state name
  left_join(state_lookup, by = c("geo_name" = "State.Name")) %>%  # no suffix needed
  rename(state_from_state_row = state_abbr) %>%     # <- this exists
  mutate(
    state2 = dplyr::coalesce(
      cd_prefix,                                             # "AL-03"
      dplyr::if_else(!is.na(suffix) & nchar(suffix) == 2,    # ", CA"
                     toupper(suffix), NA_character_),
      state_from_suffix_name,                                # ", Colorado" -> "CO"
      state_from_state_row                                   # "Colorado" (state rows)
    )
  ) %>%
  select(geo, geo_name, pop, state2)

# Warn if any rows couldn't be mapped to a state
n_unmapped <- sum(is.na(pop_base$state2))
if (n_unmapped > 0) {
  cli_warn("{n_unmapped} pop rows could not be mapped to a state; dropping them for 30D apportionment.")
}

pop_expanded <- pop_base %>%
  filter(!is.na(state2)) %>%
  distinct()

# Apportion each state's 30D total down to all its geos by population share
fac_30d_down <- pop_expanded %>%
  filter(geo != "State") %>%            # <-- prevent state rows here
  group_by(state2) %>%
  mutate(
    state_pop = sum(pop, na.rm = TRUE),
    pop_share = if_else(state_pop > 0, pop / state_pop, 0)
  ) %>%
  ungroup() %>%
  select(geo, geo_name, state2, pop_share) %>%
  safe_left_join(state_30d %>% transmute(state2 = State, state_30d), by = "state2") %>%
  mutate(local_30d = replace_na(state_30d, 0) * replace_na(pop_share, 0)) %>%
  select(geo, geo_name, local_30d) %>%
  distinct()

# Ensure state-level rows exist explicitly (even if pop table didn’t carry states)
state_map <- tibble(state_abbr = state.abb, State.Name = state.name)

fac_30d_states <- state_30d %>%
  mutate(state_abbr = State) %>%
  safe_left_join(state_map, by = "state_abbr") %>%
  transmute(
    geo       = "State",
    geo_name  = State.Name,
    local_30d = state_30d
  ) %>%
  filter(!is.na(geo_name))

# Final: all geos (states + sub-state)
fac_30d_geo <- bind_rows(fac_30d_down, fac_30d_states) %>%
  filter(!is.na(geo_name)) %>%
  distinct()

dbg(fac_30d_geo, "fac_30d_geo (pop-apportioned to all geos)")

# -------------------------
# Combine all geo credit layers
# -------------------------
cli::cli_h1("Combine geo credit layers")

norm_name <- function(x) stringr::str_squish(as.character(x))

geo_spine <- geo_long %>%
  transmute(
    geo      = norm_name(geo_type), # expects: State / County / Congressional District / Economic Area / Metro Area
    geo_name = norm_name(geo_name)
  ) %>%
  filter(!is.na(geo), !is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  distinct()

dbg(geo_spine, "geo_spine (from geo_long)")

# helper: within-group ranks, but return all-NA when the group's vector is all zeros
rank_or_na <- function(x) {
  x <- replace_na(x, 0)
  if (all(x == 0)) rep(NA_real_, length(x)) else rank(-x, ties.method = "min")
}

geo_credits <- geo_spine %>%
  safe_left_join(geo_45x  %>% select(geo, geo_name, local_45x),        by = c("geo","geo_name")) %>%
  safe_left_join(geo_45vq %>% select(geo, geo_name, local_45vq),       by = c("geo","geo_name")) %>%
  safe_left_join(geo_45   %>% select(geo, geo_name, local_45),         by = c("geo","geo_name")) %>%
  safe_left_join(geo_45z_40b %>% select(geo, geo_name, local_45z_40b), by = c("geo","geo_name")) %>%
  safe_left_join(fac_30d_geo %>% select(geo, geo_name, local_30d),     by = c("geo","geo_name")) %>%
  mutate(across(starts_with("local_"), ~replace_na(.x, 0))) %>%
  group_by(geo) %>%
  mutate(
    rank_45x     = rank_or_na(local_45x),
    rank_45vq    = rank_or_na(local_45vq),
    rank_45      = rank_or_na(local_45),
    rank_30d     = rank_or_na(local_30d),
    rank_45z_40b = rank_or_na(local_45z_40b)
  ) %>%
  ungroup() %>%
  arrange(geo, desc(local_45x), desc(local_45), desc(local_45vq))

dbg(geo_credits, "geo_credits (final)")

#Check for duplicates in geo_credits
dup_geo <- geo_credits %>%
  count(geo, geo_name) %>%
  filter(n > 1)
if (nrow(dup_geo) > 0) {
  cli_warn("There are {nrow(dup_geo)} duplicate (geo, geo_name) pairs in geo_credits. Example rows:\n{utils::head(dup_geo, 10) %>% capture.output() %>% paste(collapse = '\n')}")
} else {
  cli_ok("No duplicate (geo, geo_name) pairs in geo_credits.")
}

#POLITICS
cbs<-read.csv('https://raw.githubusercontent.com/cbs-news-data/election-2024-maps/refs/heads/master/output/all_counties_clean_2024.csv')
#Turn "fips" into five-digit string with leading zeros
cbs$fips<-sprintf("%05d",cbs$fips)
#Remove rows for which NAME is blank/NA
cbs<-cbs[!is.na(cbs$NAME) & cbs$NAME!="",]
cbs<-left_join(cbs,geo,by="fips")

results_list <- list()

for (geog in geographies) {
  politics_geo<-cbs %>%
    group_by(!!sym(geog)) %>%
    summarize_at(vars(vote_Harris,totalVote),sum,na.rm=T) %>%
    mutate(demshare=vote_Harris/totalVote) %>%
    mutate(partisan = case_when(demshare<0.4 ~ 1,
                                demshare<0.45~2,
                                demshare<0.55~3,
                                demshare<0.65~4,
                                demshare>0.65~5)) %>%
    mutate(partisan = factor(partisan,
                             levels=c(1:5),
                             labels=c("Strong Republican",
                                      "Leans Republican",
                                      "Battleground",
                                      "Leans Democratic",
                                      "Strong Democratic")))
  
  results_list[[geog]] <- politics_geo
}
pres2024<-bind_rows(results_list) 
pres2024<-pres2024 %>%
  mutate(geo = case_when(
    !is.na(State.Name) ~ "State",
    !is.na(cd_119) ~ "Congressional District",
    !is.na(PEA) ~ "Economic Area",
    !is.na(GeoName) ~"County",
    TRUE ~ "Metro Area"
  )) %>%
  mutate(geo_name = case_when(
    !is.na(State.Name) ~ State.Name,
    !is.na(cd_119) ~ cd_119,
    !is.na(PEA) ~ PEA,
    !is.na(GeoName) ~ GeoName,
    TRUE ~ CBSA.Title
  )) %>%
  filter(!is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  dplyr::select(geo,geo_name,demshare,partisan)
glimpse(pres2024)

# ====================== StatsAmerica (prep: Index + Measures, 3 geo types + diagnostics) ======================

options(warn=1)
sanitize_names <- function(x) gsub("\\.+","_",make.names(x,unique=TRUE)); coerce_numeric <- function(x) suppressWarnings(as.numeric(x))
prep_common <- function(df){
  if (!nrow(df)) return(df)
  df %>%
    dplyr::rename(
      area_name = dplyr::any_of(c("description","description...3")),
      indicator = dplyr::any_of(c("description...5"))
    ) %>%
    dplyr::mutate(
      geo_id  = as.character(.data$geo_id),
      time_id = coerce_numeric(.data$time_id)
    ) %>%
    fix_df() %>%                         # repairs blank/dup names first
    { stats::setNames(., sanitize_names(names(.))) }
}
keep_latest <- function(df){ if(!nrow(df)||!"time_id"%in%names(df)) return(df); df %>% dplyr::group_by(geo_id) %>% dplyr::filter(time_id==max(time_id,na.rm=TRUE)) %>% dplyr::ungroup() }
normalize_metro <- function(df){ if(!nrow(df)||!"geo_id"%in%names(df)) return(df); df %>% dplyr::mutate(geo_id=ifelse(grepl("^2",geo_id),substr(geo_id,2,nchar(geo_id)),geo_id)) %>% fix_df() }
print_df_issues <- function(df,label,top_na=12){ cat(sprintf("\n==== Diagnostics — %s ====\n",label)); if(requireNamespace("readr",quietly=TRUE)&&inherits(df,"tbl_df")){ p<-try(readr::problems(df),silent=TRUE); if(!inherits(p,"try-error")&&nrow(p)) print(utils::head(p,12)) else cat("No readr parsing problems.\n") } else cat("Skipping readr::problems().\n"); nac<-sort(sapply(df,function(v)sum(is.na(v))),decreasing=TRUE); cat("\n---- NA counts (top) ----\n"); if(length(nac)) print(utils::head(nac,top_na)) else cat("No columns.\n") }
coverage_report <- function(df,label,threshold=0.85){ cat(sprintf("\n==== Coverage — %s ====\n",label)); if(!nrow(df)) return(invisible(NULL)); cov<-sapply(df,function(v) mean(!is.na(v))); cov_df<-tibble::tibble(column=names(cov),coverage=as.numeric(cov))%>%dplyr::arrange(coverage); print(utils::head(cov_df,20)); bad<-dplyr::filter(cov_df,coverage<threshold); if(nrow(bad)){ cat(sprintf("\n-- Columns below %.0f%% coverage --\n",threshold*100)); print(bad) }; invisible(cov_df) }

# --- Download & read ---
sa_zip<-tempfile(fileext=".zip"); sa_ok<-tryCatch({download.file("https://www.statsamerica.org/downloads/Innovation-Intelligence.zip",sa_zip,mode="wb",quiet=TRUE);file.exists(sa_zip)},error=function(e)FALSE)
sa_list<-if(sa_ok) try(unzip(sa_zip,list=TRUE),silent=TRUE) else structure("try-error",class="try-error"); tmp_sa<-tempdir()
sa_read <- function(regex){
  f <- if (!inherits(sa_list, "try-error")) sa_list$Name[grepl(regex, sa_list$Name, ignore.case = TRUE)] else character(0)
  f <- f[!grepl("EDD", f, ignore.case = TRUE)]
  if (!length(f)) return(tibble())
  unzip(sa_zip, files = f[1], exdir = tmp_sa)
  readr::read_csv(file.path(tmp_sa, f[1]), show_col_types = FALSE, na = c("", "NULL", "NA", "N/A"), guess_max = 100000) %>% fix_df()
}

# --- Raw loads + quick diagnostics ---
idx_sc_raw    <- sa_read("Index Values.*States and Counties\\.csv$");  print_df_issues(idx_sc_raw,"idx_sc_raw")
meas_sc_raw   <- sa_read("Measures.*States and Counties\\.csv$");      print_df_issues(meas_sc_raw,"meas_sc_raw")
idx_metro_raw <- sa_read("Index Values.*Metros\\.csv$") %>% normalize_metro; print_df_issues(idx_metro_raw,"idx_metro_raw (normalized)")
meas_metro_raw<- sa_read("Measures.*Metros\\.csv$")     %>% normalize_metro; print_df_issues(meas_metro_raw,"meas_metro_raw (normalized)")

# --- Index: States + Counties (pivot wide) ---
idx_sc <- idx_sc_raw %>% prep_common() %>% keep_latest() %>% dplyr::rename(value=dplyr::any_of(c("Index.Value","Index_Value"))) %>% dplyr::mutate(value=coerce_numeric(value)) %>%
  dplyr::group_by(geo_id,area_name,indicator) %>% dplyr::summarise(value=mean(value,na.rm=TRUE),.groups="drop") %>%
  tidyr::pivot_wider(names_from="indicator",values_from="value",names_repair="unique"); dbg(idx_sc,"idx_sc (wide)"); coverage_report(idx_sc,"idx_sc")

# --- Measures: States + Counties (pivot wide, with Summary_Level) ---
meas_sc <- meas_sc_raw %>% prep_common() %>%
  dplyr::rename(value=dplyr::any_of(c("Measure.Value","Measure_Value")), indicator=dplyr::any_of(c("Code.Description","Code_Description")), Summary_Level=dplyr::any_of(c("Summary.Level","Summary_Level"))) %>%
  dplyr::mutate(value=coerce_numeric(value), Summary_Level=as.character(Summary_Level)) %>% keep_latest() %>%
  dplyr::group_by(geo_id,area_name,indicator,Summary_Level) %>% dplyr::summarise(value=mean(value,na.rm=TRUE),.groups="drop") %>%
  tidyr::pivot_wider(names_from="indicator",values_from="value",names_repair="unique"); dbg(meas_sc,"meas_sc (wide + Summary_Level)"); coverage_report(meas_sc,"meas_sc")

# --- Index: Metros (pivot wide) ---
idx_metro <- idx_metro_raw %>% prep_common() %>% keep_latest() %>% dplyr::rename(value=dplyr::any_of(c("Index.Value","Index_Value"))) %>%
  dplyr::mutate(value=coerce_numeric(value)) %>% dplyr::group_by(geo_id,area_name,indicator) %>% dplyr::summarise(value=mean(value,na.rm=TRUE),.groups="drop") %>%
  tidyr::pivot_wider(names_from="indicator",values_from="value",names_repair="unique"); dbg(idx_metro,"idx_metro (wide)"); coverage_report(idx_metro,"idx_metro")

# --- Measures: Metros (pivot wide) ---
meas_metro <- meas_metro_raw %>% prep_common() %>%
  dplyr::rename(value=dplyr::any_of(c("Measure.Value","Measure_Value")), indicator=dplyr::any_of(c("Code.Description","Code_Description")), Summary_Level=dplyr::any_of(c("Summary.Level","Summary_Level"))) %>%
  dplyr::mutate(value=coerce_numeric(value), Summary_Level=as.character(Summary_Level)) %>% keep_latest() %>%
  dplyr::group_by(geo_id,area_name,indicator,Summary_Level) %>% dplyr::summarise(value=mean(value,na.rm=TRUE),.groups="drop") %>%
  tidyr::pivot_wider(names_from="indicator",values_from="value",names_repair="unique"); dbg(meas_metro,"meas_metro (wide)"); coverage_report(meas_metro,"meas_metro")

# --- Add geo_type (exactly 3: State, County, Metro) ---
add_geo_type <- function(df,type){ if(!nrow(df)) return(df); df %>% dplyr::mutate(statsamerica_geo_type=type, statsamerica_geo_name=area_name, statsamerica_geo_id=geo_id) %>% dplyr::select(statsamerica_geo_type,statsamerica_geo_name,statsamerica_geo_id,dplyr::everything(),-area_name,-geo_id) }

# Use Summary_Level to split State vs County for SC frames
states_idx   <- add_geo_type(dplyr::filter(idx_sc, geo_id %in% unique(meas_sc$geo_id[meas_sc$Summary_Level=="40"])),"State")
counties_idx <- add_geo_type(dplyr::filter(idx_sc, geo_id %in% unique(meas_sc$geo_id[meas_sc$Summary_Level=="50"])),"County")
metros_idx   <- add_geo_type(idx_metro,"Metro")

states_meas   <- add_geo_type(dplyr::filter(meas_sc, Summary_Level=="40") %>% dplyr::select(-Summary_Level),"State")
counties_meas <- add_geo_type(dplyr::filter(meas_sc, Summary_Level=="50") %>% dplyr::select(-Summary_Level),"County")
metros_meas   <- add_geo_type(meas_metro %>% dplyr::select(-Summary_Level),"Metro")

# --- Final pivoted outputs (separate Index vs Measures) + NA->"" ---
statsamerica_allgeos_index <- dplyr::bind_rows(states_idx,counties_idx,metros_idx) %>%
  dplyr::mutate(dplyr::across(where(is.numeric), ~ifelse(is.na(.),"",.))); dbg(statsamerica_allgeos_index,"statsamerica_allgeos_index (Index, 3 geo types)")
statsamerica_allgeos_measures <- dplyr::bind_rows(states_meas,counties_meas,metros_meas) %>%
  dplyr::mutate(dplyr::across(where(is.numeric), ~ifelse(is.na(.),"",.))); dbg(statsamerica_allgeos_measures,"statsamerica_allgeos_measures (Measures, 3 geo types)")

# --- Extra debugging: quick coverage on the final tables ---
coverage_report(statsamerica_allgeos_index,"statsamerica_allgeos_index")
coverage_report(statsamerica_allgeos_measures,"statsamerica_allgeos_measures")

# ====================== StatsAmerica -> County-weighted rollups to custom geographies ======================

# 1) Build a county-level master of indicators (Measures + Index) to join with your county geo + gdp
#    - We use Summary_Level to isolate counties (50) for the SC files
#    - We drop the "(Removed)" measure and keep the newer traded-sector composite

# Clean up SC Measures: just counties
meas_sc_counties <- meas_sc %>%
  dplyr::filter(.data$Summary_Level == "50") %>%
  dplyr::select(-.data$Summary_Level) %>%
  # Drop the old "Removed" column if present
  dplyr::select(-dplyr::any_of("Traded Sector Establishment Births to All Establishment Ratio (Removed)"))

# County slice of SC Index (idx_sc contains states+counties; restrict to counties known in meas_sc_counties)
idx_sc_counties <- idx_sc %>%
  dplyr::filter(.data$geo_id %in% meas_sc_counties$geo_id)

# Metro Index/Measures exist, but for your weighted rollups by custom geographies
# you are aggregating *county-based* values by county GDP. We'll stay county-centric.
# (Metros are still available from your earlier products if you need them separately.)

# 2) Harmonize + join Measures (county) with Index (county) side-by-side
#    (Make sure there are no duplicated indicator names across tables.)
shared_cols <- intersect(names(meas_sc_counties), names(idx_sc_counties))
shared_cols <- setdiff(shared_cols, c("geo_id","area_name")) # keep only true dup indicators
if (length(shared_cols)) {
  # For safety, suffix duplicates coming from Index (rare; most names are distinct)
  idx_sc_counties <- idx_sc_counties %>%
    dplyr::rename_with(~ paste0(., " (Index)"), dplyr::all_of(shared_cols))
}

county_indicators <- meas_sc_counties %>%
  dplyr::full_join(idx_sc_counties, by = c("geo_id","area_name"))

# 3) Join to your `geo` to get the rollup geographies + GDP weights
#    - For counties, your key is county FIPS in `geo$fips` (5-digit)
county_indicators_geo <- county_indicators %>%
  dplyr::left_join(geo %>% dplyr::select(.data$fips, dplyr::all_of(geographies), .data$gdp),
                   by = c("geo_id" = "fips"))

# 4) Choose the indicator sets for rollup
meas_cols <- c(
  "Technology-Based Knowledge Occupation Clusters",
  "Average STEM Degree Creation (per 1,000 Population)",
  "Average High-Tech Industry Employment Share",
  "Average Annual Venture Capital (scaled by GDP)",
  "Average Annual Expansion Stage Venture Capital (scaled by GDP)",
  "Average Annual High-Tech Industry Venture Capital (scaled by GDP)",
  "Industry Diversity",
  "Industry Cluster Growth Factor",
  "Average Gross Domestic Product (per Worker)",
  "Change in Share of High-Tech Industry Employment",
  "Per Capita Personal Income Growth",
  "Income Inequality (Mean to Median Ratio)",
  "Government Transfers to Total Personal Income Ratio",
  "Average Net Migration"
)

index_cols <- c(
  "Headline Innovation Index",
  "Educational Attainment",
  "Economic Well-Being",
  "Business Dynamics",
  # prefer the newer traded-sector composite if present
  "Traded Sector Births and Expansions to Deaths and Contractions Ratio",
  "Foreign Direct Investment Attractiveness",
  "Industry Performance",
  "Latent Innovation",
  "Industry Cluster Performance",
  "Industry Cluster Strength"
)

# guard: only keep columns that actually exist in the joined county table
meas_cols  <- intersect(meas_cols,  names(county_indicators_geo))
index_cols <- intersect(index_cols, names(county_indicators_geo))
rollup_cols <- unique(c(meas_cols, index_cols))

# 5) Weighted mean helper that returns NA_real_ when weights are missing/zero
wmean_safe0 <- function(x, w) {
  w <- replace_na(as.numeric(w), 0)
  if (sum(w) <= 0) return(NA_real_)
  stats::weighted.mean(as.numeric(x), w, na.rm = TRUE)
}

# 6) Build rollups across each named geography in your `geographies` vector
#    - Keep blanks (""), not "NA", *only in the final output*
rollup_list <- vector("list", length(geographies))
names(rollup_list) <- geographies

for (geog_name in geographies) {
  # Only aggregate where we actually have the grouping column
  if (!geog_name %in% names(county_indicators_geo)) next
  
  gdf <- county_indicators_geo %>%
    dplyr::filter(!is.na(.data[[geog_name]]), .data[[geog_name]] != "", .data[[geog_name]] != "NA-NA") %>%
    dplyr::group_by(.data[[geog_name]], .drop = FALSE) %>%
    dplyr::summarise(
      dplyr::across(
        dplyr::any_of(rollup_cols),
        ~ wmean_safe(., .data$gdp),
        .names = "{.col}"
      ),
      .groups = "drop"
    ) %>%
    # rename the grouping column back to its original name
    dplyr::rename(!!geog_name := 1)
  
  rollup_list[[geog_name]] <- gdf
}

innovation_geo_meas <- dplyr::bind_rows(rollup_list)

# 7) Optional: Join back additional index-only columns if you want them separated
#    (here we already included both measure and index fields in one pass via rollup_cols)

# 8) Geo typing + naming (your logic), then enforce blanks instead of NA at the very end
innovation_geo <- innovation_geo_meas %>%
  dplyr::mutate(
    geo = dplyr::case_when(
      !is.na(.data$State.Name) ~ "State",
      !is.na(.data$cd_119)     ~ "Congressional District",
      !is.na(.data$PEA)        ~ "Economic Area",
      !is.na(.data$GeoName)    ~ "County",
      TRUE                     ~ "Metro Area" # falls back; your inputs may not need this case
    ),
    geo_name = dplyr::case_when(
      !is.na(.data$State.Name) ~ .data$State.Name,
      !is.na(.data$cd_119)     ~ .data$cd_119,
      !is.na(.data$PEA)        ~ .data$PEA,
      !is.na(.data$GeoName)    ~ .data$GeoName,
      TRUE                     ~ .data$CBSA.Title
    )
  ) %>%
  dplyr::filter(!is.na(.data$geo_name), .data$geo_name != "", .data$geo_name != "NA-NA") %>%
  # final requirement: leave blanks where missing
  dplyr::mutate(dplyr::across(dplyr::where(is.numeric), ~ .)) %>% # keep numerics as numerics for downstream math
  { # but if you need an export with blanks, convert *at export time*:
    .
  }

# If you do need the “blanks-not-NA” version *as a delivery table* (e.g., CSV export),
# make a copy with numeric -> character blanks:
innovation_geo_export <- innovation_geo %>%
  dplyr::mutate(
    dplyr::across(dplyr::where(is.numeric), ~ ifelse(is.na(.), "", as.character(.)))
  )

# 9) Quick sanity check, mirroring your diagnostics philosophy
dbg(innovation_geo, "innovation_geo (weighted rollups)")
coverage_report(innovation_geo, "innovation_geo (numeric coverage)")

# ==== QUICK STRUCTURE PREVIEW (unchanged) ====
str(geo_long)
str(rengen)
str(facilities_all)
str(geo_credits)
str(fed_inv_geo)
str(elec_grid)
str(supplycurve_geo)
str(tech_pot_geo)
str(county_gdp_ind_final)
str(manpay_geo)
str(manshare)
str(vit)
str(pop)
str(prop)
str(life_geo)
str(pres2024)
str(innovation_geo)
str(geo)

# ==== HELPERS ===============================================================

assert_unique_by <- function(df, keys, name = deparse(substitute(df))) {
  d <- df %>%
    dplyr::count(dplyr::across(all_of(keys)), name = "n") %>%
    dplyr::filter(.data$n > 1)
  if (nrow(d)) {
    stop(sprintf("[DUP] %s not unique by (%s). First few:\n%s",
                 name, paste(keys, collapse = ", "),
                 paste(utils::capture.output(print(utils::head(d, 10))), collapse = "\n")))
  }
  invisible(df)
}

make_unique_by <- function(df, keys, summarise_fn = dplyr::first) {
  if (!all(keys %in% names(df))) return(df)
  df %>%
    dplyr::group_by(dplyr::across(all_of(keys))) %>%
    dplyr::summarise(dplyr::across(dplyr::everything(), summarise_fn), .groups = "drop")
}

qa_unique <- function(df, nm) {
  d <- df %>% dplyr::count(geo, geo_name, name = "n") %>% dplyr::filter(n > 1)
  if (nrow(d)) {
    stop(sprintf("[DUP] %s not unique by (geo,geo_name). First few:\n%s",
                 nm, paste(capture.output(print(utils::head(d, 10))), collapse = "\n")))
  }
}

# optional helper: only parse numbers when a column is character
parse_if_char <- function(x) if (is.character(x)) readr::parse_number(x) else x

# rollups for enforcing uniqueness (choose mean vs sum by table semantics)
sum_cols_fn  <- function(x) if (is.numeric(x)) sum(x, na.rm = TRUE) else dplyr::first(x)
mean_cols_fn <- function(x) if (is.numeric(x)) mean(x, na.rm = TRUE) else dplyr::first(x)

# mean that returns NA instead of NaN when all values are missing
mean_or_na <- function(x) {
  if (!is.numeric(x)) return(dplyr::first(x))
  if (all(is.na(x))) return(NA_real_)
  mean(x, na.rm = TRUE)
}

# ==== ENFORCE UNIQUENESS ON RIGHT-HAND TABLES (BEFORE JOINS) ===============

rengen               <- make_unique_by(rengen,               c("geo","geo_name"), mean_cols_fn)
facilities_all       <- make_unique_by(facilities_all,       c("geo","geo_name"), mean_cols_fn)
geo_credits          <- make_unique_by(geo_credits,          c("geo","geo_name"), mean_cols_fn)
fed_inv_geo          <- make_unique_by(fed_inv_geo,          c("geo","geo_name"), sum_cols_fn)
elec_grid            <- make_unique_by(elec_grid,            c("geo","geo_name"), mean_cols_fn)
supplycurve_geo      <- make_unique_by(supplycurve_geo,      c("geo","geo_name"), mean_cols_fn)
tech_pot_geo         <- make_unique_by(tech_pot_geo,         c("geo","geo_name"), sum_cols_fn)
county_gdp_ind_final <- make_unique_by(county_gdp_ind_final, c("geo","geo_name"), mean_cols_fn)
manpay_geo           <- make_unique_by(manpay_geo,           c("geo","geo_name"), mean_cols_fn)
manshare             <- make_unique_by(manshare,             c("geo","geo_name"), mean_cols_fn)
vit                  <- make_unique_by(vit,                  c("geo","geo_name"), mean_cols_fn)
pop                  <- make_unique_by(pop,                  c("geo","geo_name"), sum_cols_fn)
prop                 <- make_unique_by(prop,                 c("geo","geo_name"), mean_cols_fn)  # ALAND-weighted mean earlier
life_geo             <- make_unique_by(life_geo,             c("geo","geo_name"), mean_cols_fn)
pres2024             <- make_unique_by(pres2024,             c("geo","geo_name"), mean_cols_fn)
innovation_geo       <- make_unique_by(innovation_geo,       c("geo","geo_name"), mean_cols_fn)

# Sanity check uniqueness right before joining
qa_unique(rengen, "rengen")
qa_unique(facilities_all, "facilities_all")
qa_unique(geo_credits, "geo_credits")
qa_unique(fed_inv_geo, "fed_inv_geo")
qa_unique(elec_grid, "elec_grid")
qa_unique(supplycurve_geo, "supplycurve_geo")
qa_unique(tech_pot_geo, "tech_pot_geo")
qa_unique(county_gdp_ind_final, "county_gdp_ind_final")
qa_unique(manpay_geo, "manpay_geo")
qa_unique(manshare, "manshare")
qa_unique(vit, "vit")
qa_unique(pop, "pop")
qa_unique(prop, "prop")
qa_unique(life_geo, "life_geo")
qa_unique(pres2024, "pres2024")
qa_unique(innovation_geo, "innovation_geo")

# ==== BUILD SPINE & JOIN ====================================================

all_geos_joined <- geo_long %>%
  dplyr::transmute(
    geo      = stringr::str_squish(as.character(geo_type)),
    geo_name = stringr::str_squish(as.character(geo_name)),
    geo_code = as.character(geo_code)
  ) %>%
  dplyr::filter(!is.na(geo), !is.na(geo_name), geo_name != "", geo_name != "NA-NA") %>%
  dplyr::distinct() %>%
  # joins on (geo, geo_name), while retaining geo_code from the spine
  dplyr::left_join(rengen,               by = c("geo","geo_name")) %>%
  dplyr::left_join(facilities_all,       by = c("geo","geo_name")) %>%
  dplyr::left_join(geo_credits,          by = c("geo","geo_name")) %>%
  dplyr::left_join(fed_inv_geo,          by = c("geo","geo_name")) %>%
  dplyr::left_join(elec_grid,            by = c("geo","geo_name")) %>%
  dplyr::left_join(supplycurve_geo,      by = c("geo","geo_name")) %>%
  dplyr::left_join(tech_pot_geo,         by = c("geo","geo_name")) %>%
  dplyr::left_join(county_gdp_ind_final, by = c("geo","geo_name")) %>%
  dplyr::left_join(manpay_geo,           by = c("geo","geo_name")) %>%
  dplyr::left_join(manshare,             by = c("geo","geo_name")) %>%
  dplyr::left_join(vit,                  by = c("geo","geo_name")) %>%
  dplyr::left_join(pop,                  by = c("geo","geo_name")) %>%
  dplyr::left_join(prop,                 by = c("geo","geo_name")) %>%
  dplyr::left_join(life_geo,             by = c("geo","geo_name")) %>%
  dplyr::left_join(pres2024,             by = c("geo","geo_name")) %>%
  dplyr::left_join(innovation_geo,       by = c("geo","geo_name"))

# ==== DEFINE ZERO-FILL WHITELIST (NUMERIC COLUMNS ONLY) =====================

# Start with explicit names you consider "additive/zero-ok", then intersect with numeric cols present
explicit_zero_ok <- c(
  "total_investment",
  "Operating Investment since IRA", "Announced Investment since IRA",
  "Investment under Construction since IRA",
  "Total_Manufacturing_Investment",
  "Operating Cleantech Manufacturing Investment since IRA",
  "Announced Cleantech Manufacturing Investment since IRA",
  "Cleantech Manufacturing Investment under Construction since IRA",
  "BIL_grants", "IRA_grants", "total_bil_ira_grants"
)

# Also pick up any investment columns that start with "inv_", but only if they're numeric
inv_like <- grep("^inv_", names(all_geos_joined), value = TRUE)

numeric_cols <- names(all_geos_joined)[vapply(all_geos_joined, is.numeric, logical(1))]
numeric_zero_ok <- intersect(c(explicit_zero_ok, inv_like), numeric_cols)

# ==== APPLY ZERO-FILL, FINAL COLLAPSE, AND CLEANUP ==========================

all_geos <- all_geos_joined %>%
  # Replace NA and NaN with 0 for the whitelisted numeric columns only
  dplyr::mutate(
    dplyr::across(
      tidyselect::any_of(numeric_zero_ok),
      ~ {
        x <- .
        if (is.numeric(x)) {
          x[is.nan(x)] <- NA_real_
          tidyr::replace_na(x, 0)
        } else {
          x
        }
      }
    )
  ) %>%
  # Final safety collapse in case any table slipped duplicate rows
  dplyr::group_by(geo, geo_name, geo_code) %>%
  dplyr::summarise(
    dplyr::across(dplyr::everything(), mean_or_na, .names = "{.col}"),
    .groups = "drop"
  ) %>%
  # keep geo_code; only drop fields that might appear and are safe to remove
  dplyr::select(-dplyr::any_of(c("state_abbr","State","Region","Division")))

# ==== BASIC SANITY CHECKS (keep light; no hard stop on diagnostics) ====
dup_n <- all_geos %>% dplyr::count(geo, geo_name, geo_code, name = "n") %>% dplyr::filter(n > 1) %>% nrow()
if (dup_n > 0) warning("all_geos still has duplicate keys; rows: ", dup_n)

# Impossible ACS-like values (now should be near-zero counts)
all_geos %>%
  dplyr::summarise(
    bad_med_inc = sum(med_house_inc < 0 | med_house_inc > 500000, na.rm = TRUE),
    bad_unemp   = sum(unemp < 0 | unemp > 100, na.rm = TRUE),
    bad_vac     = sum(vacancy < 0 | vacancy > 100, na.rm = TRUE)
  ) %>% print()

cat("Glimpse of all_geos:\n"); str(all_geos)

# ==== EXPORT ====
write.csv(all_geos, "all_geos_test.csv", row.names = FALSE)

cat("\n=== FINAL QA ===\n")
cat("Rows:", nrow(all_geos), "  Unique keys:", nrow(distinct(all_geos, geo, geo_name, geo_code)), "\n")

# 1) No duplicate keys
stopifnot(nrow(all_geos %>% count(geo, geo_name, geo_code) %>% filter(n>1)) == 0)

# 2) No absurd ACS values
stopifnot(all(all_geos$unemp     <= 100 | is.na(all_geos$unemp)))
stopifnot(all(all_geos$vacancy   <= 100 | is.na(all_geos$vacancy)))
stopifnot(all(all_geos$med_house_inc >= 0 | is.na(all_geos$med_house_inc)))

# 3) Life expectancy not auto-zeroed
cat("life_expectancy zeros:", sum(all_geos$life_expectancy == 0, na.rm=TRUE), "\n")

# 4) Check “Unknown” EIA tech share
if (exists("op_gen_geo")) {
  cat("Unknown tech rows in EIA:", sum(op_gen_geo$clean == "Unknown", na.rm=TRUE), "\n")
}




# State-level vars — raw
eps_raw <- suppressWarnings(read.csv(file.path(paths$raw_data,"eps.csv"), check.names=FALSE)) %>% fix_df(); dbg(eps_raw,"eps_raw (patched names)")

eps_elec<-eps_raw %>%
  filter(scenario=="BAU",
         var1=="Electricity Generation by Type" ,
         var2 %in% c("onshore wind","solar PV","hard coal","natural gas combined cycle","natural gas peaker")) %>%
  mutate(index=round(100*Value/Value[Year=="2021"],1)) %>%
  select(Division,State,var2,Year,index)
glimpse(eps_elec)


# Quarterly State GDP (SQGDP) — raw (for reference elsewhere)
sqgdp_zip <- tempfile(fileext=".zip"); download.file("https://apps.bea.gov/regional/zip/SQGDP.zip", sqgdp_zip, mode="wb", quiet=TRUE)
sq_list <- try(unzip(sqgdp_zip, list=TRUE), silent=TRUE); sqf <- if(!inherits(sq_list,"try-error")) sq_list$Name[grepl("^SQGDP1__ALL_AREAS_\\d{4}_\\d{4}\\.csv$", sq_list$Name)][1] else NA
tmp_sg <- tempdir(); if(!is.na(sqf)) unzip(sqgdp_zip, files=sqf, exdir=tmp_sg); sqgdp1_raw <- if(!is.na(sqf)) read.csv(file.path(tmp_sg, sqf), check.names=FALSE) else tibble(); sqgdp1_raw <- fix_df(sqgdp1_raw); dbg(sqgdp1_raw,"sqgdp1_raw")
cat("Glimpse of sqgdp1_raw:\n"); glimpse(sqgdp1_raw)

#gdp_q<-sqgdp1_raw %>%
#  filter(LineCode==1) %>%
#  mutate(state_gdp_1yr=round((`2024:Q4`-`2023:Q4`)/`2023:Q4`*100,1),
#         state_gdp_5yr=round((`2024:Q4`-`2019:Q4`)/`2019:Q4`*100,1)) %>%
#  arrange(desc(state_gdp_5yr)) 
#glimpse(gdp_q)

#Create state_gdp_quarterly where we have state_gdp_1_yr column that dynamically identifies the most recent YYYY:Q# column and goes from that
#Then we'd also have state_gdp_5_yr column that goes from most recent YYYY:Q# to YYYY-5:Q#
# ---------- Quarterly state GDP: dynamic latest YoY & 5y YoY ----------
state_gdp_quarterly <- {
  df <- sqgdp1_raw %>% filter(LineCode == 1)
  
  qcols <- grep("^\\d{4}:Q[1-4]$", names(df), value = TRUE)
  stopifnot(length(qcols) > 0)
  
  # Treat quarter labels lexicographically (YYYY:Qn compares correctly)
  latest_q <- max(qcols)
  latest_y <- as.integer(substr(latest_q, 1, 4))
  latest_qn<- as.integer(sub(".*:Q", "", latest_q))
  
  q_1yr <- sprintf("%d:Q%d", latest_y - 1, latest_qn)
  q_5yr <- sprintf("%d:Q%d", latest_y - 5, latest_qn)
  
  # Only compute if the reference columns exist
  has_1yr <- q_1yr %in% names(df)
  has_5yr <- q_5yr %in% names(df)
  
  out <- df %>%
    mutate(
      latest_val = .data[[latest_q]],
      one_yr_val = if (has_1yr) .data[[q_1yr]] else NA_real_,
      five_yr_val= if (has_5yr) .data[[q_5yr]] else NA_real_,
      state_gdp_1_yr = round((latest_val / dplyr::na_if(one_yr_val, 0) - 1) * 100, 1),
      state_gdp_5_yr = round((latest_val / dplyr::na_if(five_yr_val, 0) - 1) * 100, 1)
    ) %>%
    select(State, contains("state_gdp_"), all_of(c(latest_q, q_1yr[q_1yr %in% names(df)], q_5yr[q_5yr %in% names(df)]))) %>%
    rename(latest_quarter = !!latest_q)
  
  out
}
glimpse(state_gdp_quarterly)


#XChange Climate Policy Data 
xchange_pol_index <- read_csv(file,path(DATA_DIR,"US Maps etc", "Policy", "xchange_climate_policy_index.csv"))
xchange_pol_index<-xchange_pol_index %>%
  select(abbr, climate_policy_index)

# EIA state emissions (raw)
eia_state_ems_tmp <- tempfile(fileext=".xlsx"); httr::GET("https://www.eia.gov/environment/emissions/state/excel/table1.xlsx", write_disk(eia_state_ems_tmp, overwrite=TRUE))
eia_state_emissions_raw <- tryCatch(readxl::read_excel(eia_state_ems_tmp, sheet=1, skip=4), error=function(e) tibble()) %>% fix_df(); dbg(eia_state_emissions_raw,"eia_state_emissions_raw")

state_ems <- eia_state_emissions_raw %>%
  mutate(state_ems_change_1722 = round((`2022`-`2017`)/`2017`*100,3)) %>%
  select(State,`2022`,state_ems_change_1722) %>%
  rename("emissions_2022"="2022") 

# Corporate tax rates (state) — raw
corp_tax_raw <- suppressWarnings(read.csv(file.path(paths$raw_data,"2024 State Corporate Income Tax Rates Brackets.csv"), check.names=FALSE)) %>% fix_df(); dbg(corp_tax_raw,"corp_tax_raw")
cat("Glimpse of corp_tax_raw:\n"); glimpse(corp_tax_raw)
corporate_tax<-corp_tax_raw %>%
  mutate(Rates=as.numeric(gsub("%","",Rates))) %>%
  rename("corporate_tax"="Rates") %>%
  mutate(corporate_tax=ifelse(X=="(b)",0,
                              ifelse(X=="None",0,corporate_tax))) %>%
  mutate(State=gsub("\\([a-zA-Z]\\)","",State),
         State=trimws(State)) %>%
  select(State,corporate_tax) %>%
  group_by(State) %>%
  slice_max(order_by=corporate_tax,n=1)
cat("Glimpse of corporate_tax:\n"); glimpse(corporate_tax)

# EIA Natural Gas Industrial Price (state) — raw
eia_ng_tmp <- tempfile(fileext=".xls"); download.file("https://www.eia.gov/dnav/ng/xls/NG_PRI_SUM_A_EPG0_PIN_DMCF_M.xls", eia_ng_tmp, mode="wb", quiet=TRUE)
eia_ng_industrial_price_raw <- tryCatch(readxl::read_excel(eia_ng_tmp, sheet=2, skip=2), error=function(e) tibble()) %>% fix_df(); dbg(eia_ng_industrial_price_raw,"eia_ng_industrial_price_raw")
clean_colnames <- function(names) {
  names %>%
    str_remove_all(" Natural Gas Industrial Price \\(Dollars per Thousand Cubic Feet\\)") %>%
    str_trim()
}

# Apply to dataframe
colnames(eia_ng_industrial_price_raw) <- c("Date", clean_colnames(colnames(eia_ng_industrial_price_raw)[-1]))
eia_gas <- eia_ng_industrial_price_raw

eia_gas<-pivot_longer(eia_gas,cols=c(`United States`:`Wyoming`),names_to="state",values_to = "dollars_mcf")
eia_gas<-left_join(eia_gas,census_divisions,by=c("state"="State"))

eia_gas_2024<-eia_gas %>%
  mutate(year=substr(Date,1,4)) %>%
  group_by(state,year) %>%
  summarize(across(c(dollars_mcf),mean,na.rm=T)) %>%
  filter(year=="2024") %>%
  dplyr::select(-year) %>%
  rename(gas_price=dollars_mcf)
cat("Glimpse of eia_gas_2024:\n"); glimpse(eia_gas_2024)


# EIA 861M SALES (state) — raw
eia861m_path <- file.path(paths$states_data,"eia_sales.xlsx"); invisible(RETRY("GET","https://www.eia.gov/electricity/data/eia861m/xls/sales_revenue.xlsx", write_disk(eia861m_path, overwrite=TRUE), times=3))
eia861m_sales_raw <- tryCatch(readxl::read_excel(eia861m_path, sheet=1, skip=2), error=function(e) tibble()) %>% fix_df(); dbg(eia861m_sales_raw,"eia861m_sales_raw")
ind_price_m <- eia861m_sales_raw %>%
  mutate(ind_price_m=`Cents/kWh...16`) %>%
  select(State,Year,Month,ind_price_m)
cat("Glimpse of ind_price_m:\n");glimpse(ind_price_m)
ind_price <- ind_price_m %>%
  group_by(State,Year) %>%
  summarize(ind_price=mean(ind_price_m,na.rm=T)) %>%
  filter(Year %in% c("2014","2019","2024")) %>%
  pivot_wider(names_from=Year,values_from=ind_price) %>%
  mutate(ind_price_10yr=(`2024`/`2014`-1)*100,
         ind_price_5yr=(`2024`/`2019`-1)*100,
         ind_price_cents_kwh=`2024`) %>%
  select(State,ind_price_10yr,ind_price_5yr,ind_price_cents_kwh)
cat("Glimpse of ind_price:\n");glimpse(ind_price)

# CNBC State rankings — raw
cnbc <- suppressWarnings(read.csv(file.path(paths$raw_data,"cnbc_bus_rankings.csv"), check.names=FALSE)) %>% fix_df() %>% rename_with(~stringr::str_trim(.x)); dbg(cnbc_rankings_raw,"cnbc_rankings_raw")
colnames(cnbc)[1]<-"cnbc_rank"
colnames(cnbc)[2]<-"state"
cnbc<-cnbc %>%
  select(state,cnbc_rank)
cat("Glimpse of cnbc state business rankings:\n");glimpse(cnbc)

# CGT / FEAS inputs — raw
cgt_county_raw <- suppressWarnings(read.csv(file.path(DATA_DIR,"CGT_county_data","cgt_county_data_08_29_2024.csv"), check.names=FALSE)) %>% fix_df(); dbg(cgt_county_raw,"cgt_county_raw")
cim_eco_eti_raw <- suppressWarnings(read.csv(file.path(paths$raw_data,"CIM_eco_eti_invest_categories.csv"), check.names=FALSE)) %>% fix_df(); dbg(cim_eco_eti_raw,"cim_eco_eti_raw")
eco_rmi_crosswalk_raw <- suppressWarnings(read.csv(file.path(paths$raw_data,"eco_rmi_updated_crosswalk.csv"), check.names=FALSE)) %>% fix_df(); dbg(eco_rmi_crosswalk_raw,"eco_rmi_crosswalk_raw")
clean_industry_naics_raw <- suppressWarnings(read.csv(file.path(paths$raw_data,"clean_industry_naics.csv"), check.names=FALSE)) %>% fix_df(); dbg(clean_industry_naics_raw,"clean_industry_naics_raw")
